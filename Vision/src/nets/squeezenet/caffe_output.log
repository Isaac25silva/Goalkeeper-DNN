I0811 03:32:40.651942 10215 upgrade_proto.cpp:1084] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /home/fei/DIGITS/digits/jobs/20180810-204659-701e/solver.prototxt
I0811 03:32:40.652088 10215 upgrade_proto.cpp:1091] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0811 03:32:40.652092 10215 upgrade_proto.cpp:1093] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0811 03:32:40.652150 10215 caffe.cpp:204] Using GPUs 0
I0811 03:32:40.655755 10215 caffe.cpp:209] GPU 0: GeForce GTX 1060
I0811 03:32:40.879047 10215 solver.cpp:45] Initializing solver from parameters:
test_iter: 240
test_interval: 562
base_lr: 0.01
display: 70
max_iter: 56200
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 18546
snapshot: 11240
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
train_state {
level: 0
stage: ""
}
type: "SGD"
I0811 03:32:40.879144 10215 solver.cpp:102] Creating training net from net file: train_val.prototxt
I0811 03:32:40.879809 10215 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I0811 03:32:40.879835 10215 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0811 03:32:40.879983 10215 net.cpp:51] Initializing net from parameters:
state {
phase: TRAIN
level: 0
stage: ""
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 227
mean_file: "/home/fei/DIGITS/digits/jobs/20180810-200238-65f4/mean.binaryproto"
}
data_param {
source: "/home/fei/DIGITS/digits/jobs/20180810-200238-65f4/train_db"
batch_size: 32
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
convolution_param {
num_output: 64
kernel_size: 3
stride: 2
weight_filler {
type: "xavier"
}
}
}
layer {
name: "relu_conv1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "pool1"
type: "Pooling"
bottom: "conv1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire2/squeeze1x1"
type: "Convolution"
bottom: "pool1"
top: "fire2/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_squeeze1x1"
type: "ReLU"
bottom: "fire2/squeeze1x1"
top: "fire2/squeeze1x1"
}
layer {
name: "fire2/expand1x1"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand1x1"
type: "ReLU"
bottom: "fire2/expand1x1"
top: "fire2/expand1x1"
}
layer {
name: "fire2/expand3x3"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand3x3"
type: "ReLU"
bottom: "fire2/expand3x3"
top: "fire2/expand3x3"
}
layer {
name: "fire2/concat"
type: "Concat"
bottom: "fire2/expand1x1"
bottom: "fire2/expand3x3"
top: "fire2/concat"
}
layer {
name: "fire3/squeeze1x1"
type: "Convolution"
bottom: "fire2/concat"
top: "fire3/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_squeeze1x1"
type: "ReLU"
bottom: "fire3/squeeze1x1"
top: "fire3/squeeze1x1"
}
layer {
name: "fire3/expand1x1"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand1x1"
type: "ReLU"
bottom: "fire3/expand1x1"
top: "fire3/expand1x1"
}
layer {
name: "fire3/expand3x3"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand3x3"
type: "ReLU"
bottom: "fire3/expand3x3"
top: "fire3/expand3x3"
}
layer {
name: "fire3/concat"
type: "Concat"
bottom: "fire3/expand1x1"
bottom: "fire3/expand3x3"
top: "fire3/concat"
}
layer {
name: "pool3"
type: "Pooling"
bottom: "fire3/concat"
top: "pool3"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire4/squeeze1x1"
type: "Convolution"
bottom: "pool3"
top: "fire4/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_squeeze1x1"
type: "ReLU"
bottom: "fire4/squeeze1x1"
top: "fire4/squeeze1x1"
}
layer {
name: "fire4/expand1x1"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand1x1"
type: "ReLU"
bottom: "fire4/expand1x1"
top: "fire4/expand1x1"
}
layer {
name: "fire4/expand3x3"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand3x3"
type: "ReLU"
bottom: "fire4/expand3x3"
top: "fire4/expand3x3"
}
layer {
name: "fire4/concat"
type: "Concat"
bottom: "fire4/expand1x1"
bottom: "fire4/expand3x3"
top: "fire4/concat"
}
layer {
name: "fire5/squeeze1x1"
type: "Convolution"
bottom: "fire4/concat"
top: "fire5/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_squeeze1x1"
type: "ReLU"
bottom: "fire5/squeeze1x1"
top: "fire5/squeeze1x1"
}
layer {
name: "fire5/expand1x1"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand1x1"
type: "ReLU"
bottom: "fire5/expand1x1"
top: "fire5/expand1x1"
}
layer {
name: "fire5/expand3x3"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand3x3"
type: "ReLU"
bottom: "fire5/expand3x3"
top: "fire5/expand3x3"
}
layer {
name: "fire5/concat"
type: "Concat"
bottom: "fire5/expand1x1"
bottom: "fire5/expand3x3"
top: "fire5/concat"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "fire5/concat"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire6/squeeze1x1"
type: "Convolution"
bottom: "pool5"
top: "fire6/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_squeeze1x1"
type: "ReLU"
bottom: "fire6/squeeze1x1"
top: "fire6/squeeze1x1"
}
layer {
name: "fire6/expand1x1"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand1x1"
type: "ReLU"
bottom: "fire6/expand1x1"
top: "fire6/expand1x1"
}
layer {
name: "fire6/expand3x3"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand3x3"
type: "ReLU"
bottom: "fire6/expand3x3"
top: "fire6/expand3x3"
}
layer {
name: "fire6/concat"
type: "Concat"
bottom: "fire6/expand1x1"
bottom: "fire6/expand3x3"
top: "fire6/concat"
}
layer {
name: "fire7/squeeze1x1"
type: "Convolution"
bottom: "fire6/concat"
top: "fire7/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_squeeze1x1"
type: "ReLU"
bottom: "fire7/squeeze1x1"
top: "fire7/squeeze1x1"
}
layer {
name: "fire7/expand1x1"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand1x1"
type: "ReLU"
bottom: "fire7/expand1x1"
top: "fire7/expand1x1"
}
layer {
name: "fire7/expand3x3"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand3x3"
type: "ReLU"
bottom: "fire7/expand3x3"
top: "fire7/expand3x3"
}
layer {
name: "fire7/concat"
type: "Concat"
bottom: "fire7/expand1x1"
bottom: "fire7/expand3x3"
top: "fire7/concat"
}
layer {
name: "fire8/squeeze1x1"
type: "Convolution"
bottom: "fire7/concat"
top: "fire8/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_squeeze1x1"
type: "ReLU"
bottom: "fire8/squeeze1x1"
top: "fire8/squeeze1x1"
}
layer {
name: "fire8/expand1x1"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand1x1"
type: "ReLU"
bottom: "fire8/expand1x1"
top: "fire8/expand1x1"
}
layer {
name: "fire8/expand3x3"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand3x3"
type: "ReLU"
bottom: "fire8/expand3x3"
top: "fire8/expand3x3"
}
layer {
name: "fire8/concat"
type: "Concat"
bottom: "fire8/expand1x1"
bottom: "fire8/expand3x3"
top: "fire8/concat"
}
layer {
name: "fire9/squeeze1x1"
type: "Convolution"
bottom: "fire8/concat"
top: "fire9/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_squeeze1x1"
type: "ReLU"
bottom: "fire9/squeeze1x1"
top: "fire9/squeeze1x1"
}
layer {
name: "fire9/expand1x1"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand1x1"
type: "ReLU"
bottom: "fire9/expand1x1"
top: "fire9/expand1x1"
}
layer {
name: "fire9/expand3x3"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand3x3"
type: "ReLU"
bottom: "fire9/expand3x3"
top: "fire9/expand3x3"
}
layer {
name: "fire9/concat"
type: "Concat"
bottom: "fire9/expand1x1"
bottom: "fire9/expand3x3"
top: "fire9/concat"
}
layer {
name: "drop9"
type: "Dropout"
bottom: "fire9/concat"
top: "fire9/concat"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "conv10"
type: "Convolution"
bottom: "fire9/concat"
top: "conv10"
convolution_param {
num_output: 1000
kernel_size: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
}
}
layer {
name: "relu_conv10"
type: "ReLU"
bottom: "conv10"
top: "conv10"
}
layer {
name: "pool10"
type: "Pooling"
bottom: "conv10"
top: "pool10"
pooling_param {
pool: AVE
global_pooling: true
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "pool10"
bottom: "label"
top: "loss"
}
I0811 03:32:40.880178 10215 layer_factory.hpp:77] Creating layer train-data
I0811 03:32:40.880254 10215 db_lmdb.cpp:35] Opened lmdb /home/fei/DIGITS/digits/jobs/20180810-200238-65f4/train_db
I0811 03:32:40.880277 10215 net.cpp:84] Creating Layer train-data
I0811 03:32:40.880282 10215 net.cpp:380] train-data -> data
I0811 03:32:40.880296 10215 net.cpp:380] train-data -> label
I0811 03:32:40.880304 10215 data_transformer.cpp:25] Loading mean file from: /home/fei/DIGITS/digits/jobs/20180810-200238-65f4/mean.binaryproto
I0811 03:32:40.884845 10215 data_layer.cpp:45] output data size: 32,3,227,227
I0811 03:32:40.913805 10215 net.cpp:122] Setting up train-data
I0811 03:32:40.913841 10215 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I0811 03:32:40.913846 10215 net.cpp:129] Top shape: 32 (32)
I0811 03:32:40.913848 10215 net.cpp:137] Memory required for data: 19787264
I0811 03:32:40.913856 10215 layer_factory.hpp:77] Creating layer conv1
I0811 03:32:40.913869 10215 net.cpp:84] Creating Layer conv1
I0811 03:32:40.913873 10215 net.cpp:406] conv1 <- data
I0811 03:32:40.913882 10215 net.cpp:380] conv1 -> conv1
I0811 03:32:40.915514 10215 net.cpp:122] Setting up conv1
I0811 03:32:40.915529 10215 net.cpp:129] Top shape: 32 64 113 113 (26150912)
I0811 03:32:40.915531 10215 net.cpp:137] Memory required for data: 124390912
I0811 03:32:40.915541 10215 layer_factory.hpp:77] Creating layer relu_conv1
I0811 03:32:40.915566 10215 net.cpp:84] Creating Layer relu_conv1
I0811 03:32:40.915570 10215 net.cpp:406] relu_conv1 <- conv1
I0811 03:32:40.915572 10215 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0811 03:32:40.915580 10215 net.cpp:122] Setting up relu_conv1
I0811 03:32:40.915582 10215 net.cpp:129] Top shape: 32 64 113 113 (26150912)
I0811 03:32:40.915585 10215 net.cpp:137] Memory required for data: 228994560
I0811 03:32:40.915586 10215 layer_factory.hpp:77] Creating layer pool1
I0811 03:32:40.915591 10215 net.cpp:84] Creating Layer pool1
I0811 03:32:40.915593 10215 net.cpp:406] pool1 <- conv1
I0811 03:32:40.915596 10215 net.cpp:380] pool1 -> pool1
I0811 03:32:40.915633 10215 net.cpp:122] Setting up pool1
I0811 03:32:40.915637 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.915639 10215 net.cpp:137] Memory required for data: 254684672
I0811 03:32:40.915642 10215 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I0811 03:32:40.915648 10215 net.cpp:84] Creating Layer fire2/squeeze1x1
I0811 03:32:40.915652 10215 net.cpp:406] fire2/squeeze1x1 <- pool1
I0811 03:32:40.915654 10215 net.cpp:380] fire2/squeeze1x1 -> fire2/squeeze1x1
I0811 03:32:40.916532 10215 net.cpp:122] Setting up fire2/squeeze1x1
I0811 03:32:40.916550 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.916553 10215 net.cpp:137] Memory required for data: 261107200
I0811 03:32:40.916560 10215 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I0811 03:32:40.916566 10215 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I0811 03:32:40.916569 10215 net.cpp:406] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I0811 03:32:40.916574 10215 net.cpp:367] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I0811 03:32:40.916579 10215 net.cpp:122] Setting up fire2/relu_squeeze1x1
I0811 03:32:40.916581 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.916584 10215 net.cpp:137] Memory required for data: 267529728
I0811 03:32:40.916585 10215 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0811 03:32:40.916589 10215 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0811 03:32:40.916591 10215 net.cpp:406] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I0811 03:32:40.916594 10215 net.cpp:380] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0811 03:32:40.916599 10215 net.cpp:380] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0811 03:32:40.916625 10215 net.cpp:122] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0811 03:32:40.916628 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.916630 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.916649 10215 net.cpp:137] Memory required for data: 280374784
I0811 03:32:40.916651 10215 layer_factory.hpp:77] Creating layer fire2/expand1x1
I0811 03:32:40.916657 10215 net.cpp:84] Creating Layer fire2/expand1x1
I0811 03:32:40.916659 10215 net.cpp:406] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0811 03:32:40.916663 10215 net.cpp:380] fire2/expand1x1 -> fire2/expand1x1
I0811 03:32:40.916841 10215 net.cpp:122] Setting up fire2/expand1x1
I0811 03:32:40.916844 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.916846 10215 net.cpp:137] Memory required for data: 306064896
I0811 03:32:40.916852 10215 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I0811 03:32:40.916857 10215 net.cpp:84] Creating Layer fire2/relu_expand1x1
I0811 03:32:40.916858 10215 net.cpp:406] fire2/relu_expand1x1 <- fire2/expand1x1
I0811 03:32:40.916862 10215 net.cpp:367] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I0811 03:32:40.916865 10215 net.cpp:122] Setting up fire2/relu_expand1x1
I0811 03:32:40.916867 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.916869 10215 net.cpp:137] Memory required for data: 331755008
I0811 03:32:40.916872 10215 layer_factory.hpp:77] Creating layer fire2/expand3x3
I0811 03:32:40.916875 10215 net.cpp:84] Creating Layer fire2/expand3x3
I0811 03:32:40.916877 10215 net.cpp:406] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0811 03:32:40.916882 10215 net.cpp:380] fire2/expand3x3 -> fire2/expand3x3
I0811 03:32:40.918648 10215 net.cpp:122] Setting up fire2/expand3x3
I0811 03:32:40.918660 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.918663 10215 net.cpp:137] Memory required for data: 357445120
I0811 03:32:40.918668 10215 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I0811 03:32:40.918673 10215 net.cpp:84] Creating Layer fire2/relu_expand3x3
I0811 03:32:40.918675 10215 net.cpp:406] fire2/relu_expand3x3 <- fire2/expand3x3
I0811 03:32:40.918678 10215 net.cpp:367] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I0811 03:32:40.918684 10215 net.cpp:122] Setting up fire2/relu_expand3x3
I0811 03:32:40.918686 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.918689 10215 net.cpp:137] Memory required for data: 383135232
I0811 03:32:40.918690 10215 layer_factory.hpp:77] Creating layer fire2/concat
I0811 03:32:40.918700 10215 net.cpp:84] Creating Layer fire2/concat
I0811 03:32:40.918702 10215 net.cpp:406] fire2/concat <- fire2/expand1x1
I0811 03:32:40.918705 10215 net.cpp:406] fire2/concat <- fire2/expand3x3
I0811 03:32:40.918709 10215 net.cpp:380] fire2/concat -> fire2/concat
I0811 03:32:40.918727 10215 net.cpp:122] Setting up fire2/concat
I0811 03:32:40.918731 10215 net.cpp:129] Top shape: 32 128 56 56 (12845056)
I0811 03:32:40.918732 10215 net.cpp:137] Memory required for data: 434515456
I0811 03:32:40.918735 10215 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I0811 03:32:40.918740 10215 net.cpp:84] Creating Layer fire3/squeeze1x1
I0811 03:32:40.918742 10215 net.cpp:406] fire3/squeeze1x1 <- fire2/concat
I0811 03:32:40.918745 10215 net.cpp:380] fire3/squeeze1x1 -> fire3/squeeze1x1
I0811 03:32:40.918903 10215 net.cpp:122] Setting up fire3/squeeze1x1
I0811 03:32:40.918910 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.918912 10215 net.cpp:137] Memory required for data: 440937984
I0811 03:32:40.918918 10215 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I0811 03:32:40.918922 10215 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I0811 03:32:40.918925 10215 net.cpp:406] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I0811 03:32:40.918927 10215 net.cpp:367] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I0811 03:32:40.918931 10215 net.cpp:122] Setting up fire3/relu_squeeze1x1
I0811 03:32:40.918934 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.918936 10215 net.cpp:137] Memory required for data: 447360512
I0811 03:32:40.918938 10215 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0811 03:32:40.918985 10215 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0811 03:32:40.918988 10215 net.cpp:406] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I0811 03:32:40.918992 10215 net.cpp:380] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0811 03:32:40.918995 10215 net.cpp:380] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0811 03:32:40.919019 10215 net.cpp:122] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0811 03:32:40.919023 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.919025 10215 net.cpp:129] Top shape: 32 16 56 56 (1605632)
I0811 03:32:40.919028 10215 net.cpp:137] Memory required for data: 460205568
I0811 03:32:40.919029 10215 layer_factory.hpp:77] Creating layer fire3/expand1x1
I0811 03:32:40.919034 10215 net.cpp:84] Creating Layer fire3/expand1x1
I0811 03:32:40.919036 10215 net.cpp:406] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0811 03:32:40.919039 10215 net.cpp:380] fire3/expand1x1 -> fire3/expand1x1
I0811 03:32:40.919184 10215 net.cpp:122] Setting up fire3/expand1x1
I0811 03:32:40.919189 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.919191 10215 net.cpp:137] Memory required for data: 485895680
I0811 03:32:40.919194 10215 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I0811 03:32:40.919199 10215 net.cpp:84] Creating Layer fire3/relu_expand1x1
I0811 03:32:40.919201 10215 net.cpp:406] fire3/relu_expand1x1 <- fire3/expand1x1
I0811 03:32:40.919204 10215 net.cpp:367] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I0811 03:32:40.919209 10215 net.cpp:122] Setting up fire3/relu_expand1x1
I0811 03:32:40.919210 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.919212 10215 net.cpp:137] Memory required for data: 511585792
I0811 03:32:40.919214 10215 layer_factory.hpp:77] Creating layer fire3/expand3x3
I0811 03:32:40.919219 10215 net.cpp:84] Creating Layer fire3/expand3x3
I0811 03:32:40.919221 10215 net.cpp:406] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0811 03:32:40.919224 10215 net.cpp:380] fire3/expand3x3 -> fire3/expand3x3
I0811 03:32:40.919416 10215 net.cpp:122] Setting up fire3/expand3x3
I0811 03:32:40.919422 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.919425 10215 net.cpp:137] Memory required for data: 537275904
I0811 03:32:40.919427 10215 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I0811 03:32:40.919430 10215 net.cpp:84] Creating Layer fire3/relu_expand3x3
I0811 03:32:40.919433 10215 net.cpp:406] fire3/relu_expand3x3 <- fire3/expand3x3
I0811 03:32:40.919435 10215 net.cpp:367] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I0811 03:32:40.919440 10215 net.cpp:122] Setting up fire3/relu_expand3x3
I0811 03:32:40.919442 10215 net.cpp:129] Top shape: 32 64 56 56 (6422528)
I0811 03:32:40.919445 10215 net.cpp:137] Memory required for data: 562966016
I0811 03:32:40.919446 10215 layer_factory.hpp:77] Creating layer fire3/concat
I0811 03:32:40.919466 10215 net.cpp:84] Creating Layer fire3/concat
I0811 03:32:40.919467 10215 net.cpp:406] fire3/concat <- fire3/expand1x1
I0811 03:32:40.919469 10215 net.cpp:406] fire3/concat <- fire3/expand3x3
I0811 03:32:40.919492 10215 net.cpp:380] fire3/concat -> fire3/concat
I0811 03:32:40.919504 10215 net.cpp:122] Setting up fire3/concat
I0811 03:32:40.919508 10215 net.cpp:129] Top shape: 32 128 56 56 (12845056)
I0811 03:32:40.919510 10215 net.cpp:137] Memory required for data: 614346240
I0811 03:32:40.919512 10215 layer_factory.hpp:77] Creating layer pool3
I0811 03:32:40.919517 10215 net.cpp:84] Creating Layer pool3
I0811 03:32:40.919518 10215 net.cpp:406] pool3 <- fire3/concat
I0811 03:32:40.919522 10215 net.cpp:380] pool3 -> pool3
I0811 03:32:40.919561 10215 net.cpp:122] Setting up pool3
I0811 03:32:40.919566 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.919570 10215 net.cpp:137] Memory required for data: 627191296
I0811 03:32:40.919572 10215 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I0811 03:32:40.919585 10215 net.cpp:84] Creating Layer fire4/squeeze1x1
I0811 03:32:40.919589 10215 net.cpp:406] fire4/squeeze1x1 <- pool3
I0811 03:32:40.919591 10215 net.cpp:380] fire4/squeeze1x1 -> fire4/squeeze1x1
I0811 03:32:40.919764 10215 net.cpp:122] Setting up fire4/squeeze1x1
I0811 03:32:40.919770 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.919772 10215 net.cpp:137] Memory required for data: 630402560
I0811 03:32:40.919776 10215 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I0811 03:32:40.919780 10215 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I0811 03:32:40.919781 10215 net.cpp:406] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I0811 03:32:40.919783 10215 net.cpp:367] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I0811 03:32:40.919787 10215 net.cpp:122] Setting up fire4/relu_squeeze1x1
I0811 03:32:40.919790 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.919791 10215 net.cpp:137] Memory required for data: 633613824
I0811 03:32:40.919793 10215 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0811 03:32:40.919796 10215 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0811 03:32:40.919798 10215 net.cpp:406] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I0811 03:32:40.919801 10215 net.cpp:380] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0811 03:32:40.919804 10215 net.cpp:380] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0811 03:32:40.919824 10215 net.cpp:122] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0811 03:32:40.919827 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.919831 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.919832 10215 net.cpp:137] Memory required for data: 640036352
I0811 03:32:40.919834 10215 layer_factory.hpp:77] Creating layer fire4/expand1x1
I0811 03:32:40.919838 10215 net.cpp:84] Creating Layer fire4/expand1x1
I0811 03:32:40.919840 10215 net.cpp:406] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0811 03:32:40.919843 10215 net.cpp:380] fire4/expand1x1 -> fire4/expand1x1
I0811 03:32:40.919998 10215 net.cpp:122] Setting up fire4/expand1x1
I0811 03:32:40.920002 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.920004 10215 net.cpp:137] Memory required for data: 652881408
I0811 03:32:40.920011 10215 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I0811 03:32:40.920013 10215 net.cpp:84] Creating Layer fire4/relu_expand1x1
I0811 03:32:40.920015 10215 net.cpp:406] fire4/relu_expand1x1 <- fire4/expand1x1
I0811 03:32:40.920018 10215 net.cpp:367] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I0811 03:32:40.920022 10215 net.cpp:122] Setting up fire4/relu_expand1x1
I0811 03:32:40.920024 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.920027 10215 net.cpp:137] Memory required for data: 665726464
I0811 03:32:40.920027 10215 layer_factory.hpp:77] Creating layer fire4/expand3x3
I0811 03:32:40.920032 10215 net.cpp:84] Creating Layer fire4/expand3x3
I0811 03:32:40.920033 10215 net.cpp:406] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0811 03:32:40.920037 10215 net.cpp:380] fire4/expand3x3 -> fire4/expand3x3
I0811 03:32:40.921058 10215 net.cpp:122] Setting up fire4/expand3x3
I0811 03:32:40.921070 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.921073 10215 net.cpp:137] Memory required for data: 678571520
I0811 03:32:40.921077 10215 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I0811 03:32:40.921082 10215 net.cpp:84] Creating Layer fire4/relu_expand3x3
I0811 03:32:40.921085 10215 net.cpp:406] fire4/relu_expand3x3 <- fire4/expand3x3
I0811 03:32:40.921089 10215 net.cpp:367] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I0811 03:32:40.921094 10215 net.cpp:122] Setting up fire4/relu_expand3x3
I0811 03:32:40.921097 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.921111 10215 net.cpp:137] Memory required for data: 691416576
I0811 03:32:40.921113 10215 layer_factory.hpp:77] Creating layer fire4/concat
I0811 03:32:40.921118 10215 net.cpp:84] Creating Layer fire4/concat
I0811 03:32:40.921119 10215 net.cpp:406] fire4/concat <- fire4/expand1x1
I0811 03:32:40.921123 10215 net.cpp:406] fire4/concat <- fire4/expand3x3
I0811 03:32:40.921125 10215 net.cpp:380] fire4/concat -> fire4/concat
I0811 03:32:40.921141 10215 net.cpp:122] Setting up fire4/concat
I0811 03:32:40.921144 10215 net.cpp:129] Top shape: 32 256 28 28 (6422528)
I0811 03:32:40.921146 10215 net.cpp:137] Memory required for data: 717106688
I0811 03:32:40.921149 10215 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I0811 03:32:40.921152 10215 net.cpp:84] Creating Layer fire5/squeeze1x1
I0811 03:32:40.921155 10215 net.cpp:406] fire5/squeeze1x1 <- fire4/concat
I0811 03:32:40.921159 10215 net.cpp:380] fire5/squeeze1x1 -> fire5/squeeze1x1
I0811 03:32:40.921344 10215 net.cpp:122] Setting up fire5/squeeze1x1
I0811 03:32:40.921349 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.921350 10215 net.cpp:137] Memory required for data: 720317952
I0811 03:32:40.921355 10215 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I0811 03:32:40.921357 10215 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I0811 03:32:40.921360 10215 net.cpp:406] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I0811 03:32:40.921362 10215 net.cpp:367] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I0811 03:32:40.921365 10215 net.cpp:122] Setting up fire5/relu_squeeze1x1
I0811 03:32:40.921368 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.921370 10215 net.cpp:137] Memory required for data: 723529216
I0811 03:32:40.921372 10215 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0811 03:32:40.921375 10215 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0811 03:32:40.921377 10215 net.cpp:406] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I0811 03:32:40.921380 10215 net.cpp:380] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0811 03:32:40.921383 10215 net.cpp:380] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0811 03:32:40.921403 10215 net.cpp:122] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0811 03:32:40.921406 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.921409 10215 net.cpp:129] Top shape: 32 32 28 28 (802816)
I0811 03:32:40.921411 10215 net.cpp:137] Memory required for data: 729951744
I0811 03:32:40.921413 10215 layer_factory.hpp:77] Creating layer fire5/expand1x1
I0811 03:32:40.921419 10215 net.cpp:84] Creating Layer fire5/expand1x1
I0811 03:32:40.921422 10215 net.cpp:406] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0811 03:32:40.921425 10215 net.cpp:380] fire5/expand1x1 -> fire5/expand1x1
I0811 03:32:40.921577 10215 net.cpp:122] Setting up fire5/expand1x1
I0811 03:32:40.921581 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.921583 10215 net.cpp:137] Memory required for data: 742796800
I0811 03:32:40.921586 10215 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I0811 03:32:40.921589 10215 net.cpp:84] Creating Layer fire5/relu_expand1x1
I0811 03:32:40.921591 10215 net.cpp:406] fire5/relu_expand1x1 <- fire5/expand1x1
I0811 03:32:40.921594 10215 net.cpp:367] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I0811 03:32:40.921597 10215 net.cpp:122] Setting up fire5/relu_expand1x1
I0811 03:32:40.921599 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.921602 10215 net.cpp:137] Memory required for data: 755641856
I0811 03:32:40.921604 10215 layer_factory.hpp:77] Creating layer fire5/expand3x3
I0811 03:32:40.921608 10215 net.cpp:84] Creating Layer fire5/expand3x3
I0811 03:32:40.921610 10215 net.cpp:406] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0811 03:32:40.921619 10215 net.cpp:380] fire5/expand3x3 -> fire5/expand3x3
I0811 03:32:40.921941 10215 net.cpp:122] Setting up fire5/expand3x3
I0811 03:32:40.921946 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.921947 10215 net.cpp:137] Memory required for data: 768486912
I0811 03:32:40.921952 10215 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I0811 03:32:40.921954 10215 net.cpp:84] Creating Layer fire5/relu_expand3x3
I0811 03:32:40.921957 10215 net.cpp:406] fire5/relu_expand3x3 <- fire5/expand3x3
I0811 03:32:40.921959 10215 net.cpp:367] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I0811 03:32:40.921962 10215 net.cpp:122] Setting up fire5/relu_expand3x3
I0811 03:32:40.921965 10215 net.cpp:129] Top shape: 32 128 28 28 (3211264)
I0811 03:32:40.921967 10215 net.cpp:137] Memory required for data: 781331968
I0811 03:32:40.921969 10215 layer_factory.hpp:77] Creating layer fire5/concat
I0811 03:32:40.921972 10215 net.cpp:84] Creating Layer fire5/concat
I0811 03:32:40.921974 10215 net.cpp:406] fire5/concat <- fire5/expand1x1
I0811 03:32:40.921977 10215 net.cpp:406] fire5/concat <- fire5/expand3x3
I0811 03:32:40.921979 10215 net.cpp:380] fire5/concat -> fire5/concat
I0811 03:32:40.921991 10215 net.cpp:122] Setting up fire5/concat
I0811 03:32:40.921995 10215 net.cpp:129] Top shape: 32 256 28 28 (6422528)
I0811 03:32:40.921996 10215 net.cpp:137] Memory required for data: 807022080
I0811 03:32:40.921999 10215 layer_factory.hpp:77] Creating layer pool5
I0811 03:32:40.922003 10215 net.cpp:84] Creating Layer pool5
I0811 03:32:40.922004 10215 net.cpp:406] pool5 <- fire5/concat
I0811 03:32:40.922008 10215 net.cpp:380] pool5 -> pool5
I0811 03:32:40.922027 10215 net.cpp:122] Setting up pool5
I0811 03:32:40.922031 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.922034 10215 net.cpp:137] Memory required for data: 813444608
I0811 03:32:40.922034 10215 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I0811 03:32:40.922039 10215 net.cpp:84] Creating Layer fire6/squeeze1x1
I0811 03:32:40.922040 10215 net.cpp:406] fire6/squeeze1x1 <- pool5
I0811 03:32:40.922044 10215 net.cpp:380] fire6/squeeze1x1 -> fire6/squeeze1x1
I0811 03:32:40.922271 10215 net.cpp:122] Setting up fire6/squeeze1x1
I0811 03:32:40.922274 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.922276 10215 net.cpp:137] Memory required for data: 814648832
I0811 03:32:40.922281 10215 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I0811 03:32:40.922283 10215 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I0811 03:32:40.922286 10215 net.cpp:406] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I0811 03:32:40.922288 10215 net.cpp:367] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I0811 03:32:40.922291 10215 net.cpp:122] Setting up fire6/relu_squeeze1x1
I0811 03:32:40.922294 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.922297 10215 net.cpp:137] Memory required for data: 815853056
I0811 03:32:40.922298 10215 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0811 03:32:40.922302 10215 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0811 03:32:40.922303 10215 net.cpp:406] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I0811 03:32:40.922307 10215 net.cpp:380] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0811 03:32:40.922309 10215 net.cpp:380] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0811 03:32:40.922339 10215 net.cpp:122] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0811 03:32:40.922343 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.922346 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.922348 10215 net.cpp:137] Memory required for data: 818261504
I0811 03:32:40.922349 10215 layer_factory.hpp:77] Creating layer fire6/expand1x1
I0811 03:32:40.922354 10215 net.cpp:84] Creating Layer fire6/expand1x1
I0811 03:32:40.922356 10215 net.cpp:406] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0811 03:32:40.922365 10215 net.cpp:380] fire6/expand1x1 -> fire6/expand1x1
I0811 03:32:40.922605 10215 net.cpp:122] Setting up fire6/expand1x1
I0811 03:32:40.922610 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.922612 10215 net.cpp:137] Memory required for data: 823078400
I0811 03:32:40.922616 10215 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I0811 03:32:40.922632 10215 net.cpp:84] Creating Layer fire6/relu_expand1x1
I0811 03:32:40.922634 10215 net.cpp:406] fire6/relu_expand1x1 <- fire6/expand1x1
I0811 03:32:40.922637 10215 net.cpp:367] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I0811 03:32:40.922641 10215 net.cpp:122] Setting up fire6/relu_expand1x1
I0811 03:32:40.922643 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.922646 10215 net.cpp:137] Memory required for data: 827895296
I0811 03:32:40.922647 10215 layer_factory.hpp:77] Creating layer fire6/expand3x3
I0811 03:32:40.922652 10215 net.cpp:84] Creating Layer fire6/expand3x3
I0811 03:32:40.922653 10215 net.cpp:406] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0811 03:32:40.922657 10215 net.cpp:380] fire6/expand3x3 -> fire6/expand3x3
I0811 03:32:40.923261 10215 net.cpp:122] Setting up fire6/expand3x3
I0811 03:32:40.923266 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.923267 10215 net.cpp:137] Memory required for data: 832712192
I0811 03:32:40.923271 10215 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I0811 03:32:40.923292 10215 net.cpp:84] Creating Layer fire6/relu_expand3x3
I0811 03:32:40.923295 10215 net.cpp:406] fire6/relu_expand3x3 <- fire6/expand3x3
I0811 03:32:40.923297 10215 net.cpp:367] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I0811 03:32:40.923301 10215 net.cpp:122] Setting up fire6/relu_expand3x3
I0811 03:32:40.923305 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.923305 10215 net.cpp:137] Memory required for data: 837529088
I0811 03:32:40.923307 10215 layer_factory.hpp:77] Creating layer fire6/concat
I0811 03:32:40.923311 10215 net.cpp:84] Creating Layer fire6/concat
I0811 03:32:40.923313 10215 net.cpp:406] fire6/concat <- fire6/expand1x1
I0811 03:32:40.923316 10215 net.cpp:406] fire6/concat <- fire6/expand3x3
I0811 03:32:40.923318 10215 net.cpp:380] fire6/concat -> fire6/concat
I0811 03:32:40.923344 10215 net.cpp:122] Setting up fire6/concat
I0811 03:32:40.923347 10215 net.cpp:129] Top shape: 32 384 14 14 (2408448)
I0811 03:32:40.923349 10215 net.cpp:137] Memory required for data: 847162880
I0811 03:32:40.923352 10215 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I0811 03:32:40.923355 10215 net.cpp:84] Creating Layer fire7/squeeze1x1
I0811 03:32:40.923357 10215 net.cpp:406] fire7/squeeze1x1 <- fire6/concat
I0811 03:32:40.923360 10215 net.cpp:380] fire7/squeeze1x1 -> fire7/squeeze1x1
I0811 03:32:40.923596 10215 net.cpp:122] Setting up fire7/squeeze1x1
I0811 03:32:40.923600 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.923602 10215 net.cpp:137] Memory required for data: 848367104
I0811 03:32:40.923609 10215 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I0811 03:32:40.923612 10215 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I0811 03:32:40.923614 10215 net.cpp:406] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I0811 03:32:40.923617 10215 net.cpp:367] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I0811 03:32:40.923621 10215 net.cpp:122] Setting up fire7/relu_squeeze1x1
I0811 03:32:40.923624 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.923625 10215 net.cpp:137] Memory required for data: 849571328
I0811 03:32:40.923627 10215 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0811 03:32:40.923630 10215 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0811 03:32:40.923632 10215 net.cpp:406] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I0811 03:32:40.923635 10215 net.cpp:380] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0811 03:32:40.923645 10215 net.cpp:380] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0811 03:32:40.923668 10215 net.cpp:122] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0811 03:32:40.923671 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.923674 10215 net.cpp:129] Top shape: 32 48 14 14 (301056)
I0811 03:32:40.923676 10215 net.cpp:137] Memory required for data: 851979776
I0811 03:32:40.923678 10215 layer_factory.hpp:77] Creating layer fire7/expand1x1
I0811 03:32:40.923682 10215 net.cpp:84] Creating Layer fire7/expand1x1
I0811 03:32:40.923684 10215 net.cpp:406] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0811 03:32:40.923687 10215 net.cpp:380] fire7/expand1x1 -> fire7/expand1x1
I0811 03:32:40.923868 10215 net.cpp:122] Setting up fire7/expand1x1
I0811 03:32:40.923872 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.923874 10215 net.cpp:137] Memory required for data: 856796672
I0811 03:32:40.923878 10215 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I0811 03:32:40.923882 10215 net.cpp:84] Creating Layer fire7/relu_expand1x1
I0811 03:32:40.923883 10215 net.cpp:406] fire7/relu_expand1x1 <- fire7/expand1x1
I0811 03:32:40.923885 10215 net.cpp:367] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I0811 03:32:40.923888 10215 net.cpp:122] Setting up fire7/relu_expand1x1
I0811 03:32:40.923892 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.923893 10215 net.cpp:137] Memory required for data: 861613568
I0811 03:32:40.923895 10215 layer_factory.hpp:77] Creating layer fire7/expand3x3
I0811 03:32:40.923899 10215 net.cpp:84] Creating Layer fire7/expand3x3
I0811 03:32:40.923902 10215 net.cpp:406] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0811 03:32:40.923904 10215 net.cpp:380] fire7/expand3x3 -> fire7/expand3x3
I0811 03:32:40.924469 10215 net.cpp:122] Setting up fire7/expand3x3
I0811 03:32:40.924473 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.924474 10215 net.cpp:137] Memory required for data: 866430464
I0811 03:32:40.924479 10215 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I0811 03:32:40.924481 10215 net.cpp:84] Creating Layer fire7/relu_expand3x3
I0811 03:32:40.924484 10215 net.cpp:406] fire7/relu_expand3x3 <- fire7/expand3x3
I0811 03:32:40.924486 10215 net.cpp:367] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I0811 03:32:40.924489 10215 net.cpp:122] Setting up fire7/relu_expand3x3
I0811 03:32:40.924492 10215 net.cpp:129] Top shape: 32 192 14 14 (1204224)
I0811 03:32:40.924494 10215 net.cpp:137] Memory required for data: 871247360
I0811 03:32:40.924496 10215 layer_factory.hpp:77] Creating layer fire7/concat
I0811 03:32:40.924499 10215 net.cpp:84] Creating Layer fire7/concat
I0811 03:32:40.924501 10215 net.cpp:406] fire7/concat <- fire7/expand1x1
I0811 03:32:40.924504 10215 net.cpp:406] fire7/concat <- fire7/expand3x3
I0811 03:32:40.924506 10215 net.cpp:380] fire7/concat -> fire7/concat
I0811 03:32:40.924518 10215 net.cpp:122] Setting up fire7/concat
I0811 03:32:40.924522 10215 net.cpp:129] Top shape: 32 384 14 14 (2408448)
I0811 03:32:40.924523 10215 net.cpp:137] Memory required for data: 880881152
I0811 03:32:40.924525 10215 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I0811 03:32:40.924530 10215 net.cpp:84] Creating Layer fire8/squeeze1x1
I0811 03:32:40.924531 10215 net.cpp:406] fire8/squeeze1x1 <- fire7/concat
I0811 03:32:40.924535 10215 net.cpp:380] fire8/squeeze1x1 -> fire8/squeeze1x1
I0811 03:32:40.924795 10215 net.cpp:122] Setting up fire8/squeeze1x1
I0811 03:32:40.924799 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.924801 10215 net.cpp:137] Memory required for data: 882486784
I0811 03:32:40.924804 10215 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I0811 03:32:40.924808 10215 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I0811 03:32:40.924809 10215 net.cpp:406] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I0811 03:32:40.924818 10215 net.cpp:367] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I0811 03:32:40.924820 10215 net.cpp:122] Setting up fire8/relu_squeeze1x1
I0811 03:32:40.924823 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.924825 10215 net.cpp:137] Memory required for data: 884092416
I0811 03:32:40.924827 10215 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0811 03:32:40.924830 10215 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0811 03:32:40.924831 10215 net.cpp:406] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I0811 03:32:40.924834 10215 net.cpp:380] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0811 03:32:40.924839 10215 net.cpp:380] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0811 03:32:40.924860 10215 net.cpp:122] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0811 03:32:40.924862 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.924865 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.924867 10215 net.cpp:137] Memory required for data: 887303680
I0811 03:32:40.924870 10215 layer_factory.hpp:77] Creating layer fire8/expand1x1
I0811 03:32:40.924872 10215 net.cpp:84] Creating Layer fire8/expand1x1
I0811 03:32:40.924875 10215 net.cpp:406] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0811 03:32:40.924877 10215 net.cpp:380] fire8/expand1x1 -> fire8/expand1x1
I0811 03:32:40.925097 10215 net.cpp:122] Setting up fire8/expand1x1
I0811 03:32:40.925101 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.925102 10215 net.cpp:137] Memory required for data: 893726208
I0811 03:32:40.925107 10215 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I0811 03:32:40.925109 10215 net.cpp:84] Creating Layer fire8/relu_expand1x1
I0811 03:32:40.925112 10215 net.cpp:406] fire8/relu_expand1x1 <- fire8/expand1x1
I0811 03:32:40.925113 10215 net.cpp:367] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I0811 03:32:40.925117 10215 net.cpp:122] Setting up fire8/relu_expand1x1
I0811 03:32:40.925119 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.925122 10215 net.cpp:137] Memory required for data: 900148736
I0811 03:32:40.925123 10215 layer_factory.hpp:77] Creating layer fire8/expand3x3
I0811 03:32:40.925127 10215 net.cpp:84] Creating Layer fire8/expand3x3
I0811 03:32:40.925129 10215 net.cpp:406] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0811 03:32:40.925132 10215 net.cpp:380] fire8/expand3x3 -> fire8/expand3x3
I0811 03:32:40.926028 10215 net.cpp:122] Setting up fire8/expand3x3
I0811 03:32:40.926033 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.926034 10215 net.cpp:137] Memory required for data: 906571264
I0811 03:32:40.926038 10215 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I0811 03:32:40.926040 10215 net.cpp:84] Creating Layer fire8/relu_expand3x3
I0811 03:32:40.926043 10215 net.cpp:406] fire8/relu_expand3x3 <- fire8/expand3x3
I0811 03:32:40.926045 10215 net.cpp:367] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I0811 03:32:40.926048 10215 net.cpp:122] Setting up fire8/relu_expand3x3
I0811 03:32:40.926051 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.926054 10215 net.cpp:137] Memory required for data: 912993792
I0811 03:32:40.926055 10215 layer_factory.hpp:77] Creating layer fire8/concat
I0811 03:32:40.926059 10215 net.cpp:84] Creating Layer fire8/concat
I0811 03:32:40.926060 10215 net.cpp:406] fire8/concat <- fire8/expand1x1
I0811 03:32:40.926062 10215 net.cpp:406] fire8/concat <- fire8/expand3x3
I0811 03:32:40.926065 10215 net.cpp:380] fire8/concat -> fire8/concat
I0811 03:32:40.926079 10215 net.cpp:122] Setting up fire8/concat
I0811 03:32:40.926082 10215 net.cpp:129] Top shape: 32 512 14 14 (3211264)
I0811 03:32:40.926084 10215 net.cpp:137] Memory required for data: 925838848
I0811 03:32:40.926091 10215 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I0811 03:32:40.926095 10215 net.cpp:84] Creating Layer fire9/squeeze1x1
I0811 03:32:40.926097 10215 net.cpp:406] fire9/squeeze1x1 <- fire8/concat
I0811 03:32:40.926100 10215 net.cpp:380] fire9/squeeze1x1 -> fire9/squeeze1x1
I0811 03:32:40.926404 10215 net.cpp:122] Setting up fire9/squeeze1x1
I0811 03:32:40.926409 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.926410 10215 net.cpp:137] Memory required for data: 927444480
I0811 03:32:40.926414 10215 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I0811 03:32:40.926417 10215 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I0811 03:32:40.926419 10215 net.cpp:406] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I0811 03:32:40.926421 10215 net.cpp:367] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I0811 03:32:40.926424 10215 net.cpp:122] Setting up fire9/relu_squeeze1x1
I0811 03:32:40.926427 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.926429 10215 net.cpp:137] Memory required for data: 929050112
I0811 03:32:40.926431 10215 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0811 03:32:40.926437 10215 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0811 03:32:40.926440 10215 net.cpp:406] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I0811 03:32:40.926443 10215 net.cpp:380] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0811 03:32:40.926446 10215 net.cpp:380] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0811 03:32:40.926467 10215 net.cpp:122] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0811 03:32:40.926470 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.926473 10215 net.cpp:129] Top shape: 32 64 14 14 (401408)
I0811 03:32:40.926476 10215 net.cpp:137] Memory required for data: 932261376
I0811 03:32:40.926477 10215 layer_factory.hpp:77] Creating layer fire9/expand1x1
I0811 03:32:40.926481 10215 net.cpp:84] Creating Layer fire9/expand1x1
I0811 03:32:40.926483 10215 net.cpp:406] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0811 03:32:40.926486 10215 net.cpp:380] fire9/expand1x1 -> fire9/expand1x1
I0811 03:32:40.926708 10215 net.cpp:122] Setting up fire9/expand1x1
I0811 03:32:40.926713 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.926715 10215 net.cpp:137] Memory required for data: 938683904
I0811 03:32:40.926719 10215 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I0811 03:32:40.926723 10215 net.cpp:84] Creating Layer fire9/relu_expand1x1
I0811 03:32:40.926724 10215 net.cpp:406] fire9/relu_expand1x1 <- fire9/expand1x1
I0811 03:32:40.926728 10215 net.cpp:367] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I0811 03:32:40.926730 10215 net.cpp:122] Setting up fire9/relu_expand1x1
I0811 03:32:40.926733 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.926734 10215 net.cpp:137] Memory required for data: 945106432
I0811 03:32:40.926736 10215 layer_factory.hpp:77] Creating layer fire9/expand3x3
I0811 03:32:40.926740 10215 net.cpp:84] Creating Layer fire9/expand3x3
I0811 03:32:40.926743 10215 net.cpp:406] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0811 03:32:40.926746 10215 net.cpp:380] fire9/expand3x3 -> fire9/expand3x3
I0811 03:32:40.928270 10215 net.cpp:122] Setting up fire9/expand3x3
I0811 03:32:40.928278 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.928280 10215 net.cpp:137] Memory required for data: 951528960
I0811 03:32:40.928284 10215 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I0811 03:32:40.928288 10215 net.cpp:84] Creating Layer fire9/relu_expand3x3
I0811 03:32:40.928292 10215 net.cpp:406] fire9/relu_expand3x3 <- fire9/expand3x3
I0811 03:32:40.928294 10215 net.cpp:367] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I0811 03:32:40.928298 10215 net.cpp:122] Setting up fire9/relu_expand3x3
I0811 03:32:40.928310 10215 net.cpp:129] Top shape: 32 256 14 14 (1605632)
I0811 03:32:40.928313 10215 net.cpp:137] Memory required for data: 957951488
I0811 03:32:40.928314 10215 layer_factory.hpp:77] Creating layer fire9/concat
I0811 03:32:40.928318 10215 net.cpp:84] Creating Layer fire9/concat
I0811 03:32:40.928320 10215 net.cpp:406] fire9/concat <- fire9/expand1x1
I0811 03:32:40.928323 10215 net.cpp:406] fire9/concat <- fire9/expand3x3
I0811 03:32:40.928325 10215 net.cpp:380] fire9/concat -> fire9/concat
I0811 03:32:40.928342 10215 net.cpp:122] Setting up fire9/concat
I0811 03:32:40.928347 10215 net.cpp:129] Top shape: 32 512 14 14 (3211264)
I0811 03:32:40.928349 10215 net.cpp:137] Memory required for data: 970796544
I0811 03:32:40.928351 10215 layer_factory.hpp:77] Creating layer drop9
I0811 03:32:40.928355 10215 net.cpp:84] Creating Layer drop9
I0811 03:32:40.928357 10215 net.cpp:406] drop9 <- fire9/concat
I0811 03:32:40.928360 10215 net.cpp:367] drop9 -> fire9/concat (in-place)
I0811 03:32:40.928377 10215 net.cpp:122] Setting up drop9
I0811 03:32:40.928380 10215 net.cpp:129] Top shape: 32 512 14 14 (3211264)
I0811 03:32:40.928382 10215 net.cpp:137] Memory required for data: 983641600
I0811 03:32:40.928385 10215 layer_factory.hpp:77] Creating layer conv10
I0811 03:32:40.928388 10215 net.cpp:84] Creating Layer conv10
I0811 03:32:40.928390 10215 net.cpp:406] conv10 <- fire9/concat
I0811 03:32:40.928393 10215 net.cpp:380] conv10 -> conv10
I0811 03:32:40.941687 10215 net.cpp:122] Setting up conv10
I0811 03:32:40.941704 10215 net.cpp:129] Top shape: 32 1000 14 14 (6272000)
I0811 03:32:40.941707 10215 net.cpp:137] Memory required for data: 1008729600
I0811 03:32:40.941712 10215 layer_factory.hpp:77] Creating layer relu_conv10
I0811 03:32:40.941720 10215 net.cpp:84] Creating Layer relu_conv10
I0811 03:32:40.941721 10215 net.cpp:406] relu_conv10 <- conv10
I0811 03:32:40.941725 10215 net.cpp:367] relu_conv10 -> conv10 (in-place)
I0811 03:32:40.941731 10215 net.cpp:122] Setting up relu_conv10
I0811 03:32:40.941735 10215 net.cpp:129] Top shape: 32 1000 14 14 (6272000)
I0811 03:32:40.941736 10215 net.cpp:137] Memory required for data: 1033817600
I0811 03:32:40.941737 10215 layer_factory.hpp:77] Creating layer pool10
I0811 03:32:40.941741 10215 net.cpp:84] Creating Layer pool10
I0811 03:32:40.941743 10215 net.cpp:406] pool10 <- conv10
I0811 03:32:40.941747 10215 net.cpp:380] pool10 -> pool10
I0811 03:32:40.941769 10215 net.cpp:122] Setting up pool10
I0811 03:32:40.941772 10215 net.cpp:129] Top shape: 32 1000 1 1 (32000)
I0811 03:32:40.941774 10215 net.cpp:137] Memory required for data: 1033945600
I0811 03:32:40.941776 10215 layer_factory.hpp:77] Creating layer loss
I0811 03:32:40.941787 10215 net.cpp:84] Creating Layer loss
I0811 03:32:40.941788 10215 net.cpp:406] loss <- pool10
I0811 03:32:40.941790 10215 net.cpp:406] loss <- label
I0811 03:32:40.941795 10215 net.cpp:380] loss -> loss
I0811 03:32:40.941807 10215 layer_factory.hpp:77] Creating layer loss
I0811 03:32:40.941887 10215 net.cpp:122] Setting up loss
I0811 03:32:40.941890 10215 net.cpp:129] Top shape: (1)
I0811 03:32:40.941892 10215 net.cpp:132]     with loss weight 1
I0811 03:32:40.941906 10215 net.cpp:137] Memory required for data: 1033945604
I0811 03:32:40.941908 10215 net.cpp:198] loss needs backward computation.
I0811 03:32:40.941911 10215 net.cpp:198] pool10 needs backward computation.
I0811 03:32:40.941913 10215 net.cpp:198] relu_conv10 needs backward computation.
I0811 03:32:40.941915 10215 net.cpp:198] conv10 needs backward computation.
I0811 03:32:40.941917 10215 net.cpp:198] drop9 needs backward computation.
I0811 03:32:40.941920 10215 net.cpp:198] fire9/concat needs backward computation.
I0811 03:32:40.941921 10215 net.cpp:198] fire9/relu_expand3x3 needs backward computation.
I0811 03:32:40.941923 10215 net.cpp:198] fire9/expand3x3 needs backward computation.
I0811 03:32:40.941926 10215 net.cpp:198] fire9/relu_expand1x1 needs backward computation.
I0811 03:32:40.941928 10215 net.cpp:198] fire9/expand1x1 needs backward computation.
I0811 03:32:40.941931 10215 net.cpp:198] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.941947 10215 net.cpp:198] fire9/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.941949 10215 net.cpp:198] fire9/squeeze1x1 needs backward computation.
I0811 03:32:40.941952 10215 net.cpp:198] fire8/concat needs backward computation.
I0811 03:32:40.941954 10215 net.cpp:198] fire8/relu_expand3x3 needs backward computation.
I0811 03:32:40.941956 10215 net.cpp:198] fire8/expand3x3 needs backward computation.
I0811 03:32:40.941958 10215 net.cpp:198] fire8/relu_expand1x1 needs backward computation.
I0811 03:32:40.941960 10215 net.cpp:198] fire8/expand1x1 needs backward computation.
I0811 03:32:40.941962 10215 net.cpp:198] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.941965 10215 net.cpp:198] fire8/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.941967 10215 net.cpp:198] fire8/squeeze1x1 needs backward computation.
I0811 03:32:40.941969 10215 net.cpp:198] fire7/concat needs backward computation.
I0811 03:32:40.941972 10215 net.cpp:198] fire7/relu_expand3x3 needs backward computation.
I0811 03:32:40.941973 10215 net.cpp:198] fire7/expand3x3 needs backward computation.
I0811 03:32:40.941975 10215 net.cpp:198] fire7/relu_expand1x1 needs backward computation.
I0811 03:32:40.941977 10215 net.cpp:198] fire7/expand1x1 needs backward computation.
I0811 03:32:40.941979 10215 net.cpp:198] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.941982 10215 net.cpp:198] fire7/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.941983 10215 net.cpp:198] fire7/squeeze1x1 needs backward computation.
I0811 03:32:40.941987 10215 net.cpp:198] fire6/concat needs backward computation.
I0811 03:32:40.941988 10215 net.cpp:198] fire6/relu_expand3x3 needs backward computation.
I0811 03:32:40.941990 10215 net.cpp:198] fire6/expand3x3 needs backward computation.
I0811 03:32:40.941992 10215 net.cpp:198] fire6/relu_expand1x1 needs backward computation.
I0811 03:32:40.941994 10215 net.cpp:198] fire6/expand1x1 needs backward computation.
I0811 03:32:40.941996 10215 net.cpp:198] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.941998 10215 net.cpp:198] fire6/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.942000 10215 net.cpp:198] fire6/squeeze1x1 needs backward computation.
I0811 03:32:40.942003 10215 net.cpp:198] pool5 needs backward computation.
I0811 03:32:40.942004 10215 net.cpp:198] fire5/concat needs backward computation.
I0811 03:32:40.942006 10215 net.cpp:198] fire5/relu_expand3x3 needs backward computation.
I0811 03:32:40.942008 10215 net.cpp:198] fire5/expand3x3 needs backward computation.
I0811 03:32:40.942010 10215 net.cpp:198] fire5/relu_expand1x1 needs backward computation.
I0811 03:32:40.942013 10215 net.cpp:198] fire5/expand1x1 needs backward computation.
I0811 03:32:40.942014 10215 net.cpp:198] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.942016 10215 net.cpp:198] fire5/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.942018 10215 net.cpp:198] fire5/squeeze1x1 needs backward computation.
I0811 03:32:40.942020 10215 net.cpp:198] fire4/concat needs backward computation.
I0811 03:32:40.942023 10215 net.cpp:198] fire4/relu_expand3x3 needs backward computation.
I0811 03:32:40.942024 10215 net.cpp:198] fire4/expand3x3 needs backward computation.
I0811 03:32:40.942026 10215 net.cpp:198] fire4/relu_expand1x1 needs backward computation.
I0811 03:32:40.942028 10215 net.cpp:198] fire4/expand1x1 needs backward computation.
I0811 03:32:40.942031 10215 net.cpp:198] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.942034 10215 net.cpp:198] fire4/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.942035 10215 net.cpp:198] fire4/squeeze1x1 needs backward computation.
I0811 03:32:40.942037 10215 net.cpp:198] pool3 needs backward computation.
I0811 03:32:40.942039 10215 net.cpp:198] fire3/concat needs backward computation.
I0811 03:32:40.942045 10215 net.cpp:198] fire3/relu_expand3x3 needs backward computation.
I0811 03:32:40.942047 10215 net.cpp:198] fire3/expand3x3 needs backward computation.
I0811 03:32:40.942049 10215 net.cpp:198] fire3/relu_expand1x1 needs backward computation.
I0811 03:32:40.942051 10215 net.cpp:198] fire3/expand1x1 needs backward computation.
I0811 03:32:40.942054 10215 net.cpp:198] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.942055 10215 net.cpp:198] fire3/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.942057 10215 net.cpp:198] fire3/squeeze1x1 needs backward computation.
I0811 03:32:40.942059 10215 net.cpp:198] fire2/concat needs backward computation.
I0811 03:32:40.942061 10215 net.cpp:198] fire2/relu_expand3x3 needs backward computation.
I0811 03:32:40.942064 10215 net.cpp:198] fire2/expand3x3 needs backward computation.
I0811 03:32:40.942065 10215 net.cpp:198] fire2/relu_expand1x1 needs backward computation.
I0811 03:32:40.942067 10215 net.cpp:198] fire2/expand1x1 needs backward computation.
I0811 03:32:40.942070 10215 net.cpp:198] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.942071 10215 net.cpp:198] fire2/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.942073 10215 net.cpp:198] fire2/squeeze1x1 needs backward computation.
I0811 03:32:40.942075 10215 net.cpp:198] pool1 needs backward computation.
I0811 03:32:40.942077 10215 net.cpp:198] relu_conv1 needs backward computation.
I0811 03:32:40.942080 10215 net.cpp:198] conv1 needs backward computation.
I0811 03:32:40.942082 10215 net.cpp:200] train-data does not need backward computation.
I0811 03:32:40.942083 10215 net.cpp:242] This network produces output loss
I0811 03:32:40.942113 10215 net.cpp:255] Network initialization done.
I0811 03:32:40.942869 10215 solver.cpp:190] Creating test net (#0) specified by net file: train_val.prototxt
I0811 03:32:40.942915 10215 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I0811 03:32:40.943087 10215 net.cpp:51] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 227
mean_file: "/home/fei/DIGITS/digits/jobs/20180810-200238-65f4/mean.binaryproto"
}
data_param {
source: "/home/fei/DIGITS/digits/jobs/20180810-200238-65f4/val_db"
batch_size: 25
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
convolution_param {
num_output: 64
kernel_size: 3
stride: 2
weight_filler {
type: "xavier"
}
}
}
layer {
name: "relu_conv1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "pool1"
type: "Pooling"
bottom: "conv1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire2/squeeze1x1"
type: "Convolution"
bottom: "pool1"
top: "fire2/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_squeeze1x1"
type: "ReLU"
bottom: "fire2/squeeze1x1"
top: "fire2/squeeze1x1"
}
layer {
name: "fire2/expand1x1"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand1x1"
type: "ReLU"
bottom: "fire2/expand1x1"
top: "fire2/expand1x1"
}
layer {
name: "fire2/expand3x3"
type: "Convolution"
bottom: "fire2/squeeze1x1"
top: "fire2/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire2/relu_expand3x3"
type: "ReLU"
bottom: "fire2/expand3x3"
top: "fire2/expand3x3"
}
layer {
name: "fire2/concat"
type: "Concat"
bottom: "fire2/expand1x1"
bottom: "fire2/expand3x3"
top: "fire2/concat"
}
layer {
name: "fire3/squeeze1x1"
type: "Convolution"
bottom: "fire2/concat"
top: "fire3/squeeze1x1"
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_squeeze1x1"
type: "ReLU"
bottom: "fire3/squeeze1x1"
top: "fire3/squeeze1x1"
}
layer {
name: "fire3/expand1x1"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand1x1"
type: "ReLU"
bottom: "fire3/expand1x1"
top: "fire3/expand1x1"
}
layer {
name: "fire3/expand3x3"
type: "Convolution"
bottom: "fire3/squeeze1x1"
top: "fire3/expand3x3"
convolution_param {
num_output: 64
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire3/relu_expand3x3"
type: "ReLU"
bottom: "fire3/expand3x3"
top: "fire3/expand3x3"
}
layer {
name: "fire3/concat"
type: "Concat"
bottom: "fire3/expand1x1"
bottom: "fire3/expand3x3"
top: "fire3/concat"
}
layer {
name: "pool3"
type: "Pooling"
bottom: "fire3/concat"
top: "pool3"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire4/squeeze1x1"
type: "Convolution"
bottom: "pool3"
top: "fire4/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_squeeze1x1"
type: "ReLU"
bottom: "fire4/squeeze1x1"
top: "fire4/squeeze1x1"
}
layer {
name: "fire4/expand1x1"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand1x1"
type: "ReLU"
bottom: "fire4/expand1x1"
top: "fire4/expand1x1"
}
layer {
name: "fire4/expand3x3"
type: "Convolution"
bottom: "fire4/squeeze1x1"
top: "fire4/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire4/relu_expand3x3"
type: "ReLU"
bottom: "fire4/expand3x3"
top: "fire4/expand3x3"
}
layer {
name: "fire4/concat"
type: "Concat"
bottom: "fire4/expand1x1"
bottom: "fire4/expand3x3"
top: "fire4/concat"
}
layer {
name: "fire5/squeeze1x1"
type: "Convolution"
bottom: "fire4/concat"
top: "fire5/squeeze1x1"
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_squeeze1x1"
type: "ReLU"
bottom: "fire5/squeeze1x1"
top: "fire5/squeeze1x1"
}
layer {
name: "fire5/expand1x1"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand1x1"
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand1x1"
type: "ReLU"
bottom: "fire5/expand1x1"
top: "fire5/expand1x1"
}
layer {
name: "fire5/expand3x3"
type: "Convolution"
bottom: "fire5/squeeze1x1"
top: "fire5/expand3x3"
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire5/relu_expand3x3"
type: "ReLU"
bottom: "fire5/expand3x3"
top: "fire5/expand3x3"
}
layer {
name: "fire5/concat"
type: "Concat"
bottom: "fire5/expand1x1"
bottom: "fire5/expand3x3"
top: "fire5/concat"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "fire5/concat"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fire6/squeeze1x1"
type: "Convolution"
bottom: "pool5"
top: "fire6/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_squeeze1x1"
type: "ReLU"
bottom: "fire6/squeeze1x1"
top: "fire6/squeeze1x1"
}
layer {
name: "fire6/expand1x1"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand1x1"
type: "ReLU"
bottom: "fire6/expand1x1"
top: "fire6/expand1x1"
}
layer {
name: "fire6/expand3x3"
type: "Convolution"
bottom: "fire6/squeeze1x1"
top: "fire6/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire6/relu_expand3x3"
type: "ReLU"
bottom: "fire6/expand3x3"
top: "fire6/expand3x3"
}
layer {
name: "fire6/concat"
type: "Concat"
bottom: "fire6/expand1x1"
bottom: "fire6/expand3x3"
top: "fire6/concat"
}
layer {
name: "fire7/squeeze1x1"
type: "Convolution"
bottom: "fire6/concat"
top: "fire7/squeeze1x1"
convolution_param {
num_output: 48
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_squeeze1x1"
type: "ReLU"
bottom: "fire7/squeeze1x1"
top: "fire7/squeeze1x1"
}
layer {
name: "fire7/expand1x1"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand1x1"
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand1x1"
type: "ReLU"
bottom: "fire7/expand1x1"
top: "fire7/expand1x1"
}
layer {
name: "fire7/expand3x3"
type: "Convolution"
bottom: "fire7/squeeze1x1"
top: "fire7/expand3x3"
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire7/relu_expand3x3"
type: "ReLU"
bottom: "fire7/expand3x3"
top: "fire7/expand3x3"
}
layer {
name: "fire7/concat"
type: "Concat"
bottom: "fire7/expand1x1"
bottom: "fire7/expand3x3"
top: "fire7/concat"
}
layer {
name: "fire8/squeeze1x1"
type: "Convolution"
bottom: "fire7/concat"
top: "fire8/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_squeeze1x1"
type: "ReLU"
bottom: "fire8/squeeze1x1"
top: "fire8/squeeze1x1"
}
layer {
name: "fire8/expand1x1"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand1x1"
type: "ReLU"
bottom: "fire8/expand1x1"
top: "fire8/expand1x1"
}
layer {
name: "fire8/expand3x3"
type: "Convolution"
bottom: "fire8/squeeze1x1"
top: "fire8/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire8/relu_expand3x3"
type: "ReLU"
bottom: "fire8/expand3x3"
top: "fire8/expand3x3"
}
layer {
name: "fire8/concat"
type: "Concat"
bottom: "fire8/expand1x1"
bottom: "fire8/expand3x3"
top: "fire8/concat"
}
layer {
name: "fire9/squeeze1x1"
type: "Convolution"
bottom: "fire8/concat"
top: "fire9/squeeze1x1"
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_squeeze1x1"
type: "ReLU"
bottom: "fire9/squeeze1x1"
top: "fire9/squeeze1x1"
}
layer {
name: "fire9/expand1x1"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand1x1"
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand1x1"
type: "ReLU"
bottom: "fire9/expand1x1"
top: "fire9/expand1x1"
}
layer {
name: "fire9/expand3x3"
type: "Convolution"
bottom: "fire9/squeeze1x1"
top: "fire9/expand3x3"
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
}
}
}
layer {
name: "fire9/relu_expand3x3"
type: "ReLU"
bottom: "fire9/expand3x3"
top: "fire9/expand3x3"
}
layer {
name: "fire9/concat"
type: "Concat"
bottom: "fire9/expand1x1"
bottom: "fire9/expand3x3"
top: "fire9/concat"
}
layer {
name: "drop9"
type: "Dropout"
bottom: "fire9/concat"
top: "fire9/concat"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "conv10"
type: "Convolution"
bottom: "fire9/concat"
top: "conv10"
convolution_param {
num_output: 1000
kernel_size: 1
weight_filler {
type: "gaussian"
mean: 0
std: 0.01
}
}
}
layer {
name: "relu_conv10"
type: "ReLU"
bottom: "conv10"
top: "conv10"
}
layer {
name: "pool10"
type: "Pooling"
bottom: "conv10"
top: "pool10"
pooling_param {
pool: AVE
global_pooling: true
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "pool10"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "pool10"
bottom: "label"
top: "loss"
}
I0811 03:32:40.943269 10215 layer_factory.hpp:77] Creating layer val-data
I0811 03:32:40.943310 10215 db_lmdb.cpp:35] Opened lmdb /home/fei/DIGITS/digits/jobs/20180810-200238-65f4/val_db
I0811 03:32:40.943323 10215 net.cpp:84] Creating Layer val-data
I0811 03:32:40.943327 10215 net.cpp:380] val-data -> data
I0811 03:32:40.943332 10215 net.cpp:380] val-data -> label
I0811 03:32:40.943337 10215 data_transformer.cpp:25] Loading mean file from: /home/fei/DIGITS/digits/jobs/20180810-200238-65f4/mean.binaryproto
I0811 03:32:40.946209 10215 data_layer.cpp:45] output data size: 25,3,227,227
I0811 03:32:40.970244 10215 net.cpp:122] Setting up val-data
I0811 03:32:40.970261 10215 net.cpp:129] Top shape: 25 3 227 227 (3864675)
I0811 03:32:40.970265 10215 net.cpp:129] Top shape: 25 (25)
I0811 03:32:40.970268 10215 net.cpp:137] Memory required for data: 15458800
I0811 03:32:40.970271 10215 layer_factory.hpp:77] Creating layer label_val-data_1_split
I0811 03:32:40.970280 10215 net.cpp:84] Creating Layer label_val-data_1_split
I0811 03:32:40.970283 10215 net.cpp:406] label_val-data_1_split <- label
I0811 03:32:40.970288 10215 net.cpp:380] label_val-data_1_split -> label_val-data_1_split_0
I0811 03:32:40.970293 10215 net.cpp:380] label_val-data_1_split -> label_val-data_1_split_1
I0811 03:32:40.970335 10215 net.cpp:122] Setting up label_val-data_1_split
I0811 03:32:40.970340 10215 net.cpp:129] Top shape: 25 (25)
I0811 03:32:40.970342 10215 net.cpp:129] Top shape: 25 (25)
I0811 03:32:40.970345 10215 net.cpp:137] Memory required for data: 15459000
I0811 03:32:40.970346 10215 layer_factory.hpp:77] Creating layer conv1
I0811 03:32:40.970353 10215 net.cpp:84] Creating Layer conv1
I0811 03:32:40.970355 10215 net.cpp:406] conv1 <- data
I0811 03:32:40.970360 10215 net.cpp:380] conv1 -> conv1
I0811 03:32:40.970546 10215 net.cpp:122] Setting up conv1
I0811 03:32:40.970562 10215 net.cpp:129] Top shape: 25 64 113 113 (20430400)
I0811 03:32:40.970566 10215 net.cpp:137] Memory required for data: 97180600
I0811 03:32:40.970572 10215 layer_factory.hpp:77] Creating layer relu_conv1
I0811 03:32:40.970577 10215 net.cpp:84] Creating Layer relu_conv1
I0811 03:32:40.970579 10215 net.cpp:406] relu_conv1 <- conv1
I0811 03:32:40.970582 10215 net.cpp:367] relu_conv1 -> conv1 (in-place)
I0811 03:32:40.970587 10215 net.cpp:122] Setting up relu_conv1
I0811 03:32:40.970589 10215 net.cpp:129] Top shape: 25 64 113 113 (20430400)
I0811 03:32:40.970592 10215 net.cpp:137] Memory required for data: 178902200
I0811 03:32:40.970593 10215 layer_factory.hpp:77] Creating layer pool1
I0811 03:32:40.970597 10215 net.cpp:84] Creating Layer pool1
I0811 03:32:40.970599 10215 net.cpp:406] pool1 <- conv1
I0811 03:32:40.970602 10215 net.cpp:380] pool1 -> pool1
I0811 03:32:40.970628 10215 net.cpp:122] Setting up pool1
I0811 03:32:40.970630 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.970633 10215 net.cpp:137] Memory required for data: 198972600
I0811 03:32:40.970634 10215 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I0811 03:32:40.970639 10215 net.cpp:84] Creating Layer fire2/squeeze1x1
I0811 03:32:40.970641 10215 net.cpp:406] fire2/squeeze1x1 <- pool1
I0811 03:32:40.970656 10215 net.cpp:380] fire2/squeeze1x1 -> fire2/squeeze1x1
I0811 03:32:40.970819 10215 net.cpp:122] Setting up fire2/squeeze1x1
I0811 03:32:40.970824 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.970826 10215 net.cpp:137] Memory required for data: 203990200
I0811 03:32:40.970831 10215 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I0811 03:32:40.970835 10215 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I0811 03:32:40.970837 10215 net.cpp:406] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I0811 03:32:40.970840 10215 net.cpp:367] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I0811 03:32:40.970844 10215 net.cpp:122] Setting up fire2/relu_squeeze1x1
I0811 03:32:40.970846 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.970849 10215 net.cpp:137] Memory required for data: 209007800
I0811 03:32:40.970850 10215 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0811 03:32:40.970854 10215 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0811 03:32:40.970855 10215 net.cpp:406] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I0811 03:32:40.970858 10215 net.cpp:380] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0811 03:32:40.970862 10215 net.cpp:380] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0811 03:32:40.970888 10215 net.cpp:122] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0811 03:32:40.970892 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.970896 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.970897 10215 net.cpp:137] Memory required for data: 219043000
I0811 03:32:40.970899 10215 layer_factory.hpp:77] Creating layer fire2/expand1x1
I0811 03:32:40.970906 10215 net.cpp:84] Creating Layer fire2/expand1x1
I0811 03:32:40.970907 10215 net.cpp:406] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0811 03:32:40.970911 10215 net.cpp:380] fire2/expand1x1 -> fire2/expand1x1
I0811 03:32:40.971153 10215 net.cpp:122] Setting up fire2/expand1x1
I0811 03:32:40.971161 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.971164 10215 net.cpp:137] Memory required for data: 239113400
I0811 03:32:40.971170 10215 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I0811 03:32:40.971175 10215 net.cpp:84] Creating Layer fire2/relu_expand1x1
I0811 03:32:40.971179 10215 net.cpp:406] fire2/relu_expand1x1 <- fire2/expand1x1
I0811 03:32:40.971181 10215 net.cpp:367] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I0811 03:32:40.971186 10215 net.cpp:122] Setting up fire2/relu_expand1x1
I0811 03:32:40.971189 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.971191 10215 net.cpp:137] Memory required for data: 259183800
I0811 03:32:40.971194 10215 layer_factory.hpp:77] Creating layer fire2/expand3x3
I0811 03:32:40.971199 10215 net.cpp:84] Creating Layer fire2/expand3x3
I0811 03:32:40.971200 10215 net.cpp:406] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0811 03:32:40.971204 10215 net.cpp:380] fire2/expand3x3 -> fire2/expand3x3
I0811 03:32:40.971412 10215 net.cpp:122] Setting up fire2/expand3x3
I0811 03:32:40.971416 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.971418 10215 net.cpp:137] Memory required for data: 279254200
I0811 03:32:40.971422 10215 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I0811 03:32:40.971426 10215 net.cpp:84] Creating Layer fire2/relu_expand3x3
I0811 03:32:40.971428 10215 net.cpp:406] fire2/relu_expand3x3 <- fire2/expand3x3
I0811 03:32:40.971431 10215 net.cpp:367] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I0811 03:32:40.971434 10215 net.cpp:122] Setting up fire2/relu_expand3x3
I0811 03:32:40.971437 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.971439 10215 net.cpp:137] Memory required for data: 299324600
I0811 03:32:40.971441 10215 layer_factory.hpp:77] Creating layer fire2/concat
I0811 03:32:40.971454 10215 net.cpp:84] Creating Layer fire2/concat
I0811 03:32:40.971457 10215 net.cpp:406] fire2/concat <- fire2/expand1x1
I0811 03:32:40.971459 10215 net.cpp:406] fire2/concat <- fire2/expand3x3
I0811 03:32:40.971462 10215 net.cpp:380] fire2/concat -> fire2/concat
I0811 03:32:40.971478 10215 net.cpp:122] Setting up fire2/concat
I0811 03:32:40.971482 10215 net.cpp:129] Top shape: 25 128 56 56 (10035200)
I0811 03:32:40.971483 10215 net.cpp:137] Memory required for data: 339465400
I0811 03:32:40.971487 10215 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I0811 03:32:40.971491 10215 net.cpp:84] Creating Layer fire3/squeeze1x1
I0811 03:32:40.971493 10215 net.cpp:406] fire3/squeeze1x1 <- fire2/concat
I0811 03:32:40.971496 10215 net.cpp:380] fire3/squeeze1x1 -> fire3/squeeze1x1
I0811 03:32:40.971658 10215 net.cpp:122] Setting up fire3/squeeze1x1
I0811 03:32:40.971663 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.971665 10215 net.cpp:137] Memory required for data: 344483000
I0811 03:32:40.971670 10215 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I0811 03:32:40.971673 10215 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I0811 03:32:40.971676 10215 net.cpp:406] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I0811 03:32:40.971679 10215 net.cpp:367] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I0811 03:32:40.971683 10215 net.cpp:122] Setting up fire3/relu_squeeze1x1
I0811 03:32:40.971685 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.971688 10215 net.cpp:137] Memory required for data: 349500600
I0811 03:32:40.971689 10215 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0811 03:32:40.971693 10215 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0811 03:32:40.971695 10215 net.cpp:406] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I0811 03:32:40.971698 10215 net.cpp:380] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0811 03:32:40.971702 10215 net.cpp:380] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0811 03:32:40.971724 10215 net.cpp:122] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0811 03:32:40.971727 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.971730 10215 net.cpp:129] Top shape: 25 16 56 56 (1254400)
I0811 03:32:40.971732 10215 net.cpp:137] Memory required for data: 359535800
I0811 03:32:40.971735 10215 layer_factory.hpp:77] Creating layer fire3/expand1x1
I0811 03:32:40.971740 10215 net.cpp:84] Creating Layer fire3/expand1x1
I0811 03:32:40.971741 10215 net.cpp:406] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0811 03:32:40.971745 10215 net.cpp:380] fire3/expand1x1 -> fire3/expand1x1
I0811 03:32:40.971896 10215 net.cpp:122] Setting up fire3/expand1x1
I0811 03:32:40.971899 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.971901 10215 net.cpp:137] Memory required for data: 379606200
I0811 03:32:40.971905 10215 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I0811 03:32:40.971909 10215 net.cpp:84] Creating Layer fire3/relu_expand1x1
I0811 03:32:40.971910 10215 net.cpp:406] fire3/relu_expand1x1 <- fire3/expand1x1
I0811 03:32:40.971913 10215 net.cpp:367] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I0811 03:32:40.971917 10215 net.cpp:122] Setting up fire3/relu_expand1x1
I0811 03:32:40.971920 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.971921 10215 net.cpp:137] Memory required for data: 399676600
I0811 03:32:40.971923 10215 layer_factory.hpp:77] Creating layer fire3/expand3x3
I0811 03:32:40.971928 10215 net.cpp:84] Creating Layer fire3/expand3x3
I0811 03:32:40.971930 10215 net.cpp:406] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0811 03:32:40.971935 10215 net.cpp:380] fire3/expand3x3 -> fire3/expand3x3
I0811 03:32:40.972129 10215 net.cpp:122] Setting up fire3/expand3x3
I0811 03:32:40.972133 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.972141 10215 net.cpp:137] Memory required for data: 419747000
I0811 03:32:40.972146 10215 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I0811 03:32:40.972148 10215 net.cpp:84] Creating Layer fire3/relu_expand3x3
I0811 03:32:40.972151 10215 net.cpp:406] fire3/relu_expand3x3 <- fire3/expand3x3
I0811 03:32:40.972153 10215 net.cpp:367] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I0811 03:32:40.972157 10215 net.cpp:122] Setting up fire3/relu_expand3x3
I0811 03:32:40.972159 10215 net.cpp:129] Top shape: 25 64 56 56 (5017600)
I0811 03:32:40.972162 10215 net.cpp:137] Memory required for data: 439817400
I0811 03:32:40.972163 10215 layer_factory.hpp:77] Creating layer fire3/concat
I0811 03:32:40.972167 10215 net.cpp:84] Creating Layer fire3/concat
I0811 03:32:40.972168 10215 net.cpp:406] fire3/concat <- fire3/expand1x1
I0811 03:32:40.972172 10215 net.cpp:406] fire3/concat <- fire3/expand3x3
I0811 03:32:40.972174 10215 net.cpp:380] fire3/concat -> fire3/concat
I0811 03:32:40.972188 10215 net.cpp:122] Setting up fire3/concat
I0811 03:32:40.972193 10215 net.cpp:129] Top shape: 25 128 56 56 (10035200)
I0811 03:32:40.972194 10215 net.cpp:137] Memory required for data: 479958200
I0811 03:32:40.972196 10215 layer_factory.hpp:77] Creating layer pool3
I0811 03:32:40.972199 10215 net.cpp:84] Creating Layer pool3
I0811 03:32:40.972201 10215 net.cpp:406] pool3 <- fire3/concat
I0811 03:32:40.972204 10215 net.cpp:380] pool3 -> pool3
I0811 03:32:40.972226 10215 net.cpp:122] Setting up pool3
I0811 03:32:40.972229 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.972231 10215 net.cpp:137] Memory required for data: 489993400
I0811 03:32:40.972234 10215 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I0811 03:32:40.972239 10215 net.cpp:84] Creating Layer fire4/squeeze1x1
I0811 03:32:40.972240 10215 net.cpp:406] fire4/squeeze1x1 <- pool3
I0811 03:32:40.972244 10215 net.cpp:380] fire4/squeeze1x1 -> fire4/squeeze1x1
I0811 03:32:40.972417 10215 net.cpp:122] Setting up fire4/squeeze1x1
I0811 03:32:40.972421 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.972424 10215 net.cpp:137] Memory required for data: 492502200
I0811 03:32:40.972427 10215 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I0811 03:32:40.972430 10215 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I0811 03:32:40.972432 10215 net.cpp:406] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I0811 03:32:40.972435 10215 net.cpp:367] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I0811 03:32:40.972438 10215 net.cpp:122] Setting up fire4/relu_squeeze1x1
I0811 03:32:40.972441 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.972443 10215 net.cpp:137] Memory required for data: 495011000
I0811 03:32:40.972445 10215 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0811 03:32:40.972448 10215 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0811 03:32:40.972450 10215 net.cpp:406] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I0811 03:32:40.972453 10215 net.cpp:380] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0811 03:32:40.972457 10215 net.cpp:380] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0811 03:32:40.972477 10215 net.cpp:122] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0811 03:32:40.972481 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.972483 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.972486 10215 net.cpp:137] Memory required for data: 500028600
I0811 03:32:40.972487 10215 layer_factory.hpp:77] Creating layer fire4/expand1x1
I0811 03:32:40.972492 10215 net.cpp:84] Creating Layer fire4/expand1x1
I0811 03:32:40.972494 10215 net.cpp:406] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0811 03:32:40.972498 10215 net.cpp:380] fire4/expand1x1 -> fire4/expand1x1
I0811 03:32:40.972664 10215 net.cpp:122] Setting up fire4/expand1x1
I0811 03:32:40.972673 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.972676 10215 net.cpp:137] Memory required for data: 510063800
I0811 03:32:40.972681 10215 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I0811 03:32:40.972685 10215 net.cpp:84] Creating Layer fire4/relu_expand1x1
I0811 03:32:40.972687 10215 net.cpp:406] fire4/relu_expand1x1 <- fire4/expand1x1
I0811 03:32:40.972690 10215 net.cpp:367] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I0811 03:32:40.972694 10215 net.cpp:122] Setting up fire4/relu_expand1x1
I0811 03:32:40.972697 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.972698 10215 net.cpp:137] Memory required for data: 520099000
I0811 03:32:40.972700 10215 layer_factory.hpp:77] Creating layer fire4/expand3x3
I0811 03:32:40.972705 10215 net.cpp:84] Creating Layer fire4/expand3x3
I0811 03:32:40.972707 10215 net.cpp:406] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0811 03:32:40.972712 10215 net.cpp:380] fire4/expand3x3 -> fire4/expand3x3
I0811 03:32:40.974289 10215 net.cpp:122] Setting up fire4/expand3x3
I0811 03:32:40.974298 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.974301 10215 net.cpp:137] Memory required for data: 530134200
I0811 03:32:40.974305 10215 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I0811 03:32:40.974309 10215 net.cpp:84] Creating Layer fire4/relu_expand3x3
I0811 03:32:40.974313 10215 net.cpp:406] fire4/relu_expand3x3 <- fire4/expand3x3
I0811 03:32:40.974316 10215 net.cpp:367] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I0811 03:32:40.974320 10215 net.cpp:122] Setting up fire4/relu_expand3x3
I0811 03:32:40.974323 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.974325 10215 net.cpp:137] Memory required for data: 540169400
I0811 03:32:40.974328 10215 layer_factory.hpp:77] Creating layer fire4/concat
I0811 03:32:40.974333 10215 net.cpp:84] Creating Layer fire4/concat
I0811 03:32:40.974334 10215 net.cpp:406] fire4/concat <- fire4/expand1x1
I0811 03:32:40.974337 10215 net.cpp:406] fire4/concat <- fire4/expand3x3
I0811 03:32:40.974340 10215 net.cpp:380] fire4/concat -> fire4/concat
I0811 03:32:40.974355 10215 net.cpp:122] Setting up fire4/concat
I0811 03:32:40.974359 10215 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0811 03:32:40.974361 10215 net.cpp:137] Memory required for data: 560239800
I0811 03:32:40.974364 10215 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I0811 03:32:40.974367 10215 net.cpp:84] Creating Layer fire5/squeeze1x1
I0811 03:32:40.974370 10215 net.cpp:406] fire5/squeeze1x1 <- fire4/concat
I0811 03:32:40.974373 10215 net.cpp:380] fire5/squeeze1x1 -> fire5/squeeze1x1
I0811 03:32:40.974577 10215 net.cpp:122] Setting up fire5/squeeze1x1
I0811 03:32:40.974582 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.974584 10215 net.cpp:137] Memory required for data: 562748600
I0811 03:32:40.974588 10215 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I0811 03:32:40.974591 10215 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I0811 03:32:40.974593 10215 net.cpp:406] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I0811 03:32:40.974596 10215 net.cpp:367] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I0811 03:32:40.974601 10215 net.cpp:122] Setting up fire5/relu_squeeze1x1
I0811 03:32:40.974603 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.974606 10215 net.cpp:137] Memory required for data: 565257400
I0811 03:32:40.974607 10215 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0811 03:32:40.974613 10215 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0811 03:32:40.974615 10215 net.cpp:406] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I0811 03:32:40.974618 10215 net.cpp:380] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0811 03:32:40.974622 10215 net.cpp:380] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0811 03:32:40.974654 10215 net.cpp:122] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0811 03:32:40.974658 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.974660 10215 net.cpp:129] Top shape: 25 32 28 28 (627200)
I0811 03:32:40.974663 10215 net.cpp:137] Memory required for data: 570275000
I0811 03:32:40.974665 10215 layer_factory.hpp:77] Creating layer fire5/expand1x1
I0811 03:32:40.974669 10215 net.cpp:84] Creating Layer fire5/expand1x1
I0811 03:32:40.974671 10215 net.cpp:406] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0811 03:32:40.974675 10215 net.cpp:380] fire5/expand1x1 -> fire5/expand1x1
I0811 03:32:40.974844 10215 net.cpp:122] Setting up fire5/expand1x1
I0811 03:32:40.974848 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.974850 10215 net.cpp:137] Memory required for data: 580310200
I0811 03:32:40.974854 10215 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I0811 03:32:40.974858 10215 net.cpp:84] Creating Layer fire5/relu_expand1x1
I0811 03:32:40.974860 10215 net.cpp:406] fire5/relu_expand1x1 <- fire5/expand1x1
I0811 03:32:40.974864 10215 net.cpp:367] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I0811 03:32:40.974866 10215 net.cpp:122] Setting up fire5/relu_expand1x1
I0811 03:32:40.974869 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.974871 10215 net.cpp:137] Memory required for data: 590345400
I0811 03:32:40.974874 10215 layer_factory.hpp:77] Creating layer fire5/expand3x3
I0811 03:32:40.974877 10215 net.cpp:84] Creating Layer fire5/expand3x3
I0811 03:32:40.974879 10215 net.cpp:406] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0811 03:32:40.974884 10215 net.cpp:380] fire5/expand3x3 -> fire5/expand3x3
I0811 03:32:40.975225 10215 net.cpp:122] Setting up fire5/expand3x3
I0811 03:32:40.975230 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.975232 10215 net.cpp:137] Memory required for data: 600380600
I0811 03:32:40.975235 10215 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I0811 03:32:40.975239 10215 net.cpp:84] Creating Layer fire5/relu_expand3x3
I0811 03:32:40.975241 10215 net.cpp:406] fire5/relu_expand3x3 <- fire5/expand3x3
I0811 03:32:40.975244 10215 net.cpp:367] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I0811 03:32:40.975247 10215 net.cpp:122] Setting up fire5/relu_expand3x3
I0811 03:32:40.975250 10215 net.cpp:129] Top shape: 25 128 28 28 (2508800)
I0811 03:32:40.975252 10215 net.cpp:137] Memory required for data: 610415800
I0811 03:32:40.975255 10215 layer_factory.hpp:77] Creating layer fire5/concat
I0811 03:32:40.975257 10215 net.cpp:84] Creating Layer fire5/concat
I0811 03:32:40.975260 10215 net.cpp:406] fire5/concat <- fire5/expand1x1
I0811 03:32:40.975262 10215 net.cpp:406] fire5/concat <- fire5/expand3x3
I0811 03:32:40.975265 10215 net.cpp:380] fire5/concat -> fire5/concat
I0811 03:32:40.975280 10215 net.cpp:122] Setting up fire5/concat
I0811 03:32:40.975282 10215 net.cpp:129] Top shape: 25 256 28 28 (5017600)
I0811 03:32:40.975284 10215 net.cpp:137] Memory required for data: 630486200
I0811 03:32:40.975286 10215 layer_factory.hpp:77] Creating layer pool5
I0811 03:32:40.975291 10215 net.cpp:84] Creating Layer pool5
I0811 03:32:40.975292 10215 net.cpp:406] pool5 <- fire5/concat
I0811 03:32:40.975296 10215 net.cpp:380] pool5 -> pool5
I0811 03:32:40.975317 10215 net.cpp:122] Setting up pool5
I0811 03:32:40.975322 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.975323 10215 net.cpp:137] Memory required for data: 635503800
I0811 03:32:40.975325 10215 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I0811 03:32:40.975329 10215 net.cpp:84] Creating Layer fire6/squeeze1x1
I0811 03:32:40.975332 10215 net.cpp:406] fire6/squeeze1x1 <- pool5
I0811 03:32:40.975334 10215 net.cpp:380] fire6/squeeze1x1 -> fire6/squeeze1x1
I0811 03:32:40.975553 10215 net.cpp:122] Setting up fire6/squeeze1x1
I0811 03:32:40.975558 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.975559 10215 net.cpp:137] Memory required for data: 636444600
I0811 03:32:40.975569 10215 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I0811 03:32:40.975572 10215 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I0811 03:32:40.975574 10215 net.cpp:406] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I0811 03:32:40.975577 10215 net.cpp:367] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I0811 03:32:40.975581 10215 net.cpp:122] Setting up fire6/relu_squeeze1x1
I0811 03:32:40.975584 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.975586 10215 net.cpp:137] Memory required for data: 637385400
I0811 03:32:40.975589 10215 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0811 03:32:40.975591 10215 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0811 03:32:40.975594 10215 net.cpp:406] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I0811 03:32:40.975596 10215 net.cpp:380] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0811 03:32:40.975600 10215 net.cpp:380] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0811 03:32:40.975627 10215 net.cpp:122] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0811 03:32:40.975631 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.975634 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.975636 10215 net.cpp:137] Memory required for data: 639267000
I0811 03:32:40.975637 10215 layer_factory.hpp:77] Creating layer fire6/expand1x1
I0811 03:32:40.975641 10215 net.cpp:84] Creating Layer fire6/expand1x1
I0811 03:32:40.975644 10215 net.cpp:406] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0811 03:32:40.975647 10215 net.cpp:380] fire6/expand1x1 -> fire6/expand1x1
I0811 03:32:40.975842 10215 net.cpp:122] Setting up fire6/expand1x1
I0811 03:32:40.975847 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.975848 10215 net.cpp:137] Memory required for data: 643030200
I0811 03:32:40.975852 10215 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I0811 03:32:40.975855 10215 net.cpp:84] Creating Layer fire6/relu_expand1x1
I0811 03:32:40.975857 10215 net.cpp:406] fire6/relu_expand1x1 <- fire6/expand1x1
I0811 03:32:40.975860 10215 net.cpp:367] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I0811 03:32:40.975863 10215 net.cpp:122] Setting up fire6/relu_expand1x1
I0811 03:32:40.975867 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.975867 10215 net.cpp:137] Memory required for data: 646793400
I0811 03:32:40.975869 10215 layer_factory.hpp:77] Creating layer fire6/expand3x3
I0811 03:32:40.975873 10215 net.cpp:84] Creating Layer fire6/expand3x3
I0811 03:32:40.975877 10215 net.cpp:406] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0811 03:32:40.975879 10215 net.cpp:380] fire6/expand3x3 -> fire6/expand3x3
I0811 03:32:40.976475 10215 net.cpp:122] Setting up fire6/expand3x3
I0811 03:32:40.976478 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.976480 10215 net.cpp:137] Memory required for data: 650556600
I0811 03:32:40.976485 10215 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I0811 03:32:40.976487 10215 net.cpp:84] Creating Layer fire6/relu_expand3x3
I0811 03:32:40.976490 10215 net.cpp:406] fire6/relu_expand3x3 <- fire6/expand3x3
I0811 03:32:40.976492 10215 net.cpp:367] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I0811 03:32:40.976496 10215 net.cpp:122] Setting up fire6/relu_expand3x3
I0811 03:32:40.976500 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.976500 10215 net.cpp:137] Memory required for data: 654319800
I0811 03:32:40.976502 10215 layer_factory.hpp:77] Creating layer fire6/concat
I0811 03:32:40.976506 10215 net.cpp:84] Creating Layer fire6/concat
I0811 03:32:40.976508 10215 net.cpp:406] fire6/concat <- fire6/expand1x1
I0811 03:32:40.976511 10215 net.cpp:406] fire6/concat <- fire6/expand3x3
I0811 03:32:40.976513 10215 net.cpp:380] fire6/concat -> fire6/concat
I0811 03:32:40.976536 10215 net.cpp:122] Setting up fire6/concat
I0811 03:32:40.976539 10215 net.cpp:129] Top shape: 25 384 14 14 (1881600)
I0811 03:32:40.976541 10215 net.cpp:137] Memory required for data: 661846200
I0811 03:32:40.976543 10215 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I0811 03:32:40.976547 10215 net.cpp:84] Creating Layer fire7/squeeze1x1
I0811 03:32:40.976549 10215 net.cpp:406] fire7/squeeze1x1 <- fire6/concat
I0811 03:32:40.976553 10215 net.cpp:380] fire7/squeeze1x1 -> fire7/squeeze1x1
I0811 03:32:40.976809 10215 net.cpp:122] Setting up fire7/squeeze1x1
I0811 03:32:40.976814 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.976815 10215 net.cpp:137] Memory required for data: 662787000
I0811 03:32:40.976824 10215 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I0811 03:32:40.976826 10215 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I0811 03:32:40.976828 10215 net.cpp:406] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I0811 03:32:40.976832 10215 net.cpp:367] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I0811 03:32:40.976835 10215 net.cpp:122] Setting up fire7/relu_squeeze1x1
I0811 03:32:40.976838 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.976840 10215 net.cpp:137] Memory required for data: 663727800
I0811 03:32:40.976842 10215 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0811 03:32:40.976845 10215 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0811 03:32:40.976847 10215 net.cpp:406] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I0811 03:32:40.976850 10215 net.cpp:380] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0811 03:32:40.976855 10215 net.cpp:380] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0811 03:32:40.976877 10215 net.cpp:122] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0811 03:32:40.976881 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.976883 10215 net.cpp:129] Top shape: 25 48 14 14 (235200)
I0811 03:32:40.976886 10215 net.cpp:137] Memory required for data: 665609400
I0811 03:32:40.976887 10215 layer_factory.hpp:77] Creating layer fire7/expand1x1
I0811 03:32:40.976891 10215 net.cpp:84] Creating Layer fire7/expand1x1
I0811 03:32:40.976893 10215 net.cpp:406] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0811 03:32:40.976897 10215 net.cpp:380] fire7/expand1x1 -> fire7/expand1x1
I0811 03:32:40.977090 10215 net.cpp:122] Setting up fire7/expand1x1
I0811 03:32:40.977094 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.977097 10215 net.cpp:137] Memory required for data: 669372600
I0811 03:32:40.977100 10215 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I0811 03:32:40.977103 10215 net.cpp:84] Creating Layer fire7/relu_expand1x1
I0811 03:32:40.977105 10215 net.cpp:406] fire7/relu_expand1x1 <- fire7/expand1x1
I0811 03:32:40.977108 10215 net.cpp:367] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I0811 03:32:40.977111 10215 net.cpp:122] Setting up fire7/relu_expand1x1
I0811 03:32:40.977114 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.977116 10215 net.cpp:137] Memory required for data: 673135800
I0811 03:32:40.977118 10215 layer_factory.hpp:77] Creating layer fire7/expand3x3
I0811 03:32:40.977123 10215 net.cpp:84] Creating Layer fire7/expand3x3
I0811 03:32:40.977124 10215 net.cpp:406] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0811 03:32:40.977128 10215 net.cpp:380] fire7/expand3x3 -> fire7/expand3x3
I0811 03:32:40.977715 10215 net.cpp:122] Setting up fire7/expand3x3
I0811 03:32:40.977718 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.977720 10215 net.cpp:137] Memory required for data: 676899000
I0811 03:32:40.977725 10215 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I0811 03:32:40.977727 10215 net.cpp:84] Creating Layer fire7/relu_expand3x3
I0811 03:32:40.977730 10215 net.cpp:406] fire7/relu_expand3x3 <- fire7/expand3x3
I0811 03:32:40.977738 10215 net.cpp:367] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I0811 03:32:40.977741 10215 net.cpp:122] Setting up fire7/relu_expand3x3
I0811 03:32:40.977744 10215 net.cpp:129] Top shape: 25 192 14 14 (940800)
I0811 03:32:40.977746 10215 net.cpp:137] Memory required for data: 680662200
I0811 03:32:40.977748 10215 layer_factory.hpp:77] Creating layer fire7/concat
I0811 03:32:40.977751 10215 net.cpp:84] Creating Layer fire7/concat
I0811 03:32:40.977753 10215 net.cpp:406] fire7/concat <- fire7/expand1x1
I0811 03:32:40.977756 10215 net.cpp:406] fire7/concat <- fire7/expand3x3
I0811 03:32:40.977758 10215 net.cpp:380] fire7/concat -> fire7/concat
I0811 03:32:40.977773 10215 net.cpp:122] Setting up fire7/concat
I0811 03:32:40.977777 10215 net.cpp:129] Top shape: 25 384 14 14 (1881600)
I0811 03:32:40.977778 10215 net.cpp:137] Memory required for data: 688188600
I0811 03:32:40.977780 10215 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I0811 03:32:40.977784 10215 net.cpp:84] Creating Layer fire8/squeeze1x1
I0811 03:32:40.977787 10215 net.cpp:406] fire8/squeeze1x1 <- fire7/concat
I0811 03:32:40.977790 10215 net.cpp:380] fire8/squeeze1x1 -> fire8/squeeze1x1
I0811 03:32:40.978065 10215 net.cpp:122] Setting up fire8/squeeze1x1
I0811 03:32:40.978070 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.978071 10215 net.cpp:137] Memory required for data: 689443000
I0811 03:32:40.978075 10215 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I0811 03:32:40.978078 10215 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I0811 03:32:40.978080 10215 net.cpp:406] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I0811 03:32:40.978083 10215 net.cpp:367] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I0811 03:32:40.978087 10215 net.cpp:122] Setting up fire8/relu_squeeze1x1
I0811 03:32:40.978090 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.978091 10215 net.cpp:137] Memory required for data: 690697400
I0811 03:32:40.978093 10215 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0811 03:32:40.978096 10215 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0811 03:32:40.978098 10215 net.cpp:406] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I0811 03:32:40.978101 10215 net.cpp:380] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0811 03:32:40.978106 10215 net.cpp:380] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0811 03:32:40.978128 10215 net.cpp:122] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0811 03:32:40.978132 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.978134 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.978137 10215 net.cpp:137] Memory required for data: 693206200
I0811 03:32:40.978138 10215 layer_factory.hpp:77] Creating layer fire8/expand1x1
I0811 03:32:40.978142 10215 net.cpp:84] Creating Layer fire8/expand1x1
I0811 03:32:40.978144 10215 net.cpp:406] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0811 03:32:40.978148 10215 net.cpp:380] fire8/expand1x1 -> fire8/expand1x1
I0811 03:32:40.978379 10215 net.cpp:122] Setting up fire8/expand1x1
I0811 03:32:40.978384 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.978385 10215 net.cpp:137] Memory required for data: 698223800
I0811 03:32:40.978389 10215 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I0811 03:32:40.978392 10215 net.cpp:84] Creating Layer fire8/relu_expand1x1
I0811 03:32:40.978394 10215 net.cpp:406] fire8/relu_expand1x1 <- fire8/expand1x1
I0811 03:32:40.978397 10215 net.cpp:367] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I0811 03:32:40.978400 10215 net.cpp:122] Setting up fire8/relu_expand1x1
I0811 03:32:40.978404 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.978405 10215 net.cpp:137] Memory required for data: 703241400
I0811 03:32:40.978407 10215 layer_factory.hpp:77] Creating layer fire8/expand3x3
I0811 03:32:40.978416 10215 net.cpp:84] Creating Layer fire8/expand3x3
I0811 03:32:40.978418 10215 net.cpp:406] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0811 03:32:40.978422 10215 net.cpp:380] fire8/expand3x3 -> fire8/expand3x3
I0811 03:32:40.980054 10215 net.cpp:122] Setting up fire8/expand3x3
I0811 03:32:40.980065 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.980068 10215 net.cpp:137] Memory required for data: 708259000
I0811 03:32:40.980072 10215 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I0811 03:32:40.980077 10215 net.cpp:84] Creating Layer fire8/relu_expand3x3
I0811 03:32:40.980080 10215 net.cpp:406] fire8/relu_expand3x3 <- fire8/expand3x3
I0811 03:32:40.980083 10215 net.cpp:367] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I0811 03:32:40.980089 10215 net.cpp:122] Setting up fire8/relu_expand3x3
I0811 03:32:40.980092 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.980093 10215 net.cpp:137] Memory required for data: 713276600
I0811 03:32:40.980096 10215 layer_factory.hpp:77] Creating layer fire8/concat
I0811 03:32:40.980099 10215 net.cpp:84] Creating Layer fire8/concat
I0811 03:32:40.980101 10215 net.cpp:406] fire8/concat <- fire8/expand1x1
I0811 03:32:40.980104 10215 net.cpp:406] fire8/concat <- fire8/expand3x3
I0811 03:32:40.980108 10215 net.cpp:380] fire8/concat -> fire8/concat
I0811 03:32:40.980127 10215 net.cpp:122] Setting up fire8/concat
I0811 03:32:40.980131 10215 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0811 03:32:40.980134 10215 net.cpp:137] Memory required for data: 723311800
I0811 03:32:40.980135 10215 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I0811 03:32:40.980140 10215 net.cpp:84] Creating Layer fire9/squeeze1x1
I0811 03:32:40.980142 10215 net.cpp:406] fire9/squeeze1x1 <- fire8/concat
I0811 03:32:40.980145 10215 net.cpp:380] fire9/squeeze1x1 -> fire9/squeeze1x1
I0811 03:32:40.980475 10215 net.cpp:122] Setting up fire9/squeeze1x1
I0811 03:32:40.980480 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.980482 10215 net.cpp:137] Memory required for data: 724566200
I0811 03:32:40.980485 10215 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I0811 03:32:40.980494 10215 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I0811 03:32:40.980496 10215 net.cpp:406] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I0811 03:32:40.980499 10215 net.cpp:367] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I0811 03:32:40.980504 10215 net.cpp:122] Setting up fire9/relu_squeeze1x1
I0811 03:32:40.980506 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.980509 10215 net.cpp:137] Memory required for data: 725820600
I0811 03:32:40.980510 10215 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0811 03:32:40.980514 10215 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0811 03:32:40.980515 10215 net.cpp:406] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I0811 03:32:40.980518 10215 net.cpp:380] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0811 03:32:40.980522 10215 net.cpp:380] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0811 03:32:40.980545 10215 net.cpp:122] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0811 03:32:40.980549 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.980551 10215 net.cpp:129] Top shape: 25 64 14 14 (313600)
I0811 03:32:40.980553 10215 net.cpp:137] Memory required for data: 728329400
I0811 03:32:40.980556 10215 layer_factory.hpp:77] Creating layer fire9/expand1x1
I0811 03:32:40.980559 10215 net.cpp:84] Creating Layer fire9/expand1x1
I0811 03:32:40.980561 10215 net.cpp:406] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0811 03:32:40.980566 10215 net.cpp:380] fire9/expand1x1 -> fire9/expand1x1
I0811 03:32:40.980798 10215 net.cpp:122] Setting up fire9/expand1x1
I0811 03:32:40.980810 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.980813 10215 net.cpp:137] Memory required for data: 733347000
I0811 03:32:40.980816 10215 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I0811 03:32:40.980819 10215 net.cpp:84] Creating Layer fire9/relu_expand1x1
I0811 03:32:40.980823 10215 net.cpp:406] fire9/relu_expand1x1 <- fire9/expand1x1
I0811 03:32:40.980825 10215 net.cpp:367] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I0811 03:32:40.980829 10215 net.cpp:122] Setting up fire9/relu_expand1x1
I0811 03:32:40.980831 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.980834 10215 net.cpp:137] Memory required for data: 738364600
I0811 03:32:40.980835 10215 layer_factory.hpp:77] Creating layer fire9/expand3x3
I0811 03:32:40.980839 10215 net.cpp:84] Creating Layer fire9/expand3x3
I0811 03:32:40.980842 10215 net.cpp:406] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0811 03:32:40.980845 10215 net.cpp:380] fire9/expand3x3 -> fire9/expand3x3
I0811 03:32:40.981781 10215 net.cpp:122] Setting up fire9/expand3x3
I0811 03:32:40.981786 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.981788 10215 net.cpp:137] Memory required for data: 743382200
I0811 03:32:40.981792 10215 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I0811 03:32:40.981796 10215 net.cpp:84] Creating Layer fire9/relu_expand3x3
I0811 03:32:40.981797 10215 net.cpp:406] fire9/relu_expand3x3 <- fire9/expand3x3
I0811 03:32:40.981801 10215 net.cpp:367] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I0811 03:32:40.981804 10215 net.cpp:122] Setting up fire9/relu_expand3x3
I0811 03:32:40.981807 10215 net.cpp:129] Top shape: 25 256 14 14 (1254400)
I0811 03:32:40.981809 10215 net.cpp:137] Memory required for data: 748399800
I0811 03:32:40.981812 10215 layer_factory.hpp:77] Creating layer fire9/concat
I0811 03:32:40.981814 10215 net.cpp:84] Creating Layer fire9/concat
I0811 03:32:40.981817 10215 net.cpp:406] fire9/concat <- fire9/expand1x1
I0811 03:32:40.981818 10215 net.cpp:406] fire9/concat <- fire9/expand3x3
I0811 03:32:40.981822 10215 net.cpp:380] fire9/concat -> fire9/concat
I0811 03:32:40.981837 10215 net.cpp:122] Setting up fire9/concat
I0811 03:32:40.981839 10215 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0811 03:32:40.981842 10215 net.cpp:137] Memory required for data: 758435000
I0811 03:32:40.981843 10215 layer_factory.hpp:77] Creating layer drop9
I0811 03:32:40.981848 10215 net.cpp:84] Creating Layer drop9
I0811 03:32:40.981849 10215 net.cpp:406] drop9 <- fire9/concat
I0811 03:32:40.981853 10215 net.cpp:367] drop9 -> fire9/concat (in-place)
I0811 03:32:40.981866 10215 net.cpp:122] Setting up drop9
I0811 03:32:40.981869 10215 net.cpp:129] Top shape: 25 512 14 14 (2508800)
I0811 03:32:40.981871 10215 net.cpp:137] Memory required for data: 768470200
I0811 03:32:40.981873 10215 layer_factory.hpp:77] Creating layer conv10
I0811 03:32:40.981878 10215 net.cpp:84] Creating Layer conv10
I0811 03:32:40.981879 10215 net.cpp:406] conv10 <- fire9/concat
I0811 03:32:40.981883 10215 net.cpp:380] conv10 -> conv10
I0811 03:32:40.995111 10215 net.cpp:122] Setting up conv10
I0811 03:32:40.995126 10215 net.cpp:129] Top shape: 25 1000 14 14 (4900000)
I0811 03:32:40.995127 10215 net.cpp:137] Memory required for data: 788070200
I0811 03:32:40.995133 10215 layer_factory.hpp:77] Creating layer relu_conv10
I0811 03:32:40.995141 10215 net.cpp:84] Creating Layer relu_conv10
I0811 03:32:40.995143 10215 net.cpp:406] relu_conv10 <- conv10
I0811 03:32:40.995148 10215 net.cpp:367] relu_conv10 -> conv10 (in-place)
I0811 03:32:40.995153 10215 net.cpp:122] Setting up relu_conv10
I0811 03:32:40.995157 10215 net.cpp:129] Top shape: 25 1000 14 14 (4900000)
I0811 03:32:40.995158 10215 net.cpp:137] Memory required for data: 807670200
I0811 03:32:40.995160 10215 layer_factory.hpp:77] Creating layer pool10
I0811 03:32:40.995164 10215 net.cpp:84] Creating Layer pool10
I0811 03:32:40.995167 10215 net.cpp:406] pool10 <- conv10
I0811 03:32:40.995170 10215 net.cpp:380] pool10 -> pool10
I0811 03:32:40.995203 10215 net.cpp:122] Setting up pool10
I0811 03:32:40.995206 10215 net.cpp:129] Top shape: 25 1000 1 1 (25000)
I0811 03:32:40.995208 10215 net.cpp:137] Memory required for data: 807770200
I0811 03:32:40.995210 10215 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I0811 03:32:40.995213 10215 net.cpp:84] Creating Layer pool10_pool10_0_split
I0811 03:32:40.995215 10215 net.cpp:406] pool10_pool10_0_split <- pool10
I0811 03:32:40.995218 10215 net.cpp:380] pool10_pool10_0_split -> pool10_pool10_0_split_0
I0811 03:32:40.995223 10215 net.cpp:380] pool10_pool10_0_split -> pool10_pool10_0_split_1
I0811 03:32:40.995244 10215 net.cpp:122] Setting up pool10_pool10_0_split
I0811 03:32:40.995247 10215 net.cpp:129] Top shape: 25 1000 1 1 (25000)
I0811 03:32:40.995250 10215 net.cpp:129] Top shape: 25 1000 1 1 (25000)
I0811 03:32:40.995252 10215 net.cpp:137] Memory required for data: 807970200
I0811 03:32:40.995254 10215 layer_factory.hpp:77] Creating layer accuracy
I0811 03:32:40.995259 10215 net.cpp:84] Creating Layer accuracy
I0811 03:32:40.995260 10215 net.cpp:406] accuracy <- pool10_pool10_0_split_0
I0811 03:32:40.995263 10215 net.cpp:406] accuracy <- label_val-data_1_split_0
I0811 03:32:40.995266 10215 net.cpp:380] accuracy -> accuracy
I0811 03:32:40.995271 10215 net.cpp:122] Setting up accuracy
I0811 03:32:40.995275 10215 net.cpp:129] Top shape: (1)
I0811 03:32:40.995275 10215 net.cpp:137] Memory required for data: 807970204
I0811 03:32:40.995277 10215 layer_factory.hpp:77] Creating layer loss
I0811 03:32:40.995281 10215 net.cpp:84] Creating Layer loss
I0811 03:32:40.995283 10215 net.cpp:406] loss <- pool10_pool10_0_split_1
I0811 03:32:40.995286 10215 net.cpp:406] loss <- label_val-data_1_split_1
I0811 03:32:40.995290 10215 net.cpp:380] loss -> loss
I0811 03:32:40.995293 10215 layer_factory.hpp:77] Creating layer loss
I0811 03:32:40.995370 10215 net.cpp:122] Setting up loss
I0811 03:32:40.995374 10215 net.cpp:129] Top shape: (1)
I0811 03:32:40.995376 10215 net.cpp:132]     with loss weight 1
I0811 03:32:40.995384 10215 net.cpp:137] Memory required for data: 807970208
I0811 03:32:40.995386 10215 net.cpp:198] loss needs backward computation.
I0811 03:32:40.995389 10215 net.cpp:200] accuracy does not need backward computation.
I0811 03:32:40.995391 10215 net.cpp:198] pool10_pool10_0_split needs backward computation.
I0811 03:32:40.995394 10215 net.cpp:198] pool10 needs backward computation.
I0811 03:32:40.995396 10215 net.cpp:198] relu_conv10 needs backward computation.
I0811 03:32:40.995398 10215 net.cpp:198] conv10 needs backward computation.
I0811 03:32:40.995400 10215 net.cpp:198] drop9 needs backward computation.
I0811 03:32:40.995402 10215 net.cpp:198] fire9/concat needs backward computation.
I0811 03:32:40.995405 10215 net.cpp:198] fire9/relu_expand3x3 needs backward computation.
I0811 03:32:40.995407 10215 net.cpp:198] fire9/expand3x3 needs backward computation.
I0811 03:32:40.995409 10215 net.cpp:198] fire9/relu_expand1x1 needs backward computation.
I0811 03:32:40.995411 10215 net.cpp:198] fire9/expand1x1 needs backward computation.
I0811 03:32:40.995414 10215 net.cpp:198] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995419 10215 net.cpp:198] fire9/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995420 10215 net.cpp:198] fire9/squeeze1x1 needs backward computation.
I0811 03:32:40.995422 10215 net.cpp:198] fire8/concat needs backward computation.
I0811 03:32:40.995425 10215 net.cpp:198] fire8/relu_expand3x3 needs backward computation.
I0811 03:32:40.995427 10215 net.cpp:198] fire8/expand3x3 needs backward computation.
I0811 03:32:40.995429 10215 net.cpp:198] fire8/relu_expand1x1 needs backward computation.
I0811 03:32:40.995431 10215 net.cpp:198] fire8/expand1x1 needs backward computation.
I0811 03:32:40.995434 10215 net.cpp:198] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995437 10215 net.cpp:198] fire8/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995440 10215 net.cpp:198] fire8/squeeze1x1 needs backward computation.
I0811 03:32:40.995446 10215 net.cpp:198] fire7/concat needs backward computation.
I0811 03:32:40.995450 10215 net.cpp:198] fire7/relu_expand3x3 needs backward computation.
I0811 03:32:40.995451 10215 net.cpp:198] fire7/expand3x3 needs backward computation.
I0811 03:32:40.995453 10215 net.cpp:198] fire7/relu_expand1x1 needs backward computation.
I0811 03:32:40.995455 10215 net.cpp:198] fire7/expand1x1 needs backward computation.
I0811 03:32:40.995457 10215 net.cpp:198] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995460 10215 net.cpp:198] fire7/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995461 10215 net.cpp:198] fire7/squeeze1x1 needs backward computation.
I0811 03:32:40.995465 10215 net.cpp:198] fire6/concat needs backward computation.
I0811 03:32:40.995467 10215 net.cpp:198] fire6/relu_expand3x3 needs backward computation.
I0811 03:32:40.995470 10215 net.cpp:198] fire6/expand3x3 needs backward computation.
I0811 03:32:40.995471 10215 net.cpp:198] fire6/relu_expand1x1 needs backward computation.
I0811 03:32:40.995473 10215 net.cpp:198] fire6/expand1x1 needs backward computation.
I0811 03:32:40.995476 10215 net.cpp:198] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995477 10215 net.cpp:198] fire6/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995479 10215 net.cpp:198] fire6/squeeze1x1 needs backward computation.
I0811 03:32:40.995481 10215 net.cpp:198] pool5 needs backward computation.
I0811 03:32:40.995484 10215 net.cpp:198] fire5/concat needs backward computation.
I0811 03:32:40.995486 10215 net.cpp:198] fire5/relu_expand3x3 needs backward computation.
I0811 03:32:40.995488 10215 net.cpp:198] fire5/expand3x3 needs backward computation.
I0811 03:32:40.995491 10215 net.cpp:198] fire5/relu_expand1x1 needs backward computation.
I0811 03:32:40.995492 10215 net.cpp:198] fire5/expand1x1 needs backward computation.
I0811 03:32:40.995496 10215 net.cpp:198] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995497 10215 net.cpp:198] fire5/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995499 10215 net.cpp:198] fire5/squeeze1x1 needs backward computation.
I0811 03:32:40.995501 10215 net.cpp:198] fire4/concat needs backward computation.
I0811 03:32:40.995504 10215 net.cpp:198] fire4/relu_expand3x3 needs backward computation.
I0811 03:32:40.995507 10215 net.cpp:198] fire4/expand3x3 needs backward computation.
I0811 03:32:40.995508 10215 net.cpp:198] fire4/relu_expand1x1 needs backward computation.
I0811 03:32:40.995510 10215 net.cpp:198] fire4/expand1x1 needs backward computation.
I0811 03:32:40.995512 10215 net.cpp:198] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995514 10215 net.cpp:198] fire4/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995517 10215 net.cpp:198] fire4/squeeze1x1 needs backward computation.
I0811 03:32:40.995519 10215 net.cpp:198] pool3 needs backward computation.
I0811 03:32:40.995522 10215 net.cpp:198] fire3/concat needs backward computation.
I0811 03:32:40.995524 10215 net.cpp:198] fire3/relu_expand3x3 needs backward computation.
I0811 03:32:40.995527 10215 net.cpp:198] fire3/expand3x3 needs backward computation.
I0811 03:32:40.995528 10215 net.cpp:198] fire3/relu_expand1x1 needs backward computation.
I0811 03:32:40.995530 10215 net.cpp:198] fire3/expand1x1 needs backward computation.
I0811 03:32:40.995532 10215 net.cpp:198] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995535 10215 net.cpp:198] fire3/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995537 10215 net.cpp:198] fire3/squeeze1x1 needs backward computation.
I0811 03:32:40.995539 10215 net.cpp:198] fire2/concat needs backward computation.
I0811 03:32:40.995543 10215 net.cpp:198] fire2/relu_expand3x3 needs backward computation.
I0811 03:32:40.995544 10215 net.cpp:198] fire2/expand3x3 needs backward computation.
I0811 03:32:40.995546 10215 net.cpp:198] fire2/relu_expand1x1 needs backward computation.
I0811 03:32:40.995551 10215 net.cpp:198] fire2/expand1x1 needs backward computation.
I0811 03:32:40.995553 10215 net.cpp:198] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I0811 03:32:40.995556 10215 net.cpp:198] fire2/relu_squeeze1x1 needs backward computation.
I0811 03:32:40.995558 10215 net.cpp:198] fire2/squeeze1x1 needs backward computation.
I0811 03:32:40.995560 10215 net.cpp:198] pool1 needs backward computation.
I0811 03:32:40.995563 10215 net.cpp:198] relu_conv1 needs backward computation.
I0811 03:32:40.995564 10215 net.cpp:198] conv1 needs backward computation.
I0811 03:32:40.995568 10215 net.cpp:200] label_val-data_1_split does not need backward computation.
I0811 03:32:40.995570 10215 net.cpp:200] val-data does not need backward computation.
I0811 03:32:40.995571 10215 net.cpp:242] This network produces output accuracy
I0811 03:32:40.995574 10215 net.cpp:242] This network produces output loss
I0811 03:32:40.995607 10215 net.cpp:255] Network initialization done.
I0811 03:32:40.995745 10215 solver.cpp:57] Solver scaffolding done.
I0811 03:32:40.996969 10215 caffe.cpp:239] Starting Optimization
I0811 03:32:40.996973 10215 solver.cpp:289] Solving
I0811 03:32:40.996974 10215 solver.cpp:290] Learning Rate Policy: step
I0811 03:32:40.998971 10215 solver.cpp:347] Iteration 0, Testing net (#0)
I0811 03:32:40.998980 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:32:41.001615 10215 blocking_queue.cpp:49] Waiting for data
I0811 03:32:58.047235 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:32:58.124464 10215 solver.cpp:414]     Test net output #0: accuracy = 0
I0811 03:32:58.124485 10215 solver.cpp:414]     Test net output #1: loss = 6.90901 (* 1 = 6.90901 loss)
I0811 03:32:58.322351 10215 solver.cpp:239] Iteration 0 (-2.38331e-33 iter/s, 17.3249s/70 iters), loss = 6.90888
I0811 03:32:58.323570 10215 solver.cpp:258]     Train net output #0: loss = 6.90888 (* 1 = 6.90888 loss)
I0811 03:32:58.323591 10215 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0811 03:33:10.963325 10215 solver.cpp:239] Iteration 70 (5.53823 iter/s, 12.6394s/70 iters), loss = 2.44455
I0811 03:33:10.963505 10215 solver.cpp:258]     Train net output #0: loss = 2.44455 (* 1 = 2.44455 loss)
I0811 03:33:10.963513 10215 sgd_solver.cpp:112] Iteration 70, lr = 0.01
I0811 03:33:23.592227 10215 solver.cpp:239] Iteration 140 (5.54307 iter/s, 12.6284s/70 iters), loss = 2.58287
I0811 03:33:23.592267 10215 solver.cpp:258]     Train net output #0: loss = 2.58287 (* 1 = 2.58287 loss)
I0811 03:33:23.592273 10215 sgd_solver.cpp:112] Iteration 140, lr = 0.01
I0811 03:33:36.216465 10215 solver.cpp:239] Iteration 210 (5.54506 iter/s, 12.6239s/70 iters), loss = 2.73853
I0811 03:33:36.216493 10215 solver.cpp:258]     Train net output #0: loss = 2.73853 (* 1 = 2.73853 loss)
I0811 03:33:36.216500 10215 sgd_solver.cpp:112] Iteration 210, lr = 0.01
I0811 03:33:48.840543 10215 solver.cpp:239] Iteration 280 (5.54512 iter/s, 12.6237s/70 iters), loss = 2.99528
I0811 03:33:48.840595 10215 solver.cpp:258]     Train net output #0: loss = 2.99528 (* 1 = 2.99528 loss)
I0811 03:33:48.840600 10215 sgd_solver.cpp:112] Iteration 280, lr = 0.01
I0811 03:34:01.476209 10215 solver.cpp:239] Iteration 350 (5.54005 iter/s, 12.6353s/70 iters), loss = 2.9626
I0811 03:34:01.476238 10215 solver.cpp:258]     Train net output #0: loss = 2.9626 (* 1 = 2.9626 loss)
I0811 03:34:01.476243 10215 sgd_solver.cpp:112] Iteration 350, lr = 0.01
I0811 03:34:14.099753 10215 solver.cpp:239] Iteration 420 (5.54536 iter/s, 12.6232s/70 iters), loss = 2.9843
I0811 03:34:14.099777 10215 solver.cpp:258]     Train net output #0: loss = 2.9843 (* 1 = 2.9843 loss)
I0811 03:34:14.099783 10215 sgd_solver.cpp:112] Iteration 420, lr = 0.01
I0811 03:34:26.724159 10215 solver.cpp:239] Iteration 490 (5.54498 iter/s, 12.624s/70 iters), loss = 2.83187
I0811 03:34:26.724232 10215 solver.cpp:258]     Train net output #0: loss = 2.83187 (* 1 = 2.83187 loss)
I0811 03:34:26.724239 10215 sgd_solver.cpp:112] Iteration 490, lr = 0.01
I0811 03:34:38.815834 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:34:39.337208 10215 solver.cpp:239] Iteration 560 (5.54999 iter/s, 12.6126s/70 iters), loss = 2.78991
I0811 03:34:39.337234 10215 solver.cpp:258]     Train net output #0: loss = 2.78991 (* 1 = 2.78991 loss)
I0811 03:34:39.337239 10215 sgd_solver.cpp:112] Iteration 560, lr = 0.01
I0811 03:34:39.435117 10215 solver.cpp:347] Iteration 562, Testing net (#0)
I0811 03:34:39.435133 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:34:56.333174 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:34:56.465072 10215 solver.cpp:414]     Test net output #0: accuracy = 0.288667
I0811 03:34:56.465101 10215 solver.cpp:414]     Test net output #1: loss = 2.73101 (* 1 = 2.73101 loss)
I0811 03:35:08.917748 10215 solver.cpp:239] Iteration 630 (2.36649 iter/s, 29.5797s/70 iters), loss = 2.70365
I0811 03:35:08.917896 10215 solver.cpp:258]     Train net output #0: loss = 2.70365 (* 1 = 2.70365 loss)
I0811 03:35:08.917903 10215 sgd_solver.cpp:112] Iteration 630, lr = 0.01
I0811 03:35:21.537919 10215 solver.cpp:239] Iteration 700 (5.54689 iter/s, 12.6197s/70 iters), loss = 2.5527
I0811 03:35:21.537946 10215 solver.cpp:258]     Train net output #0: loss = 2.5527 (* 1 = 2.5527 loss)
I0811 03:35:21.537952 10215 sgd_solver.cpp:112] Iteration 700, lr = 0.01
I0811 03:35:34.171954 10215 solver.cpp:239] Iteration 770 (5.54075 iter/s, 12.6337s/70 iters), loss = 2.72557
I0811 03:35:34.171981 10215 solver.cpp:258]     Train net output #0: loss = 2.72557 (* 1 = 2.72557 loss)
I0811 03:35:34.171986 10215 sgd_solver.cpp:112] Iteration 770, lr = 0.01
I0811 03:35:46.787699 10215 solver.cpp:239] Iteration 840 (5.54878 iter/s, 12.6154s/70 iters), loss = 2.48126
I0811 03:35:46.787835 10215 solver.cpp:258]     Train net output #0: loss = 2.48126 (* 1 = 2.48126 loss)
I0811 03:35:46.787843 10215 sgd_solver.cpp:112] Iteration 840, lr = 0.01
I0811 03:35:59.400056 10215 solver.cpp:239] Iteration 910 (5.55032 iter/s, 12.6119s/70 iters), loss = 2.54295
I0811 03:35:59.400082 10215 solver.cpp:258]     Train net output #0: loss = 2.54295 (* 1 = 2.54295 loss)
I0811 03:35:59.400089 10215 sgd_solver.cpp:112] Iteration 910, lr = 0.01
I0811 03:36:12.020507 10215 solver.cpp:239] Iteration 980 (5.54672 iter/s, 12.6201s/70 iters), loss = 3.01427
I0811 03:36:12.020534 10215 solver.cpp:258]     Train net output #0: loss = 3.01427 (* 1 = 3.01427 loss)
I0811 03:36:12.020540 10215 sgd_solver.cpp:112] Iteration 980, lr = 0.01
I0811 03:36:24.635371 10215 solver.cpp:239] Iteration 1050 (5.54917 iter/s, 12.6145s/70 iters), loss = 3.20576
I0811 03:36:24.635411 10215 solver.cpp:258]     Train net output #0: loss = 3.20576 (* 1 = 3.20576 loss)
I0811 03:36:24.635417 10215 sgd_solver.cpp:112] Iteration 1050, lr = 0.01
I0811 03:36:36.911137 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:36:37.233660 10215 solver.cpp:239] Iteration 1120 (5.55648 iter/s, 12.5979s/70 iters), loss = 2.46574
I0811 03:36:37.233693 10215 solver.cpp:258]     Train net output #0: loss = 2.46574 (* 1 = 2.46574 loss)
I0811 03:36:37.233700 10215 sgd_solver.cpp:112] Iteration 1120, lr = 0.01
I0811 03:36:37.690802 10215 solver.cpp:347] Iteration 1124, Testing net (#0)
I0811 03:36:37.690816 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:36:54.473202 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:36:54.660120 10215 solver.cpp:414]     Test net output #0: accuracy = 0.332833
I0811 03:36:54.660253 10215 solver.cpp:414]     Test net output #1: loss = 2.47161 (* 1 = 2.47161 loss)
I0811 03:37:06.744988 10215 solver.cpp:239] Iteration 1190 (2.37204 iter/s, 29.5105s/70 iters), loss = 2.36376
I0811 03:37:06.745015 10215 solver.cpp:258]     Train net output #0: loss = 2.36376 (* 1 = 2.36376 loss)
I0811 03:37:06.745021 10215 sgd_solver.cpp:112] Iteration 1190, lr = 0.01
I0811 03:37:19.366603 10215 solver.cpp:239] Iteration 1260 (5.54621 iter/s, 12.6212s/70 iters), loss = 2.87079
I0811 03:37:19.366631 10215 solver.cpp:258]     Train net output #0: loss = 2.87079 (* 1 = 2.87079 loss)
I0811 03:37:19.366636 10215 sgd_solver.cpp:112] Iteration 1260, lr = 0.01
I0811 03:37:31.977480 10215 solver.cpp:239] Iteration 1330 (5.55093 iter/s, 12.6105s/70 iters), loss = 2.20412
I0811 03:37:31.977602 10215 solver.cpp:258]     Train net output #0: loss = 2.20412 (* 1 = 2.20412 loss)
I0811 03:37:31.977607 10215 sgd_solver.cpp:112] Iteration 1330, lr = 0.01
I0811 03:37:44.604794 10215 solver.cpp:239] Iteration 1400 (5.54374 iter/s, 12.6269s/70 iters), loss = 2.78425
I0811 03:37:44.604820 10215 solver.cpp:258]     Train net output #0: loss = 2.78425 (* 1 = 2.78425 loss)
I0811 03:37:44.604825 10215 sgd_solver.cpp:112] Iteration 1400, lr = 0.01
I0811 03:37:57.214102 10215 solver.cpp:239] Iteration 1470 (5.55162 iter/s, 12.6089s/70 iters), loss = 2.42039
I0811 03:37:57.214131 10215 solver.cpp:258]     Train net output #0: loss = 2.42039 (* 1 = 2.42039 loss)
I0811 03:37:57.214138 10215 sgd_solver.cpp:112] Iteration 1470, lr = 0.01
I0811 03:38:09.838642 10215 solver.cpp:239] Iteration 1540 (5.54492 iter/s, 12.6242s/70 iters), loss = 2.02372
I0811 03:38:09.838693 10215 solver.cpp:258]     Train net output #0: loss = 2.02372 (* 1 = 2.02372 loss)
I0811 03:38:09.838701 10215 sgd_solver.cpp:112] Iteration 1540, lr = 0.01
I0811 03:38:22.461383 10215 solver.cpp:239] Iteration 1610 (5.54572 iter/s, 12.6223s/70 iters), loss = 2.74005
I0811 03:38:22.461410 10215 solver.cpp:258]     Train net output #0: loss = 2.74005 (* 1 = 2.74005 loss)
I0811 03:38:22.461416 10215 sgd_solver.cpp:112] Iteration 1610, lr = 0.01
I0811 03:38:34.933511 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:38:35.075906 10215 solver.cpp:239] Iteration 1680 (5.54932 iter/s, 12.6142s/70 iters), loss = 2.6628
I0811 03:38:35.075930 10215 solver.cpp:258]     Train net output #0: loss = 2.6628 (* 1 = 2.6628 loss)
I0811 03:38:35.075937 10215 sgd_solver.cpp:112] Iteration 1680, lr = 0.01
I0811 03:38:35.891474 10215 solver.cpp:347] Iteration 1686, Testing net (#0)
I0811 03:38:35.891489 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:38:52.672375 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:38:52.901137 10215 solver.cpp:414]     Test net output #0: accuracy = 0.419334
I0811 03:38:52.901161 10215 solver.cpp:414]     Test net output #1: loss = 2.27949 (* 1 = 2.27949 loss)
I0811 03:39:04.634650 10215 solver.cpp:239] Iteration 1750 (2.36823 iter/s, 29.5579s/70 iters), loss = 2.64469
I0811 03:39:04.634677 10215 solver.cpp:258]     Train net output #0: loss = 2.64469 (* 1 = 2.64469 loss)
I0811 03:39:04.634683 10215 sgd_solver.cpp:112] Iteration 1750, lr = 0.01
I0811 03:39:17.251389 10215 solver.cpp:239] Iteration 1820 (5.54835 iter/s, 12.6164s/70 iters), loss = 1.9577
I0811 03:39:17.251423 10215 solver.cpp:258]     Train net output #0: loss = 1.9577 (* 1 = 1.9577 loss)
I0811 03:39:17.251428 10215 sgd_solver.cpp:112] Iteration 1820, lr = 0.01
I0811 03:39:29.874555 10215 solver.cpp:239] Iteration 1890 (5.54553 iter/s, 12.6228s/70 iters), loss = 1.86508
I0811 03:39:29.874678 10215 solver.cpp:258]     Train net output #0: loss = 1.86508 (* 1 = 1.86508 loss)
I0811 03:39:29.874699 10215 sgd_solver.cpp:112] Iteration 1890, lr = 0.01
I0811 03:39:42.504720 10215 solver.cpp:239] Iteration 1960 (5.54249 iter/s, 12.6297s/70 iters), loss = 2.23026
I0811 03:39:42.504745 10215 solver.cpp:258]     Train net output #0: loss = 2.23026 (* 1 = 2.23026 loss)
I0811 03:39:42.504751 10215 sgd_solver.cpp:112] Iteration 1960, lr = 0.01
I0811 03:39:55.137711 10215 solver.cpp:239] Iteration 2030 (5.54121 iter/s, 12.6326s/70 iters), loss = 2.5723
I0811 03:39:55.137737 10215 solver.cpp:258]     Train net output #0: loss = 2.5723 (* 1 = 2.5723 loss)
I0811 03:39:55.137743 10215 sgd_solver.cpp:112] Iteration 2030, lr = 0.01
I0811 03:40:07.758700 10215 solver.cpp:239] Iteration 2100 (5.54648 iter/s, 12.6206s/70 iters), loss = 1.86218
I0811 03:40:07.758862 10215 solver.cpp:258]     Train net output #0: loss = 1.86218 (* 1 = 1.86218 loss)
I0811 03:40:07.758882 10215 sgd_solver.cpp:112] Iteration 2100, lr = 0.01
I0811 03:40:20.376235 10215 solver.cpp:239] Iteration 2170 (5.54805 iter/s, 12.617s/70 iters), loss = 2.0643
I0811 03:40:20.376260 10215 solver.cpp:258]     Train net output #0: loss = 2.0643 (* 1 = 2.0643 loss)
I0811 03:40:20.376266 10215 sgd_solver.cpp:112] Iteration 2170, lr = 0.01
I0811 03:40:33.002825 10215 solver.cpp:239] Iteration 2240 (5.54402 iter/s, 12.6262s/70 iters), loss = 3.44803
I0811 03:40:33.002851 10215 solver.cpp:258]     Train net output #0: loss = 3.44803 (* 1 = 3.44803 loss)
I0811 03:40:33.002856 10215 sgd_solver.cpp:112] Iteration 2240, lr = 0.01
I0811 03:40:33.058887 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:40:34.184999 10215 solver.cpp:347] Iteration 2248, Testing net (#0)
I0811 03:40:34.185014 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:40:38.216754 10215 blocking_queue.cpp:49] Waiting for data
I0811 03:40:50.884130 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:40:51.171391 10215 solver.cpp:414]     Test net output #0: accuracy = 0.5175
I0811 03:40:51.171413 10215 solver.cpp:414]     Test net output #1: loss = 1.94164 (* 1 = 1.94164 loss)
I0811 03:41:02.518733 10215 solver.cpp:239] Iteration 2310 (2.37167 iter/s, 29.5151s/70 iters), loss = 0.819282
I0811 03:41:02.518759 10215 solver.cpp:258]     Train net output #0: loss = 0.819282 (* 1 = 0.819282 loss)
I0811 03:41:02.518765 10215 sgd_solver.cpp:112] Iteration 2310, lr = 0.01
I0811 03:41:15.119547 10215 solver.cpp:239] Iteration 2380 (5.55536 iter/s, 12.6004s/70 iters), loss = 1.22504
I0811 03:41:15.119712 10215 solver.cpp:258]     Train net output #0: loss = 1.22504 (* 1 = 1.22504 loss)
I0811 03:41:15.119719 10215 sgd_solver.cpp:112] Iteration 2380, lr = 0.01
I0811 03:41:27.749939 10215 solver.cpp:239] Iteration 2450 (5.54241 iter/s, 12.6299s/70 iters), loss = 1.93116
I0811 03:41:27.749969 10215 solver.cpp:258]     Train net output #0: loss = 1.93116 (* 1 = 1.93116 loss)
I0811 03:41:27.749974 10215 sgd_solver.cpp:112] Iteration 2450, lr = 0.01
I0811 03:41:40.367950 10215 solver.cpp:239] Iteration 2520 (5.54779 iter/s, 12.6176s/70 iters), loss = 2.33839
I0811 03:41:40.367976 10215 solver.cpp:258]     Train net output #0: loss = 2.33839 (* 1 = 2.33839 loss)
I0811 03:41:40.367981 10215 sgd_solver.cpp:112] Iteration 2520, lr = 0.01
I0811 03:41:52.978132 10215 solver.cpp:239] Iteration 2590 (5.55123 iter/s, 12.6098s/70 iters), loss = 2.03734
I0811 03:41:52.978263 10215 solver.cpp:258]     Train net output #0: loss = 2.03734 (* 1 = 2.03734 loss)
I0811 03:41:52.978271 10215 sgd_solver.cpp:112] Iteration 2590, lr = 0.01
I0811 03:42:05.603281 10215 solver.cpp:239] Iteration 2660 (5.5447 iter/s, 12.6247s/70 iters), loss = 2.58079
I0811 03:42:05.603307 10215 solver.cpp:258]     Train net output #0: loss = 2.58079 (* 1 = 2.58079 loss)
I0811 03:42:05.603312 10215 sgd_solver.cpp:112] Iteration 2660, lr = 0.01
I0811 03:42:18.215898 10215 solver.cpp:239] Iteration 2730 (5.55016 iter/s, 12.6122s/70 iters), loss = 1.57409
I0811 03:42:18.215924 10215 solver.cpp:258]     Train net output #0: loss = 1.57409 (* 1 = 1.57409 loss)
I0811 03:42:18.215930 10215 sgd_solver.cpp:112] Iteration 2730, lr = 0.01
I0811 03:42:30.818097 10215 solver.cpp:239] Iteration 2800 (5.55475 iter/s, 12.6018s/70 iters), loss = 1.27128
I0811 03:42:30.818229 10215 solver.cpp:258]     Train net output #0: loss = 1.27128 (* 1 = 1.27128 loss)
I0811 03:42:30.818236 10215 sgd_solver.cpp:112] Iteration 2800, lr = 0.01
I0811 03:42:31.057193 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:42:32.358501 10215 solver.cpp:347] Iteration 2810, Testing net (#0)
I0811 03:42:32.358516 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:42:48.994269 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:42:49.331557 10215 solver.cpp:414]     Test net output #0: accuracy = 0.569333
I0811 03:42:49.331578 10215 solver.cpp:414]     Test net output #1: loss = 1.81791 (* 1 = 1.81791 loss)
I0811 03:43:00.334439 10215 solver.cpp:239] Iteration 2870 (2.37164 iter/s, 29.5154s/70 iters), loss = 1.77623
I0811 03:43:00.334484 10215 solver.cpp:258]     Train net output #0: loss = 1.77623 (* 1 = 1.77623 loss)
I0811 03:43:00.334491 10215 sgd_solver.cpp:112] Iteration 2870, lr = 0.01
I0811 03:43:12.971482 10215 solver.cpp:239] Iteration 2940 (5.53944 iter/s, 12.6367s/70 iters), loss = 2.26667
I0811 03:43:12.971649 10215 solver.cpp:258]     Train net output #0: loss = 2.26667 (* 1 = 2.26667 loss)
I0811 03:43:12.971669 10215 sgd_solver.cpp:112] Iteration 2940, lr = 0.01
I0811 03:43:25.605362 10215 solver.cpp:239] Iteration 3010 (5.54088 iter/s, 12.6334s/70 iters), loss = 2.27113
I0811 03:43:25.605394 10215 solver.cpp:258]     Train net output #0: loss = 2.27113 (* 1 = 2.27113 loss)
I0811 03:43:25.605401 10215 sgd_solver.cpp:112] Iteration 3010, lr = 0.01
I0811 03:43:38.221446 10215 solver.cpp:239] Iteration 3080 (5.54864 iter/s, 12.6157s/70 iters), loss = 1.3845
I0811 03:43:38.221474 10215 solver.cpp:258]     Train net output #0: loss = 1.3845 (* 1 = 1.3845 loss)
I0811 03:43:38.221480 10215 sgd_solver.cpp:112] Iteration 3080, lr = 0.01
I0811 03:43:50.842499 10215 solver.cpp:239] Iteration 3150 (5.54645 iter/s, 12.6207s/70 iters), loss = 1.92788
I0811 03:43:50.842577 10215 solver.cpp:258]     Train net output #0: loss = 1.92788 (* 1 = 1.92788 loss)
I0811 03:43:50.842584 10215 sgd_solver.cpp:112] Iteration 3150, lr = 0.01
I0811 03:44:03.455085 10215 solver.cpp:239] Iteration 3220 (5.55019 iter/s, 12.6122s/70 iters), loss = 1.72271
I0811 03:44:03.455113 10215 solver.cpp:258]     Train net output #0: loss = 1.72271 (* 1 = 1.72271 loss)
I0811 03:44:03.455119 10215 sgd_solver.cpp:112] Iteration 3220, lr = 0.01
I0811 03:44:16.068275 10215 solver.cpp:239] Iteration 3290 (5.54991 iter/s, 12.6128s/70 iters), loss = 1.60823
I0811 03:44:16.068307 10215 solver.cpp:258]     Train net output #0: loss = 1.60823 (* 1 = 1.60823 loss)
I0811 03:44:16.068313 10215 sgd_solver.cpp:112] Iteration 3290, lr = 0.01
I0811 03:44:28.679675 10215 solver.cpp:239] Iteration 3360 (5.5507 iter/s, 12.611s/70 iters), loss = 1.87907
I0811 03:44:28.679781 10215 solver.cpp:258]     Train net output #0: loss = 1.87907 (* 1 = 1.87907 loss)
I0811 03:44:28.679790 10215 sgd_solver.cpp:112] Iteration 3360, lr = 0.01
I0811 03:44:29.113867 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:44:30.584080 10215 solver.cpp:347] Iteration 3372, Testing net (#0)
I0811 03:44:30.584096 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:44:47.147547 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:44:47.544167 10215 solver.cpp:414]     Test net output #0: accuracy = 0.705666
I0811 03:44:47.544189 10215 solver.cpp:414]     Test net output #1: loss = 1.54229 (* 1 = 1.54229 loss)
I0811 03:44:58.175859 10215 solver.cpp:239] Iteration 3430 (2.37326 iter/s, 29.4953s/70 iters), loss = 2.99514
I0811 03:44:58.175889 10215 solver.cpp:258]     Train net output #0: loss = 2.99514 (* 1 = 2.99514 loss)
I0811 03:44:58.175895 10215 sgd_solver.cpp:112] Iteration 3430, lr = 0.01
I0811 03:45:10.809829 10215 solver.cpp:239] Iteration 3500 (5.54078 iter/s, 12.6336s/70 iters), loss = 1.43034
I0811 03:45:10.809909 10215 solver.cpp:258]     Train net output #0: loss = 1.43034 (* 1 = 1.43034 loss)
I0811 03:45:10.809929 10215 sgd_solver.cpp:112] Iteration 3500, lr = 0.01
I0811 03:45:23.434098 10215 solver.cpp:239] Iteration 3570 (5.54506 iter/s, 12.6238s/70 iters), loss = 1.30935
I0811 03:45:23.434126 10215 solver.cpp:258]     Train net output #0: loss = 1.30935 (* 1 = 1.30935 loss)
I0811 03:45:23.434131 10215 sgd_solver.cpp:112] Iteration 3570, lr = 0.01
I0811 03:45:36.035905 10215 solver.cpp:239] Iteration 3640 (5.55492 iter/s, 12.6014s/70 iters), loss = 1.79438
I0811 03:45:36.035933 10215 solver.cpp:258]     Train net output #0: loss = 1.79438 (* 1 = 1.79438 loss)
I0811 03:45:36.035938 10215 sgd_solver.cpp:112] Iteration 3640, lr = 0.01
I0811 03:45:48.658772 10215 solver.cpp:239] Iteration 3710 (5.54565 iter/s, 12.6225s/70 iters), loss = 1.52942
I0811 03:45:48.658885 10215 solver.cpp:258]     Train net output #0: loss = 1.52942 (* 1 = 1.52942 loss)
I0811 03:45:48.658905 10215 sgd_solver.cpp:112] Iteration 3710, lr = 0.01
I0811 03:46:01.284045 10215 solver.cpp:239] Iteration 3780 (5.54463 iter/s, 12.6248s/70 iters), loss = 1.8266
I0811 03:46:01.284075 10215 solver.cpp:258]     Train net output #0: loss = 1.8266 (* 1 = 1.8266 loss)
I0811 03:46:01.284080 10215 sgd_solver.cpp:112] Iteration 3780, lr = 0.01
I0811 03:46:13.906565 10215 solver.cpp:239] Iteration 3850 (5.54581 iter/s, 12.6221s/70 iters), loss = 1.7896
I0811 03:46:13.906592 10215 solver.cpp:258]     Train net output #0: loss = 1.7896 (* 1 = 1.7896 loss)
I0811 03:46:13.906597 10215 sgd_solver.cpp:112] Iteration 3850, lr = 0.01
I0811 03:46:26.519471 10215 solver.cpp:239] Iteration 3920 (5.55003 iter/s, 12.6125s/70 iters), loss = 2.20269
I0811 03:46:26.519515 10215 solver.cpp:258]     Train net output #0: loss = 2.20269 (* 1 = 2.20269 loss)
I0811 03:46:26.519520 10215 sgd_solver.cpp:112] Iteration 3920, lr = 0.01
I0811 03:46:27.141783 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:46:28.784984 10215 solver.cpp:347] Iteration 3934, Testing net (#0)
I0811 03:46:28.784998 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:46:45.390542 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:46:45.828038 10215 solver.cpp:414]     Test net output #0: accuracy = 0.743
I0811 03:46:45.828060 10215 solver.cpp:414]     Test net output #1: loss = 1.43989 (* 1 = 1.43989 loss)
I0811 03:46:56.096848 10215 solver.cpp:239] Iteration 3990 (2.36674 iter/s, 29.5765s/70 iters), loss = 1.51269
I0811 03:46:56.096879 10215 solver.cpp:258]     Train net output #0: loss = 1.51269 (* 1 = 1.51269 loss)
I0811 03:46:56.096884 10215 sgd_solver.cpp:112] Iteration 3990, lr = 0.01
I0811 03:47:08.716945 10215 solver.cpp:239] Iteration 4060 (5.54687 iter/s, 12.6197s/70 iters), loss = 1.52783
I0811 03:47:08.716989 10215 solver.cpp:258]     Train net output #0: loss = 1.52783 (* 1 = 1.52783 loss)
I0811 03:47:08.716995 10215 sgd_solver.cpp:112] Iteration 4060, lr = 0.01
I0811 03:47:21.331967 10215 solver.cpp:239] Iteration 4130 (5.54911 iter/s, 12.6146s/70 iters), loss = 1.04752
I0811 03:47:21.331993 10215 solver.cpp:258]     Train net output #0: loss = 1.04752 (* 1 = 1.04752 loss)
I0811 03:47:21.332000 10215 sgd_solver.cpp:112] Iteration 4130, lr = 0.01
I0811 03:47:33.938078 10215 solver.cpp:239] Iteration 4200 (5.55303 iter/s, 12.6057s/70 iters), loss = 1.70144
I0811 03:47:33.938108 10215 solver.cpp:258]     Train net output #0: loss = 1.70144 (* 1 = 1.70144 loss)
I0811 03:47:33.938114 10215 sgd_solver.cpp:112] Iteration 4200, lr = 0.01
I0811 03:47:46.548565 10215 solver.cpp:239] Iteration 4270 (5.5511 iter/s, 12.6101s/70 iters), loss = 2.65213
I0811 03:47:46.548606 10215 solver.cpp:258]     Train net output #0: loss = 2.65213 (* 1 = 2.65213 loss)
I0811 03:47:46.548611 10215 sgd_solver.cpp:112] Iteration 4270, lr = 0.01
I0811 03:47:59.157806 10215 solver.cpp:239] Iteration 4340 (5.55165 iter/s, 12.6089s/70 iters), loss = 0.846637
I0811 03:47:59.157832 10215 solver.cpp:258]     Train net output #0: loss = 0.846637 (* 1 = 0.846637 loss)
I0811 03:47:59.157837 10215 sgd_solver.cpp:112] Iteration 4340, lr = 0.01
I0811 03:48:11.771689 10215 solver.cpp:239] Iteration 4410 (5.5496 iter/s, 12.6135s/70 iters), loss = 1.87622
I0811 03:48:11.771716 10215 solver.cpp:258]     Train net output #0: loss = 1.87622 (* 1 = 1.87622 loss)
I0811 03:48:11.771723 10215 sgd_solver.cpp:112] Iteration 4410, lr = 0.01
I0811 03:48:24.394140 10215 solver.cpp:239] Iteration 4480 (5.54584 iter/s, 12.6221s/70 iters), loss = 2.39218
I0811 03:48:24.394276 10215 solver.cpp:258]     Train net output #0: loss = 2.39218 (* 1 = 2.39218 loss)
I0811 03:48:24.394284 10215 sgd_solver.cpp:112] Iteration 4480, lr = 0.01
I0811 03:48:25.199503 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:48:27.011122 10215 solver.cpp:347] Iteration 4496, Testing net (#0)
I0811 03:48:27.011137 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:48:35.088362 10215 blocking_queue.cpp:49] Waiting for data
I0811 03:48:43.489756 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:48:43.973904 10215 solver.cpp:414]     Test net output #0: accuracy = 0.772833
I0811 03:48:43.973933 10215 solver.cpp:414]     Test net output #1: loss = 1.30719 (* 1 = 1.30719 loss)
I0811 03:48:53.891849 10215 solver.cpp:239] Iteration 4550 (2.37314 iter/s, 29.4968s/70 iters), loss = 2.18574
I0811 03:48:53.891876 10215 solver.cpp:258]     Train net output #0: loss = 2.18574 (* 1 = 2.18574 loss)
I0811 03:48:53.891882 10215 sgd_solver.cpp:112] Iteration 4550, lr = 0.01
I0811 03:49:06.512256 10215 solver.cpp:239] Iteration 4620 (5.54673 iter/s, 12.62s/70 iters), loss = 2.25715
I0811 03:49:06.512435 10215 solver.cpp:258]     Train net output #0: loss = 2.25715 (* 1 = 2.25715 loss)
I0811 03:49:06.512442 10215 sgd_solver.cpp:112] Iteration 4620, lr = 0.01
I0811 03:49:19.116957 10215 solver.cpp:239] Iteration 4690 (5.55371 iter/s, 12.6042s/70 iters), loss = 1.51354
I0811 03:49:19.116983 10215 solver.cpp:258]     Train net output #0: loss = 1.51353 (* 1 = 1.51353 loss)
I0811 03:49:19.116989 10215 sgd_solver.cpp:112] Iteration 4690, lr = 0.01
I0811 03:49:31.744146 10215 solver.cpp:239] Iteration 4760 (5.54376 iter/s, 12.6268s/70 iters), loss = 0.757271
I0811 03:49:31.744174 10215 solver.cpp:258]     Train net output #0: loss = 0.757271 (* 1 = 0.757271 loss)
I0811 03:49:31.744179 10215 sgd_solver.cpp:112] Iteration 4760, lr = 0.01
I0811 03:49:44.375630 10215 solver.cpp:239] Iteration 4830 (5.54187 iter/s, 12.6311s/70 iters), loss = 2.33199
I0811 03:49:44.375797 10215 solver.cpp:258]     Train net output #0: loss = 2.33198 (* 1 = 2.33198 loss)
I0811 03:49:44.375804 10215 sgd_solver.cpp:112] Iteration 4830, lr = 0.01
I0811 03:49:57.005030 10215 solver.cpp:239] Iteration 4900 (5.54284 iter/s, 12.6289s/70 iters), loss = 1.09104
I0811 03:49:57.005056 10215 solver.cpp:258]     Train net output #0: loss = 1.09104 (* 1 = 1.09104 loss)
I0811 03:49:57.005061 10215 sgd_solver.cpp:112] Iteration 4900, lr = 0.01
I0811 03:50:09.631947 10215 solver.cpp:239] Iteration 4970 (5.54388 iter/s, 12.6265s/70 iters), loss = 1.75366
I0811 03:50:09.631971 10215 solver.cpp:258]     Train net output #0: loss = 1.75366 (* 1 = 1.75366 loss)
I0811 03:50:09.631978 10215 sgd_solver.cpp:112] Iteration 4970, lr = 0.01
I0811 03:50:22.257660 10215 solver.cpp:239] Iteration 5040 (5.5444 iter/s, 12.6253s/70 iters), loss = 2.05614
I0811 03:50:22.257746 10215 solver.cpp:258]     Train net output #0: loss = 2.05614 (* 1 = 2.05614 loss)
I0811 03:50:22.257766 10215 sgd_solver.cpp:112] Iteration 5040, lr = 0.01
I0811 03:50:23.360299 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:50:25.237349 10215 solver.cpp:347] Iteration 5058, Testing net (#0)
I0811 03:50:25.237363 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:50:41.714257 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:50:42.259424 10215 solver.cpp:414]     Test net output #0: accuracy = 0.768499
I0811 03:50:42.259447 10215 solver.cpp:414]     Test net output #1: loss = 1.37068 (* 1 = 1.37068 loss)
I0811 03:50:51.815529 10215 solver.cpp:239] Iteration 5110 (2.36831 iter/s, 29.557s/70 iters), loss = 1.05564
I0811 03:50:51.815560 10215 solver.cpp:258]     Train net output #0: loss = 1.05564 (* 1 = 1.05564 loss)
I0811 03:50:51.815567 10215 sgd_solver.cpp:112] Iteration 5110, lr = 0.01
I0811 03:51:04.433377 10215 solver.cpp:239] Iteration 5180 (5.54786 iter/s, 12.6175s/70 iters), loss = 2.27658
I0811 03:51:04.433518 10215 solver.cpp:258]     Train net output #0: loss = 2.27658 (* 1 = 2.27658 loss)
I0811 03:51:04.433526 10215 sgd_solver.cpp:112] Iteration 5180, lr = 0.01
I0811 03:51:17.038851 10215 solver.cpp:239] Iteration 5250 (5.55336 iter/s, 12.605s/70 iters), loss = 1.61422
I0811 03:51:17.038878 10215 solver.cpp:258]     Train net output #0: loss = 1.61422 (* 1 = 1.61422 loss)
I0811 03:51:17.038884 10215 sgd_solver.cpp:112] Iteration 5250, lr = 0.01
I0811 03:51:29.664482 10215 solver.cpp:239] Iteration 5320 (5.54444 iter/s, 12.6253s/70 iters), loss = 1.56651
I0811 03:51:29.664510 10215 solver.cpp:258]     Train net output #0: loss = 1.56651 (* 1 = 1.56651 loss)
I0811 03:51:29.664515 10215 sgd_solver.cpp:112] Iteration 5320, lr = 0.01
I0811 03:51:42.293793 10215 solver.cpp:239] Iteration 5390 (5.54283 iter/s, 12.6289s/70 iters), loss = 1.77975
I0811 03:51:42.293952 10215 solver.cpp:258]     Train net output #0: loss = 1.77975 (* 1 = 1.77975 loss)
I0811 03:51:42.293961 10215 sgd_solver.cpp:112] Iteration 5390, lr = 0.01
I0811 03:51:54.920799 10215 solver.cpp:239] Iteration 5460 (5.54389 iter/s, 12.6265s/70 iters), loss = 1.07702
I0811 03:51:54.920828 10215 solver.cpp:258]     Train net output #0: loss = 1.07702 (* 1 = 1.07702 loss)
I0811 03:51:54.920835 10215 sgd_solver.cpp:112] Iteration 5460, lr = 0.01
I0811 03:52:07.535560 10215 solver.cpp:239] Iteration 5530 (5.54922 iter/s, 12.6144s/70 iters), loss = 0.57305
I0811 03:52:07.535589 10215 solver.cpp:258]     Train net output #0: loss = 0.57305 (* 1 = 0.57305 loss)
I0811 03:52:07.535595 10215 sgd_solver.cpp:112] Iteration 5530, lr = 0.01
I0811 03:52:20.159988 10215 solver.cpp:239] Iteration 5600 (5.54497 iter/s, 12.6241s/70 iters), loss = 1.52039
I0811 03:52:20.160107 10215 solver.cpp:258]     Train net output #0: loss = 1.52039 (* 1 = 1.52039 loss)
I0811 03:52:20.160126 10215 sgd_solver.cpp:112] Iteration 5600, lr = 0.01
I0811 03:52:21.460063 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:52:23.505314 10215 solver.cpp:347] Iteration 5620, Testing net (#0)
I0811 03:52:23.505328 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:52:39.873445 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:52:40.461338 10215 solver.cpp:414]     Test net output #0: accuracy = 0.815333
I0811 03:52:40.461362 10215 solver.cpp:414]     Test net output #1: loss = 1.16821 (* 1 = 1.16821 loss)
I0811 03:52:49.665268 10215 solver.cpp:239] Iteration 5670 (2.37253 iter/s, 29.5044s/70 iters), loss = 1.16122
I0811 03:52:49.665295 10215 solver.cpp:258]     Train net output #0: loss = 1.16122 (* 1 = 1.16122 loss)
I0811 03:52:49.665302 10215 sgd_solver.cpp:112] Iteration 5670, lr = 0.01
I0811 03:53:02.283490 10215 solver.cpp:239] Iteration 5740 (5.5477 iter/s, 12.6179s/70 iters), loss = 1.5383
I0811 03:53:02.283630 10215 solver.cpp:258]     Train net output #0: loss = 1.5383 (* 1 = 1.5383 loss)
I0811 03:53:02.283638 10215 sgd_solver.cpp:112] Iteration 5740, lr = 0.01
I0811 03:53:14.900188 10215 solver.cpp:239] Iteration 5810 (5.54841 iter/s, 12.6162s/70 iters), loss = 1.09873
I0811 03:53:14.900216 10215 solver.cpp:258]     Train net output #0: loss = 1.09873 (* 1 = 1.09873 loss)
I0811 03:53:14.900221 10215 sgd_solver.cpp:112] Iteration 5810, lr = 0.01
I0811 03:53:27.528035 10215 solver.cpp:239] Iteration 5880 (5.54347 iter/s, 12.6275s/70 iters), loss = 0.934035
I0811 03:53:27.528065 10215 solver.cpp:258]     Train net output #0: loss = 0.934036 (* 1 = 0.934036 loss)
I0811 03:53:27.528071 10215 sgd_solver.cpp:112] Iteration 5880, lr = 0.01
I0811 03:53:40.173224 10215 solver.cpp:239] Iteration 5950 (5.53587 iter/s, 12.6448s/70 iters), loss = 1.30513
I0811 03:53:40.173363 10215 solver.cpp:258]     Train net output #0: loss = 1.30513 (* 1 = 1.30513 loss)
I0811 03:53:40.173372 10215 sgd_solver.cpp:112] Iteration 5950, lr = 0.01
I0811 03:53:52.798060 10215 solver.cpp:239] Iteration 6020 (5.54484 iter/s, 12.6244s/70 iters), loss = 0.461873
I0811 03:53:52.798086 10215 solver.cpp:258]     Train net output #0: loss = 0.461873 (* 1 = 0.461873 loss)
I0811 03:53:52.798092 10215 sgd_solver.cpp:112] Iteration 6020, lr = 0.01
I0811 03:54:05.399243 10215 solver.cpp:239] Iteration 6090 (5.5552 iter/s, 12.6008s/70 iters), loss = 0.926161
I0811 03:54:05.399279 10215 solver.cpp:258]     Train net output #0: loss = 0.926161 (* 1 = 0.926161 loss)
I0811 03:54:05.399286 10215 sgd_solver.cpp:112] Iteration 6090, lr = 0.01
I0811 03:54:18.021908 10215 solver.cpp:239] Iteration 6160 (5.54575 iter/s, 12.6223s/70 iters), loss = 0.711571
I0811 03:54:18.022027 10215 solver.cpp:258]     Train net output #0: loss = 0.711572 (* 1 = 0.711572 loss)
I0811 03:54:18.022047 10215 sgd_solver.cpp:112] Iteration 6160, lr = 0.01
I0811 03:54:19.503525 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:54:21.727030 10215 solver.cpp:347] Iteration 6182, Testing net (#0)
I0811 03:54:21.727046 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:54:38.041908 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:54:38.677244 10215 solver.cpp:414]     Test net output #0: accuracy = 0.792167
I0811 03:54:38.677268 10215 solver.cpp:414]     Test net output #1: loss = 1.22691 (* 1 = 1.22691 loss)
I0811 03:54:47.518676 10215 solver.cpp:239] Iteration 6230 (2.37321 iter/s, 29.4959s/70 iters), loss = 0.674444
I0811 03:54:47.518703 10215 solver.cpp:258]     Train net output #0: loss = 0.674444 (* 1 = 0.674444 loss)
I0811 03:54:47.518709 10215 sgd_solver.cpp:112] Iteration 6230, lr = 0.01
I0811 03:55:00.143535 10215 solver.cpp:239] Iteration 6300 (5.54478 iter/s, 12.6245s/70 iters), loss = 0.93569
I0811 03:55:00.143595 10215 solver.cpp:258]     Train net output #0: loss = 0.935691 (* 1 = 0.935691 loss)
I0811 03:55:00.143602 10215 sgd_solver.cpp:112] Iteration 6300, lr = 0.01
I0811 03:55:12.782903 10215 solver.cpp:239] Iteration 6370 (5.53843 iter/s, 12.639s/70 iters), loss = 1.33852
I0811 03:55:12.782930 10215 solver.cpp:258]     Train net output #0: loss = 1.33852 (* 1 = 1.33852 loss)
I0811 03:55:12.782936 10215 sgd_solver.cpp:112] Iteration 6370, lr = 0.01
I0811 03:55:25.413380 10215 solver.cpp:239] Iteration 6440 (5.54232 iter/s, 12.6301s/70 iters), loss = 1.56366
I0811 03:55:25.413410 10215 solver.cpp:258]     Train net output #0: loss = 1.56366 (* 1 = 1.56366 loss)
I0811 03:55:25.413416 10215 sgd_solver.cpp:112] Iteration 6440, lr = 0.01
I0811 03:55:38.016290 10215 solver.cpp:239] Iteration 6510 (5.55444 iter/s, 12.6025s/70 iters), loss = 2.20062
I0811 03:55:38.016415 10215 solver.cpp:258]     Train net output #0: loss = 2.20062 (* 1 = 2.20062 loss)
I0811 03:55:38.016433 10215 sgd_solver.cpp:112] Iteration 6510, lr = 0.01
I0811 03:55:50.628459 10215 solver.cpp:239] Iteration 6580 (5.5504 iter/s, 12.6117s/70 iters), loss = 1.55774
I0811 03:55:50.628489 10215 solver.cpp:258]     Train net output #0: loss = 1.55774 (* 1 = 1.55774 loss)
I0811 03:55:50.628494 10215 sgd_solver.cpp:112] Iteration 6580, lr = 0.01
I0811 03:56:03.239806 10215 solver.cpp:239] Iteration 6650 (5.55072 iter/s, 12.611s/70 iters), loss = 0.969385
I0811 03:56:03.239832 10215 solver.cpp:258]     Train net output #0: loss = 0.969386 (* 1 = 0.969386 loss)
I0811 03:56:03.239837 10215 sgd_solver.cpp:112] Iteration 6650, lr = 0.01
I0811 03:56:15.862325 10215 solver.cpp:239] Iteration 6720 (5.54581 iter/s, 12.6221s/70 iters), loss = 2.00814
I0811 03:56:15.862464 10215 solver.cpp:258]     Train net output #0: loss = 2.00815 (* 1 = 2.00815 loss)
I0811 03:56:15.862471 10215 sgd_solver.cpp:112] Iteration 6720, lr = 0.01
I0811 03:56:17.546357 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:56:19.928196 10215 solver.cpp:347] Iteration 6744, Testing net (#0)
I0811 03:56:19.928211 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:56:32.114253 10215 blocking_queue.cpp:49] Waiting for data
I0811 03:56:36.276859 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:56:36.972002 10215 solver.cpp:414]     Test net output #0: accuracy = 0.8245
I0811 03:56:36.972026 10215 solver.cpp:414]     Test net output #1: loss = 1.13985 (* 1 = 1.13985 loss)
I0811 03:56:45.454937 10215 solver.cpp:239] Iteration 6790 (2.36553 iter/s, 29.5917s/70 iters), loss = 1.29376
I0811 03:56:45.454967 10215 solver.cpp:258]     Train net output #0: loss = 1.29376 (* 1 = 1.29376 loss)
I0811 03:56:45.454972 10215 sgd_solver.cpp:112] Iteration 6790, lr = 0.01
I0811 03:56:58.076174 10215 solver.cpp:239] Iteration 6860 (5.54637 iter/s, 12.6209s/70 iters), loss = 1.36394
I0811 03:56:58.076265 10215 solver.cpp:258]     Train net output #0: loss = 1.36394 (* 1 = 1.36394 loss)
I0811 03:56:58.076272 10215 sgd_solver.cpp:112] Iteration 6860, lr = 0.01
I0811 03:57:10.704211 10215 solver.cpp:239] Iteration 6930 (5.54341 iter/s, 12.6276s/70 iters), loss = 1.88614
I0811 03:57:10.704244 10215 solver.cpp:258]     Train net output #0: loss = 1.88614 (* 1 = 1.88614 loss)
I0811 03:57:10.704250 10215 sgd_solver.cpp:112] Iteration 6930, lr = 0.01
I0811 03:57:23.318518 10215 solver.cpp:239] Iteration 7000 (5.54942 iter/s, 12.6139s/70 iters), loss = 1.25043
I0811 03:57:23.318547 10215 solver.cpp:258]     Train net output #0: loss = 1.25043 (* 1 = 1.25043 loss)
I0811 03:57:23.318557 10215 sgd_solver.cpp:112] Iteration 7000, lr = 0.01
I0811 03:57:35.940052 10215 solver.cpp:239] Iteration 7070 (5.54624 iter/s, 12.6212s/70 iters), loss = 0.321549
I0811 03:57:35.940188 10215 solver.cpp:258]     Train net output #0: loss = 0.32155 (* 1 = 0.32155 loss)
I0811 03:57:35.940196 10215 sgd_solver.cpp:112] Iteration 7070, lr = 0.01
I0811 03:57:48.565812 10215 solver.cpp:239] Iteration 7140 (5.54443 iter/s, 12.6253s/70 iters), loss = 0.832846
I0811 03:57:48.565843 10215 solver.cpp:258]     Train net output #0: loss = 0.832847 (* 1 = 0.832847 loss)
I0811 03:57:48.565850 10215 sgd_solver.cpp:112] Iteration 7140, lr = 0.01
I0811 03:58:01.175619 10215 solver.cpp:239] Iteration 7210 (5.5514 iter/s, 12.6094s/70 iters), loss = 1.7876
I0811 03:58:01.175644 10215 solver.cpp:258]     Train net output #0: loss = 1.7876 (* 1 = 1.7876 loss)
I0811 03:58:01.175649 10215 sgd_solver.cpp:112] Iteration 7210, lr = 0.01
I0811 03:58:13.798184 10215 solver.cpp:239] Iteration 7280 (5.54579 iter/s, 12.6222s/70 iters), loss = 0.527166
I0811 03:58:13.798342 10215 solver.cpp:258]     Train net output #0: loss = 0.527167 (* 1 = 0.527167 loss)
I0811 03:58:13.798349 10215 sgd_solver.cpp:112] Iteration 7280, lr = 0.01
I0811 03:58:15.667645 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:58:18.225421 10215 solver.cpp:347] Iteration 7306, Testing net (#0)
I0811 03:58:18.225437 10215 net.cpp:676] Ignoring source layer train-data
I0811 03:58:34.475589 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 03:58:35.231463 10215 solver.cpp:414]     Test net output #0: accuracy = 0.832833
I0811 03:58:35.231485 10215 solver.cpp:414]     Test net output #1: loss = 1.10482 (* 1 = 1.10482 loss)
I0811 03:58:43.352131 10215 solver.cpp:239] Iteration 7350 (2.36863 iter/s, 29.553s/70 iters), loss = 1.37866
I0811 03:58:43.352156 10215 solver.cpp:258]     Train net output #0: loss = 1.37866 (* 1 = 1.37866 loss)
I0811 03:58:43.352162 10215 sgd_solver.cpp:112] Iteration 7350, lr = 0.01
I0811 03:58:55.968515 10215 solver.cpp:239] Iteration 7420 (5.5485 iter/s, 12.616s/70 iters), loss = 1.17688
I0811 03:58:55.968655 10215 solver.cpp:258]     Train net output #0: loss = 1.17688 (* 1 = 1.17688 loss)
I0811 03:58:55.968663 10215 sgd_solver.cpp:112] Iteration 7420, lr = 0.01
I0811 03:59:08.579951 10215 solver.cpp:239] Iteration 7490 (5.55073 iter/s, 12.611s/70 iters), loss = 0.252139
I0811 03:59:08.579977 10215 solver.cpp:258]     Train net output #0: loss = 0.25214 (* 1 = 0.25214 loss)
I0811 03:59:08.579983 10215 sgd_solver.cpp:112] Iteration 7490, lr = 0.01
I0811 03:59:21.193419 10215 solver.cpp:239] Iteration 7560 (5.54979 iter/s, 12.6131s/70 iters), loss = 0.901132
I0811 03:59:21.193446 10215 solver.cpp:258]     Train net output #0: loss = 0.901133 (* 1 = 0.901133 loss)
I0811 03:59:21.193451 10215 sgd_solver.cpp:112] Iteration 7560, lr = 0.01
I0811 03:59:33.823706 10215 solver.cpp:239] Iteration 7630 (5.5424 iter/s, 12.6299s/70 iters), loss = 1.50927
I0811 03:59:33.823848 10215 solver.cpp:258]     Train net output #0: loss = 1.50927 (* 1 = 1.50927 loss)
I0811 03:59:33.823856 10215 sgd_solver.cpp:112] Iteration 7630, lr = 0.01
I0811 03:59:46.437973 10215 solver.cpp:239] Iteration 7700 (5.54949 iter/s, 12.6138s/70 iters), loss = 0.925655
I0811 03:59:46.438004 10215 solver.cpp:258]     Train net output #0: loss = 0.925656 (* 1 = 0.925656 loss)
I0811 03:59:46.438009 10215 sgd_solver.cpp:112] Iteration 7700, lr = 0.01
I0811 03:59:59.064050 10215 solver.cpp:239] Iteration 7770 (5.54425 iter/s, 12.6257s/70 iters), loss = 1.49181
I0811 03:59:59.064075 10215 solver.cpp:258]     Train net output #0: loss = 1.49181 (* 1 = 1.49181 loss)
I0811 03:59:59.064080 10215 sgd_solver.cpp:112] Iteration 7770, lr = 0.01
I0811 04:00:11.676826 10215 solver.cpp:239] Iteration 7840 (5.55009 iter/s, 12.6124s/70 iters), loss = 0.982993
I0811 04:00:11.676987 10215 solver.cpp:258]     Train net output #0: loss = 0.982994 (* 1 = 0.982994 loss)
I0811 04:00:11.676995 10215 sgd_solver.cpp:112] Iteration 7840, lr = 0.01
I0811 04:00:13.731606 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:00:16.463023 10215 solver.cpp:347] Iteration 7868, Testing net (#0)
I0811 04:00:16.463038 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:00:32.679064 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:00:33.477524 10215 solver.cpp:414]     Test net output #0: accuracy = 0.830333
I0811 04:00:33.477550 10215 solver.cpp:414]     Test net output #1: loss = 1.12015 (* 1 = 1.12015 loss)
I0811 04:00:41.242584 10215 solver.cpp:239] Iteration 7910 (2.36768 iter/s, 29.5648s/70 iters), loss = 0.536116
I0811 04:00:41.242627 10215 solver.cpp:258]     Train net output #0: loss = 0.536117 (* 1 = 0.536117 loss)
I0811 04:00:41.242633 10215 sgd_solver.cpp:112] Iteration 7910, lr = 0.01
I0811 04:00:53.867260 10215 solver.cpp:239] Iteration 7980 (5.54487 iter/s, 12.6243s/70 iters), loss = 0.294123
I0811 04:00:53.867404 10215 solver.cpp:258]     Train net output #0: loss = 0.294124 (* 1 = 0.294124 loss)
I0811 04:00:53.867411 10215 sgd_solver.cpp:112] Iteration 7980, lr = 0.01
I0811 04:01:06.488847 10215 solver.cpp:239] Iteration 8050 (5.54627 iter/s, 12.6211s/70 iters), loss = 0.0616564
I0811 04:01:06.488874 10215 solver.cpp:258]     Train net output #0: loss = 0.0616574 (* 1 = 0.0616574 loss)
I0811 04:01:06.488879 10215 sgd_solver.cpp:112] Iteration 8050, lr = 0.01
I0811 04:01:19.123900 10215 solver.cpp:239] Iteration 8120 (5.54031 iter/s, 12.6347s/70 iters), loss = 0.121049
I0811 04:01:19.123929 10215 solver.cpp:258]     Train net output #0: loss = 0.12105 (* 1 = 0.12105 loss)
I0811 04:01:19.123934 10215 sgd_solver.cpp:112] Iteration 8120, lr = 0.01
I0811 04:01:31.760562 10215 solver.cpp:239] Iteration 8190 (5.5396 iter/s, 12.6363s/70 iters), loss = 0.157542
I0811 04:01:31.760702 10215 solver.cpp:258]     Train net output #0: loss = 0.157543 (* 1 = 0.157543 loss)
I0811 04:01:31.760710 10215 sgd_solver.cpp:112] Iteration 8190, lr = 0.01
I0811 04:01:44.394258 10215 solver.cpp:239] Iteration 8260 (5.54095 iter/s, 12.6332s/70 iters), loss = 0.123513
I0811 04:01:44.394286 10215 solver.cpp:258]     Train net output #0: loss = 0.123514 (* 1 = 0.123514 loss)
I0811 04:01:44.394292 10215 sgd_solver.cpp:112] Iteration 8260, lr = 0.01
I0811 04:01:57.024210 10215 solver.cpp:239] Iteration 8330 (5.54255 iter/s, 12.6296s/70 iters), loss = 0.0308286
I0811 04:01:57.024240 10215 solver.cpp:258]     Train net output #0: loss = 0.0308295 (* 1 = 0.0308295 loss)
I0811 04:01:57.024245 10215 sgd_solver.cpp:112] Iteration 8330, lr = 0.01
I0811 04:02:09.653161 10215 solver.cpp:239] Iteration 8400 (5.54298 iter/s, 12.6286s/70 iters), loss = 0.482435
I0811 04:02:09.653302 10215 solver.cpp:258]     Train net output #0: loss = 0.482436 (* 1 = 0.482436 loss)
I0811 04:02:09.653311 10215 sgd_solver.cpp:112] Iteration 8400, lr = 0.01
I0811 04:02:11.892933 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:02:14.794018 10215 solver.cpp:347] Iteration 8430, Testing net (#0)
I0811 04:02:14.794032 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:02:31.163502 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:02:32.004328 10215 solver.cpp:414]     Test net output #0: accuracy = 0.952167
I0811 04:02:32.004353 10215 solver.cpp:414]     Test net output #1: loss = 0.160387 (* 1 = 0.160387 loss)
I0811 04:02:39.392443 10215 solver.cpp:239] Iteration 8470 (2.35386 iter/s, 29.7383s/70 iters), loss = 0.0636369
I0811 04:02:39.392469 10215 solver.cpp:258]     Train net output #0: loss = 0.0636379 (* 1 = 0.0636379 loss)
I0811 04:02:39.392475 10215 sgd_solver.cpp:112] Iteration 8470, lr = 0.01
I0811 04:02:52.016018 10215 solver.cpp:239] Iteration 8540 (5.54534 iter/s, 12.6232s/70 iters), loss = 0.120297
I0811 04:02:52.016082 10215 solver.cpp:258]     Train net output #0: loss = 0.120298 (* 1 = 0.120298 loss)
I0811 04:02:52.016088 10215 sgd_solver.cpp:112] Iteration 8540, lr = 0.01
I0811 04:03:04.617538 10215 solver.cpp:239] Iteration 8610 (5.55506 iter/s, 12.6011s/70 iters), loss = 0.104031
I0811 04:03:04.617565 10215 solver.cpp:258]     Train net output #0: loss = 0.104032 (* 1 = 0.104032 loss)
I0811 04:03:04.617571 10215 sgd_solver.cpp:112] Iteration 8610, lr = 0.01
I0811 04:03:17.228271 10215 solver.cpp:239] Iteration 8680 (5.55099 iter/s, 12.6104s/70 iters), loss = 0.0277294
I0811 04:03:17.228317 10215 solver.cpp:258]     Train net output #0: loss = 0.0277304 (* 1 = 0.0277304 loss)
I0811 04:03:17.228322 10215 sgd_solver.cpp:112] Iteration 8680, lr = 0.01
I0811 04:03:29.843624 10215 solver.cpp:239] Iteration 8750 (5.54896 iter/s, 12.615s/70 iters), loss = 0.0935377
I0811 04:03:29.843765 10215 solver.cpp:258]     Train net output #0: loss = 0.0935387 (* 1 = 0.0935387 loss)
I0811 04:03:29.843772 10215 sgd_solver.cpp:112] Iteration 8750, lr = 0.01
I0811 04:03:42.454331 10215 solver.cpp:239] Iteration 8820 (5.55105 iter/s, 12.6102s/70 iters), loss = 0.0711031
I0811 04:03:42.454360 10215 solver.cpp:258]     Train net output #0: loss = 0.0711042 (* 1 = 0.0711042 loss)
I0811 04:03:42.454365 10215 sgd_solver.cpp:112] Iteration 8820, lr = 0.01
I0811 04:03:55.079695 10215 solver.cpp:239] Iteration 8890 (5.54456 iter/s, 12.625s/70 iters), loss = 0.11167
I0811 04:03:55.079722 10215 solver.cpp:258]     Train net output #0: loss = 0.111671 (* 1 = 0.111671 loss)
I0811 04:03:55.079728 10215 sgd_solver.cpp:112] Iteration 8890, lr = 0.01
I0811 04:04:07.680979 10215 solver.cpp:239] Iteration 8960 (5.55515 iter/s, 12.6009s/70 iters), loss = 0.164343
I0811 04:04:07.681118 10215 solver.cpp:258]     Train net output #0: loss = 0.164344 (* 1 = 0.164344 loss)
I0811 04:04:07.681126 10215 sgd_solver.cpp:112] Iteration 8960, lr = 0.01
I0811 04:04:10.123651 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:04:13.192400 10215 solver.cpp:347] Iteration 8992, Testing net (#0)
I0811 04:04:13.192414 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:04:29.260252 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:04:29.382302 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:04:30.161253 10215 solver.cpp:414]     Test net output #0: accuracy = 0.964501
I0811 04:04:30.161278 10215 solver.cpp:414]     Test net output #1: loss = 0.102376 (* 1 = 0.102376 loss)
I0811 04:04:37.198729 10215 solver.cpp:239] Iteration 9030 (2.37153 iter/s, 29.5168s/70 iters), loss = 0.0873998
I0811 04:04:37.198755 10215 solver.cpp:258]     Train net output #0: loss = 0.0874007 (* 1 = 0.0874007 loss)
I0811 04:04:37.198760 10215 sgd_solver.cpp:112] Iteration 9030, lr = 0.01
I0811 04:04:49.823465 10215 solver.cpp:239] Iteration 9100 (5.54484 iter/s, 12.6244s/70 iters), loss = 0.139196
I0811 04:04:49.823606 10215 solver.cpp:258]     Train net output #0: loss = 0.139196 (* 1 = 0.139196 loss)
I0811 04:04:49.823611 10215 sgd_solver.cpp:112] Iteration 9100, lr = 0.01
I0811 04:05:02.446414 10215 solver.cpp:239] Iteration 9170 (5.54567 iter/s, 12.6225s/70 iters), loss = 0.100664
I0811 04:05:02.446444 10215 solver.cpp:258]     Train net output #0: loss = 0.100665 (* 1 = 0.100665 loss)
I0811 04:05:02.446450 10215 sgd_solver.cpp:112] Iteration 9170, lr = 0.01
I0811 04:05:15.086674 10215 solver.cpp:239] Iteration 9240 (5.53802 iter/s, 12.6399s/70 iters), loss = 0.105621
I0811 04:05:15.086700 10215 solver.cpp:258]     Train net output #0: loss = 0.105622 (* 1 = 0.105622 loss)
I0811 04:05:15.086706 10215 sgd_solver.cpp:112] Iteration 9240, lr = 0.01
I0811 04:05:27.714588 10215 solver.cpp:239] Iteration 9310 (5.54344 iter/s, 12.6275s/70 iters), loss = 0.259989
I0811 04:05:27.714705 10215 solver.cpp:258]     Train net output #0: loss = 0.25999 (* 1 = 0.25999 loss)
I0811 04:05:27.714712 10215 sgd_solver.cpp:112] Iteration 9310, lr = 0.01
I0811 04:05:40.351362 10215 solver.cpp:239] Iteration 9380 (5.53959 iter/s, 12.6363s/70 iters), loss = 0.153543
I0811 04:05:40.351389 10215 solver.cpp:258]     Train net output #0: loss = 0.153543 (* 1 = 0.153543 loss)
I0811 04:05:40.351395 10215 sgd_solver.cpp:112] Iteration 9380, lr = 0.01
I0811 04:05:52.975677 10215 solver.cpp:239] Iteration 9450 (5.54502 iter/s, 12.6239s/70 iters), loss = 0.190327
I0811 04:05:52.975704 10215 solver.cpp:258]     Train net output #0: loss = 0.190328 (* 1 = 0.190328 loss)
I0811 04:05:52.975710 10215 sgd_solver.cpp:112] Iteration 9450, lr = 0.01
I0811 04:06:05.593780 10215 solver.cpp:239] Iteration 9520 (5.54775 iter/s, 12.6177s/70 iters), loss = 0.17068
I0811 04:06:05.593919 10215 solver.cpp:258]     Train net output #0: loss = 0.170681 (* 1 = 0.170681 loss)
I0811 04:06:05.593926 10215 sgd_solver.cpp:112] Iteration 9520, lr = 0.01
I0811 04:06:08.319207 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:06:11.461035 10215 solver.cpp:347] Iteration 9554, Testing net (#0)
I0811 04:06:11.461050 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:06:27.485298 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:06:28.446642 10215 solver.cpp:414]     Test net output #0: accuracy = 0.940167
I0811 04:06:28.446677 10215 solver.cpp:414]     Test net output #1: loss = 0.184328 (* 1 = 0.184328 loss)
I0811 04:06:35.123700 10215 solver.cpp:239] Iteration 9590 (2.37055 iter/s, 29.529s/70 iters), loss = 0.186141
I0811 04:06:35.123726 10215 solver.cpp:258]     Train net output #0: loss = 0.186142 (* 1 = 0.186142 loss)
I0811 04:06:35.123731 10215 sgd_solver.cpp:112] Iteration 9590, lr = 0.01
I0811 04:06:47.744380 10215 solver.cpp:239] Iteration 9660 (5.54661 iter/s, 12.6203s/70 iters), loss = 0.220427
I0811 04:06:47.744521 10215 solver.cpp:258]     Train net output #0: loss = 0.220428 (* 1 = 0.220428 loss)
I0811 04:06:47.744529 10215 sgd_solver.cpp:112] Iteration 9660, lr = 0.01
I0811 04:07:00.372771 10215 solver.cpp:239] Iteration 9730 (5.54328 iter/s, 12.6279s/70 iters), loss = 0.318723
I0811 04:07:00.372798 10215 solver.cpp:258]     Train net output #0: loss = 0.318724 (* 1 = 0.318724 loss)
I0811 04:07:00.372804 10215 sgd_solver.cpp:112] Iteration 9730, lr = 0.01
I0811 04:07:12.993202 10215 solver.cpp:239] Iteration 9800 (5.54672 iter/s, 12.6201s/70 iters), loss = 0.0848493
I0811 04:07:12.993228 10215 solver.cpp:258]     Train net output #0: loss = 0.08485 (* 1 = 0.08485 loss)
I0811 04:07:12.993234 10215 sgd_solver.cpp:112] Iteration 9800, lr = 0.01
I0811 04:07:25.592800 10215 solver.cpp:239] Iteration 9870 (5.5559 iter/s, 12.5992s/70 iters), loss = 0.0744468
I0811 04:07:25.592938 10215 solver.cpp:258]     Train net output #0: loss = 0.0744475 (* 1 = 0.0744475 loss)
I0811 04:07:25.592947 10215 sgd_solver.cpp:112] Iteration 9870, lr = 0.01
I0811 04:07:38.195089 10215 solver.cpp:239] Iteration 9940 (5.55476 iter/s, 12.6018s/70 iters), loss = 0.0164649
I0811 04:07:38.195119 10215 solver.cpp:258]     Train net output #0: loss = 0.0164655 (* 1 = 0.0164655 loss)
I0811 04:07:38.195127 10215 sgd_solver.cpp:112] Iteration 9940, lr = 0.01
I0811 04:07:50.808295 10215 solver.cpp:239] Iteration 10010 (5.5499 iter/s, 12.6128s/70 iters), loss = 0.0220708
I0811 04:07:50.808320 10215 solver.cpp:258]     Train net output #0: loss = 0.0220714 (* 1 = 0.0220714 loss)
I0811 04:07:50.808326 10215 sgd_solver.cpp:112] Iteration 10010, lr = 0.01
I0811 04:08:03.431388 10215 solver.cpp:239] Iteration 10080 (5.54555 iter/s, 12.6227s/70 iters), loss = 0.0473998
I0811 04:08:03.431525 10215 solver.cpp:258]     Train net output #0: loss = 0.0474004 (* 1 = 0.0474004 loss)
I0811 04:08:03.431535 10215 sgd_solver.cpp:112] Iteration 10080, lr = 0.01
I0811 04:08:06.352958 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:08:09.659878 10215 solver.cpp:347] Iteration 10116, Testing net (#0)
I0811 04:08:09.659893 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:08:25.548341 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:08:26.549762 10215 solver.cpp:414]     Test net output #0: accuracy = 0.962834
I0811 04:08:26.549787 10215 solver.cpp:414]     Test net output #1: loss = 0.104908 (* 1 = 0.104908 loss)
I0811 04:08:32.855772 10215 solver.cpp:239] Iteration 10150 (2.37905 iter/s, 29.4235s/70 iters), loss = 0.0297813
I0811 04:08:32.855804 10215 solver.cpp:258]     Train net output #0: loss = 0.0297818 (* 1 = 0.0297818 loss)
I0811 04:08:32.855810 10215 sgd_solver.cpp:112] Iteration 10150, lr = 0.01
I0811 04:08:45.479704 10215 solver.cpp:239] Iteration 10220 (5.54519 iter/s, 12.6236s/70 iters), loss = 0.0192366
I0811 04:08:45.479858 10215 solver.cpp:258]     Train net output #0: loss = 0.0192372 (* 1 = 0.0192372 loss)
I0811 04:08:45.479866 10215 sgd_solver.cpp:112] Iteration 10220, lr = 0.01
I0811 04:08:58.103277 10215 solver.cpp:239] Iteration 10290 (5.5454 iter/s, 12.6231s/70 iters), loss = 0.0433636
I0811 04:08:58.103305 10215 solver.cpp:258]     Train net output #0: loss = 0.0433641 (* 1 = 0.0433641 loss)
I0811 04:08:58.103310 10215 sgd_solver.cpp:112] Iteration 10290, lr = 0.01
I0811 04:09:10.716027 10215 solver.cpp:239] Iteration 10360 (5.5501 iter/s, 12.6124s/70 iters), loss = 0.047618
I0811 04:09:10.716054 10215 solver.cpp:258]     Train net output #0: loss = 0.0476185 (* 1 = 0.0476185 loss)
I0811 04:09:10.716060 10215 sgd_solver.cpp:112] Iteration 10360, lr = 0.01
I0811 04:09:23.338716 10215 solver.cpp:239] Iteration 10430 (5.54573 iter/s, 12.6223s/70 iters), loss = 0.0856191
I0811 04:09:23.338855 10215 solver.cpp:258]     Train net output #0: loss = 0.0856197 (* 1 = 0.0856197 loss)
I0811 04:09:23.338863 10215 sgd_solver.cpp:112] Iteration 10430, lr = 0.01
I0811 04:09:35.961021 10215 solver.cpp:239] Iteration 10500 (5.54595 iter/s, 12.6218s/70 iters), loss = 0.0104324
I0811 04:09:35.961053 10215 solver.cpp:258]     Train net output #0: loss = 0.0104329 (* 1 = 0.0104329 loss)
I0811 04:09:35.961060 10215 sgd_solver.cpp:112] Iteration 10500, lr = 0.01
I0811 04:09:48.576874 10215 solver.cpp:239] Iteration 10570 (5.54874 iter/s, 12.6155s/70 iters), loss = 0.0509236
I0811 04:09:48.576900 10215 solver.cpp:258]     Train net output #0: loss = 0.0509241 (* 1 = 0.0509241 loss)
I0811 04:09:48.576906 10215 sgd_solver.cpp:112] Iteration 10570, lr = 0.01
I0811 04:10:01.199597 10215 solver.cpp:239] Iteration 10640 (5.54572 iter/s, 12.6224s/70 iters), loss = 0.0579004
I0811 04:10:01.199736 10215 solver.cpp:258]     Train net output #0: loss = 0.0579009 (* 1 = 0.0579009 loss)
I0811 04:10:01.199744 10215 sgd_solver.cpp:112] Iteration 10640, lr = 0.01
I0811 04:10:04.309229 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:10:07.787191 10215 solver.cpp:347] Iteration 10678, Testing net (#0)
I0811 04:10:07.787204 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:10:23.722302 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:10:24.789953 10215 solver.cpp:414]     Test net output #0: accuracy = 0.984334
I0811 04:10:24.789980 10215 solver.cpp:414]     Test net output #1: loss = 0.0580752 (* 1 = 0.0580752 loss)
I0811 04:10:30.750102 10215 solver.cpp:239] Iteration 10710 (2.3689 iter/s, 29.5496s/70 iters), loss = 0.0815814
I0811 04:10:30.750130 10215 solver.cpp:258]     Train net output #0: loss = 0.081582 (* 1 = 0.081582 loss)
I0811 04:10:30.750136 10215 sgd_solver.cpp:112] Iteration 10710, lr = 0.01
I0811 04:10:43.352715 10215 solver.cpp:239] Iteration 10780 (5.55457 iter/s, 12.6022s/70 iters), loss = 0.162546
I0811 04:10:43.352847 10215 solver.cpp:258]     Train net output #0: loss = 0.162547 (* 1 = 0.162547 loss)
I0811 04:10:43.352855 10215 sgd_solver.cpp:112] Iteration 10780, lr = 0.01
I0811 04:10:55.967557 10215 solver.cpp:239] Iteration 10850 (5.54923 iter/s, 12.6144s/70 iters), loss = 0.0231424
I0811 04:10:55.967586 10215 solver.cpp:258]     Train net output #0: loss = 0.023143 (* 1 = 0.023143 loss)
I0811 04:10:55.967592 10215 sgd_solver.cpp:112] Iteration 10850, lr = 0.01
I0811 04:11:08.605370 10215 solver.cpp:239] Iteration 10920 (5.5391 iter/s, 12.6374s/70 iters), loss = 0.0240736
I0811 04:11:08.605397 10215 solver.cpp:258]     Train net output #0: loss = 0.0240742 (* 1 = 0.0240742 loss)
I0811 04:11:08.605402 10215 sgd_solver.cpp:112] Iteration 10920, lr = 0.01
I0811 04:11:21.239526 10215 solver.cpp:239] Iteration 10990 (5.5407 iter/s, 12.6338s/70 iters), loss = 0.0310145
I0811 04:11:21.239683 10215 solver.cpp:258]     Train net output #0: loss = 0.0310151 (* 1 = 0.0310151 loss)
I0811 04:11:21.239691 10215 sgd_solver.cpp:112] Iteration 10990, lr = 0.01
I0811 04:11:33.859869 10215 solver.cpp:239] Iteration 11060 (5.54681 iter/s, 12.6199s/70 iters), loss = 0.117156
I0811 04:11:33.859897 10215 solver.cpp:258]     Train net output #0: loss = 0.117156 (* 1 = 0.117156 loss)
I0811 04:11:33.859902 10215 sgd_solver.cpp:112] Iteration 11060, lr = 0.01
I0811 04:11:46.481703 10215 solver.cpp:239] Iteration 11130 (5.54611 iter/s, 12.6215s/70 iters), loss = 0.0176138
I0811 04:11:46.481731 10215 solver.cpp:258]     Train net output #0: loss = 0.0176143 (* 1 = 0.0176143 loss)
I0811 04:11:46.481737 10215 sgd_solver.cpp:112] Iteration 11130, lr = 0.01
I0811 04:11:59.110282 10215 solver.cpp:239] Iteration 11200 (5.54315 iter/s, 12.6282s/70 iters), loss = 0.0333821
I0811 04:11:59.110401 10215 solver.cpp:258]     Train net output #0: loss = 0.0333827 (* 1 = 0.0333827 loss)
I0811 04:11:59.110422 10215 sgd_solver.cpp:112] Iteration 11200, lr = 0.01
I0811 04:12:02.408838 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:12:06.058719 10215 solver.cpp:464] Snapshotting to binary proto file snapshot_iter_11240.caffemodel
I0811 04:12:06.157101 10215 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshot_iter_11240.solverstate
I0811 04:12:06.161548 10215 solver.cpp:347] Iteration 11240, Testing net (#0)
I0811 04:12:06.161561 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:12:21.974421 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:12:23.077745 10215 solver.cpp:414]     Test net output #0: accuracy = 0.980501
I0811 04:12:23.077769 10215 solver.cpp:414]     Test net output #1: loss = 0.0599057 (* 1 = 0.0599057 loss)
I0811 04:12:28.669358 10215 solver.cpp:239] Iteration 11270 (2.36821 iter/s, 29.5582s/70 iters), loss = 0.0849424
I0811 04:12:28.669383 10215 solver.cpp:258]     Train net output #0: loss = 0.084943 (* 1 = 0.084943 loss)
I0811 04:12:28.669389 10215 sgd_solver.cpp:112] Iteration 11270, lr = 0.01
I0811 04:12:41.291851 10215 solver.cpp:239] Iteration 11340 (5.54582 iter/s, 12.6221s/70 iters), loss = 0.0150629
I0811 04:12:41.291996 10215 solver.cpp:258]     Train net output #0: loss = 0.0150635 (* 1 = 0.0150635 loss)
I0811 04:12:41.292003 10215 sgd_solver.cpp:112] Iteration 11340, lr = 0.01
I0811 04:12:53.916007 10215 solver.cpp:239] Iteration 11410 (5.54514 iter/s, 12.6237s/70 iters), loss = 0.0940394
I0811 04:12:53.916034 10215 solver.cpp:258]     Train net output #0: loss = 0.0940399 (* 1 = 0.0940399 loss)
I0811 04:12:53.916039 10215 sgd_solver.cpp:112] Iteration 11410, lr = 0.01
I0811 04:13:06.552258 10215 solver.cpp:239] Iteration 11480 (5.53978 iter/s, 12.6359s/70 iters), loss = 0.0396639
I0811 04:13:06.552286 10215 solver.cpp:258]     Train net output #0: loss = 0.0396645 (* 1 = 0.0396645 loss)
I0811 04:13:06.552292 10215 sgd_solver.cpp:112] Iteration 11480, lr = 0.01
I0811 04:13:19.176268 10215 solver.cpp:239] Iteration 11550 (5.54515 iter/s, 12.6236s/70 iters), loss = 0.100888
I0811 04:13:19.176401 10215 solver.cpp:258]     Train net output #0: loss = 0.100889 (* 1 = 0.100889 loss)
I0811 04:13:19.176409 10215 sgd_solver.cpp:112] Iteration 11550, lr = 0.01
I0811 04:13:31.804293 10215 solver.cpp:239] Iteration 11620 (5.54343 iter/s, 12.6276s/70 iters), loss = 0.00314595
I0811 04:13:31.804320 10215 solver.cpp:258]     Train net output #0: loss = 0.00314648 (* 1 = 0.00314648 loss)
I0811 04:13:31.804327 10215 sgd_solver.cpp:112] Iteration 11620, lr = 0.01
I0811 04:13:44.433941 10215 solver.cpp:239] Iteration 11690 (5.54268 iter/s, 12.6293s/70 iters), loss = 0.10384
I0811 04:13:44.433974 10215 solver.cpp:258]     Train net output #0: loss = 0.103841 (* 1 = 0.103841 loss)
I0811 04:13:44.433980 10215 sgd_solver.cpp:112] Iteration 11690, lr = 0.01
I0811 04:13:57.069973 10215 solver.cpp:239] Iteration 11760 (5.53988 iter/s, 12.6357s/70 iters), loss = 0.0202499
I0811 04:13:57.070997 10215 solver.cpp:258]     Train net output #0: loss = 0.0202505 (* 1 = 0.0202505 loss)
I0811 04:13:57.071007 10215 sgd_solver.cpp:112] Iteration 11760, lr = 0.01
I0811 04:14:00.567795 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:14:04.389607 10215 solver.cpp:347] Iteration 11802, Testing net (#0)
I0811 04:14:04.389622 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:14:07.766854 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:14:20.242238 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:14:21.394780 10215 solver.cpp:414]     Test net output #0: accuracy = 0.967001
I0811 04:14:21.394804 10215 solver.cpp:414]     Test net output #1: loss = 0.103847 (* 1 = 0.103847 loss)
I0811 04:14:26.635900 10215 solver.cpp:239] Iteration 11830 (2.36774 iter/s, 29.5641s/70 iters), loss = 0.212596
I0811 04:14:26.635927 10215 solver.cpp:258]     Train net output #0: loss = 0.212596 (* 1 = 0.212596 loss)
I0811 04:14:26.635933 10215 sgd_solver.cpp:112] Iteration 11830, lr = 0.01
I0811 04:14:39.240380 10215 solver.cpp:239] Iteration 11900 (5.55374 iter/s, 12.6041s/70 iters), loss = 0.0245732
I0811 04:14:39.240517 10215 solver.cpp:258]     Train net output #0: loss = 0.0245737 (* 1 = 0.0245737 loss)
I0811 04:14:39.240525 10215 sgd_solver.cpp:112] Iteration 11900, lr = 0.01
I0811 04:14:51.850541 10215 solver.cpp:239] Iteration 11970 (5.55129 iter/s, 12.6097s/70 iters), loss = 0.0670539
I0811 04:14:51.850570 10215 solver.cpp:258]     Train net output #0: loss = 0.0670545 (* 1 = 0.0670545 loss)
I0811 04:14:51.850576 10215 sgd_solver.cpp:112] Iteration 11970, lr = 0.01
I0811 04:15:04.470069 10215 solver.cpp:239] Iteration 12040 (5.54712 iter/s, 12.6192s/70 iters), loss = 0.125379
I0811 04:15:04.470098 10215 solver.cpp:258]     Train net output #0: loss = 0.125379 (* 1 = 0.125379 loss)
I0811 04:15:04.470104 10215 sgd_solver.cpp:112] Iteration 12040, lr = 0.01
I0811 04:15:17.084165 10215 solver.cpp:239] Iteration 12110 (5.54951 iter/s, 12.6137s/70 iters), loss = 0.262257
I0811 04:15:17.084218 10215 solver.cpp:258]     Train net output #0: loss = 0.262258 (* 1 = 0.262258 loss)
I0811 04:15:17.084224 10215 sgd_solver.cpp:112] Iteration 12110, lr = 0.01
I0811 04:15:29.697046 10215 solver.cpp:239] Iteration 12180 (5.55006 iter/s, 12.6125s/70 iters), loss = 0.0434178
I0811 04:15:29.697072 10215 solver.cpp:258]     Train net output #0: loss = 0.0434183 (* 1 = 0.0434183 loss)
I0811 04:15:29.697078 10215 sgd_solver.cpp:112] Iteration 12180, lr = 0.01
I0811 04:15:42.302341 10215 solver.cpp:239] Iteration 12250 (5.55338 iter/s, 12.6049s/70 iters), loss = 0.0100606
I0811 04:15:42.302368 10215 solver.cpp:258]     Train net output #0: loss = 0.0100611 (* 1 = 0.0100611 loss)
I0811 04:15:42.302374 10215 sgd_solver.cpp:112] Iteration 12250, lr = 0.01
I0811 04:15:54.923650 10215 solver.cpp:239] Iteration 12320 (5.54634 iter/s, 12.6209s/70 iters), loss = 0.0383843
I0811 04:15:54.923737 10215 solver.cpp:258]     Train net output #0: loss = 0.0383849 (* 1 = 0.0383849 loss)
I0811 04:15:54.923755 10215 sgd_solver.cpp:112] Iteration 12320, lr = 0.01
I0811 04:15:58.599258 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:16:02.597034 10215 solver.cpp:347] Iteration 12364, Testing net (#0)
I0811 04:16:02.597049 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:16:18.276885 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:16:19.482295 10215 solver.cpp:414]     Test net output #0: accuracy = 0.983334
I0811 04:16:19.482318 10215 solver.cpp:414]     Test net output #1: loss = 0.048792 (* 1 = 0.048792 loss)
I0811 04:16:24.358886 10215 solver.cpp:239] Iteration 12390 (2.37817 iter/s, 29.4344s/70 iters), loss = 0.00943567
I0811 04:16:24.358914 10215 solver.cpp:258]     Train net output #0: loss = 0.00943621 (* 1 = 0.00943621 loss)
I0811 04:16:24.358919 10215 sgd_solver.cpp:112] Iteration 12390, lr = 0.01
I0811 04:16:36.979460 10215 solver.cpp:239] Iteration 12460 (5.54666 iter/s, 12.6202s/70 iters), loss = 0.0236772
I0811 04:16:36.979589 10215 solver.cpp:258]     Train net output #0: loss = 0.0236778 (* 1 = 0.0236778 loss)
I0811 04:16:36.979596 10215 sgd_solver.cpp:112] Iteration 12460, lr = 0.01
I0811 04:16:49.593672 10215 solver.cpp:239] Iteration 12530 (5.5495 iter/s, 12.6138s/70 iters), loss = 0.150663
I0811 04:16:49.593699 10215 solver.cpp:258]     Train net output #0: loss = 0.150664 (* 1 = 0.150664 loss)
I0811 04:16:49.593705 10215 sgd_solver.cpp:112] Iteration 12530, lr = 0.01
I0811 04:17:02.215965 10215 solver.cpp:239] Iteration 12600 (5.54591 iter/s, 12.6219s/70 iters), loss = 0.0200669
I0811 04:17:02.215993 10215 solver.cpp:258]     Train net output #0: loss = 0.0200674 (* 1 = 0.0200674 loss)
I0811 04:17:02.215999 10215 sgd_solver.cpp:112] Iteration 12600, lr = 0.01
I0811 04:17:14.823247 10215 solver.cpp:239] Iteration 12670 (5.55251 iter/s, 12.6069s/70 iters), loss = 0.0753457
I0811 04:17:14.823307 10215 solver.cpp:258]     Train net output #0: loss = 0.0753461 (* 1 = 0.0753461 loss)
I0811 04:17:14.823313 10215 sgd_solver.cpp:112] Iteration 12670, lr = 0.01
I0811 04:17:27.456570 10215 solver.cpp:239] Iteration 12740 (5.54108 iter/s, 12.6329s/70 iters), loss = 0.0852425
I0811 04:17:27.456598 10215 solver.cpp:258]     Train net output #0: loss = 0.085243 (* 1 = 0.085243 loss)
I0811 04:17:27.456604 10215 sgd_solver.cpp:112] Iteration 12740, lr = 0.01
I0811 04:17:40.079157 10215 solver.cpp:239] Iteration 12810 (5.54578 iter/s, 12.6222s/70 iters), loss = 0.116123
I0811 04:17:40.079185 10215 solver.cpp:258]     Train net output #0: loss = 0.116124 (* 1 = 0.116124 loss)
I0811 04:17:40.079191 10215 sgd_solver.cpp:112] Iteration 12810, lr = 0.01
I0811 04:17:52.715343 10215 solver.cpp:239] Iteration 12880 (5.53981 iter/s, 12.6358s/70 iters), loss = 0.0321204
I0811 04:17:52.715473 10215 solver.cpp:258]     Train net output #0: loss = 0.0321209 (* 1 = 0.0321209 loss)
I0811 04:17:52.715492 10215 sgd_solver.cpp:112] Iteration 12880, lr = 0.01
I0811 04:17:56.582567 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:18:00.744469 10215 solver.cpp:347] Iteration 12926, Testing net (#0)
I0811 04:18:00.744484 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:18:16.428186 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:18:17.675932 10215 solver.cpp:414]     Test net output #0: accuracy = 0.978334
I0811 04:18:17.675956 10215 solver.cpp:414]     Test net output #1: loss = 0.0583681 (* 1 = 0.0583681 loss)
I0811 04:18:22.176252 10215 solver.cpp:239] Iteration 12950 (2.3761 iter/s, 29.46s/70 iters), loss = 0.0511871
I0811 04:18:22.176280 10215 solver.cpp:258]     Train net output #0: loss = 0.0511875 (* 1 = 0.0511875 loss)
I0811 04:18:22.176285 10215 sgd_solver.cpp:112] Iteration 12950, lr = 0.01
I0811 04:18:34.806464 10215 solver.cpp:239] Iteration 13020 (5.54243 iter/s, 12.6298s/70 iters), loss = 0.0211246
I0811 04:18:34.806603 10215 solver.cpp:258]     Train net output #0: loss = 0.021125 (* 1 = 0.021125 loss)
I0811 04:18:34.806612 10215 sgd_solver.cpp:112] Iteration 13020, lr = 0.01
I0811 04:18:47.425048 10215 solver.cpp:239] Iteration 13090 (5.54758 iter/s, 12.6181s/70 iters), loss = 0.068739
I0811 04:18:47.425076 10215 solver.cpp:258]     Train net output #0: loss = 0.0687393 (* 1 = 0.0687393 loss)
I0811 04:18:47.425081 10215 sgd_solver.cpp:112] Iteration 13090, lr = 0.01
I0811 04:19:00.034492 10215 solver.cpp:239] Iteration 13160 (5.55156 iter/s, 12.6091s/70 iters), loss = 0.0608275
I0811 04:19:00.034525 10215 solver.cpp:258]     Train net output #0: loss = 0.0608279 (* 1 = 0.0608279 loss)
I0811 04:19:00.034531 10215 sgd_solver.cpp:112] Iteration 13160, lr = 0.01
I0811 04:19:12.661029 10215 solver.cpp:239] Iteration 13230 (5.54404 iter/s, 12.6262s/70 iters), loss = 0.0686528
I0811 04:19:12.661105 10215 solver.cpp:258]     Train net output #0: loss = 0.0686532 (* 1 = 0.0686532 loss)
I0811 04:19:12.661113 10215 sgd_solver.cpp:112] Iteration 13230, lr = 0.01
I0811 04:19:25.289952 10215 solver.cpp:239] Iteration 13300 (5.54302 iter/s, 12.6285s/70 iters), loss = 0.0240807
I0811 04:19:25.289979 10215 solver.cpp:258]     Train net output #0: loss = 0.024081 (* 1 = 0.024081 loss)
I0811 04:19:25.289984 10215 sgd_solver.cpp:112] Iteration 13300, lr = 0.01
I0811 04:19:37.912796 10215 solver.cpp:239] Iteration 13370 (5.54566 iter/s, 12.6225s/70 iters), loss = 0.0203698
I0811 04:19:37.912822 10215 solver.cpp:258]     Train net output #0: loss = 0.0203701 (* 1 = 0.0203701 loss)
I0811 04:19:37.912828 10215 sgd_solver.cpp:112] Iteration 13370, lr = 0.01
I0811 04:19:50.521756 10215 solver.cpp:239] Iteration 13440 (5.55177 iter/s, 12.6086s/70 iters), loss = 0.126885
I0811 04:19:50.521898 10215 solver.cpp:258]     Train net output #0: loss = 0.126885 (* 1 = 0.126885 loss)
I0811 04:19:50.521905 10215 sgd_solver.cpp:112] Iteration 13440, lr = 0.01
I0811 04:19:54.576622 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:19:58.916841 10215 solver.cpp:347] Iteration 13488, Testing net (#0)
I0811 04:19:58.916857 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:20:14.545912 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:20:15.836977 10215 solver.cpp:414]     Test net output #0: accuracy = 0.984167
I0811 04:20:15.837000 10215 solver.cpp:414]     Test net output #1: loss = 0.0441256 (* 1 = 0.0441256 loss)
I0811 04:20:19.992622 10215 solver.cpp:239] Iteration 13510 (2.3753 iter/s, 29.4699s/70 iters), loss = 0.053804
I0811 04:20:19.992651 10215 solver.cpp:258]     Train net output #0: loss = 0.0538044 (* 1 = 0.0538044 loss)
I0811 04:20:19.992658 10215 sgd_solver.cpp:112] Iteration 13510, lr = 0.01
I0811 04:20:32.616209 10215 solver.cpp:239] Iteration 13580 (5.54534 iter/s, 12.6232s/70 iters), loss = 0.0327775
I0811 04:20:32.616348 10215 solver.cpp:258]     Train net output #0: loss = 0.0327778 (* 1 = 0.0327778 loss)
I0811 04:20:32.616356 10215 sgd_solver.cpp:112] Iteration 13580, lr = 0.01
I0811 04:20:45.251050 10215 solver.cpp:239] Iteration 13650 (5.54045 iter/s, 12.6344s/70 iters), loss = 0.0157436
I0811 04:20:45.251082 10215 solver.cpp:258]     Train net output #0: loss = 0.0157439 (* 1 = 0.0157439 loss)
I0811 04:20:45.251088 10215 sgd_solver.cpp:112] Iteration 13650, lr = 0.01
I0811 04:20:57.875674 10215 solver.cpp:239] Iteration 13720 (5.54489 iter/s, 12.6242s/70 iters), loss = 0.0492382
I0811 04:20:57.875701 10215 solver.cpp:258]     Train net output #0: loss = 0.0492385 (* 1 = 0.0492385 loss)
I0811 04:20:57.875706 10215 sgd_solver.cpp:112] Iteration 13720, lr = 0.01
I0811 04:21:10.525856 10215 solver.cpp:239] Iteration 13790 (5.53368 iter/s, 12.6498s/70 iters), loss = 0.285419
I0811 04:21:10.525995 10215 solver.cpp:258]     Train net output #0: loss = 0.285419 (* 1 = 0.285419 loss)
I0811 04:21:10.526002 10215 sgd_solver.cpp:112] Iteration 13790, lr = 0.01
I0811 04:21:23.155268 10215 solver.cpp:239] Iteration 13860 (5.54283 iter/s, 12.6289s/70 iters), loss = 0.191588
I0811 04:21:23.155298 10215 solver.cpp:258]     Train net output #0: loss = 0.191589 (* 1 = 0.191589 loss)
I0811 04:21:23.155304 10215 sgd_solver.cpp:112] Iteration 13860, lr = 0.01
I0811 04:21:35.774068 10215 solver.cpp:239] Iteration 13930 (5.54744 iter/s, 12.6184s/70 iters), loss = 0.0694488
I0811 04:21:35.774096 10215 solver.cpp:258]     Train net output #0: loss = 0.0694491 (* 1 = 0.0694491 loss)
I0811 04:21:35.774101 10215 sgd_solver.cpp:112] Iteration 13930, lr = 0.01
I0811 04:21:48.415433 10215 solver.cpp:239] Iteration 14000 (5.53754 iter/s, 12.641s/70 iters), loss = 0.0868541
I0811 04:21:48.415593 10215 solver.cpp:258]     Train net output #0: loss = 0.0868544 (* 1 = 0.0868544 loss)
I0811 04:21:48.415601 10215 sgd_solver.cpp:112] Iteration 14000, lr = 0.01
I0811 04:21:52.760586 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:21:57.167925 10215 solver.cpp:347] Iteration 14050, Testing net (#0)
I0811 04:21:57.167942 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:22:04.764854 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:22:12.792590 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:22:14.160269 10215 solver.cpp:414]     Test net output #0: accuracy = 0.986834
I0811 04:22:14.160293 10215 solver.cpp:414]     Test net output #1: loss = 0.0369692 (* 1 = 0.0369692 loss)
I0811 04:22:17.956662 10215 solver.cpp:239] Iteration 14070 (2.36965 iter/s, 29.5403s/70 iters), loss = 0.0143686
I0811 04:22:17.956689 10215 solver.cpp:258]     Train net output #0: loss = 0.014369 (* 1 = 0.014369 loss)
I0811 04:22:17.956696 10215 sgd_solver.cpp:112] Iteration 14070, lr = 0.01
I0811 04:22:30.584035 10215 solver.cpp:239] Iteration 14140 (5.54368 iter/s, 12.627s/70 iters), loss = 0.00122064
I0811 04:22:30.584177 10215 solver.cpp:258]     Train net output #0: loss = 0.00122099 (* 1 = 0.00122099 loss)
I0811 04:22:30.584184 10215 sgd_solver.cpp:112] Iteration 14140, lr = 0.01
I0811 04:22:43.199714 10215 solver.cpp:239] Iteration 14210 (5.54886 iter/s, 12.6152s/70 iters), loss = 0.0184207
I0811 04:22:43.199743 10215 solver.cpp:258]     Train net output #0: loss = 0.0184211 (* 1 = 0.0184211 loss)
I0811 04:22:43.199748 10215 sgd_solver.cpp:112] Iteration 14210, lr = 0.01
I0811 04:22:55.824913 10215 solver.cpp:239] Iteration 14280 (5.54463 iter/s, 12.6248s/70 iters), loss = 0.0461987
I0811 04:22:55.824940 10215 solver.cpp:258]     Train net output #0: loss = 0.046199 (* 1 = 0.046199 loss)
I0811 04:22:55.824946 10215 sgd_solver.cpp:112] Iteration 14280, lr = 0.01
I0811 04:23:08.463610 10215 solver.cpp:239] Iteration 14350 (5.53871 iter/s, 12.6383s/70 iters), loss = 0.0823347
I0811 04:23:08.463748 10215 solver.cpp:258]     Train net output #0: loss = 0.082335 (* 1 = 0.082335 loss)
I0811 04:23:08.463757 10215 sgd_solver.cpp:112] Iteration 14350, lr = 0.01
I0811 04:23:21.082170 10215 solver.cpp:239] Iteration 14420 (5.54759 iter/s, 12.6181s/70 iters), loss = 0.158408
I0811 04:23:21.082197 10215 solver.cpp:258]     Train net output #0: loss = 0.158409 (* 1 = 0.158409 loss)
I0811 04:23:21.082203 10215 sgd_solver.cpp:112] Iteration 14420, lr = 0.01
I0811 04:23:33.708418 10215 solver.cpp:239] Iteration 14490 (5.54417 iter/s, 12.6259s/70 iters), loss = 0.0458384
I0811 04:23:33.708446 10215 solver.cpp:258]     Train net output #0: loss = 0.0458388 (* 1 = 0.0458388 loss)
I0811 04:23:33.708452 10215 sgd_solver.cpp:112] Iteration 14490, lr = 0.01
I0811 04:23:46.327823 10215 solver.cpp:239] Iteration 14560 (5.54718 iter/s, 12.619s/70 iters), loss = 0.263062
I0811 04:23:46.327962 10215 solver.cpp:258]     Train net output #0: loss = 0.263062 (* 1 = 0.263062 loss)
I0811 04:23:46.327970 10215 sgd_solver.cpp:112] Iteration 14560, lr = 0.01
I0811 04:23:50.861690 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:23:55.436254 10215 solver.cpp:347] Iteration 14612, Testing net (#0)
I0811 04:23:55.436269 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:24:10.894446 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:24:12.285215 10215 solver.cpp:414]     Test net output #0: accuracy = 0.984834
I0811 04:24:12.285238 10215 solver.cpp:414]     Test net output #1: loss = 0.0418649 (* 1 = 0.0418649 loss)
I0811 04:24:15.716608 10215 solver.cpp:239] Iteration 14630 (2.38194 iter/s, 29.3879s/70 iters), loss = 0.00592577
I0811 04:24:15.716640 10215 solver.cpp:258]     Train net output #0: loss = 0.00592615 (* 1 = 0.00592615 loss)
I0811 04:24:15.716647 10215 sgd_solver.cpp:112] Iteration 14630, lr = 0.01
I0811 04:24:28.336689 10215 solver.cpp:239] Iteration 14700 (5.54688 iter/s, 12.6197s/70 iters), loss = 0.127507
I0811 04:24:28.336835 10215 solver.cpp:258]     Train net output #0: loss = 0.127507 (* 1 = 0.127507 loss)
I0811 04:24:28.336855 10215 sgd_solver.cpp:112] Iteration 14700, lr = 0.01
I0811 04:24:40.951300 10215 solver.cpp:239] Iteration 14770 (5.54933 iter/s, 12.6141s/70 iters), loss = 0.0740859
I0811 04:24:40.951328 10215 solver.cpp:258]     Train net output #0: loss = 0.0740863 (* 1 = 0.0740863 loss)
I0811 04:24:40.951333 10215 sgd_solver.cpp:112] Iteration 14770, lr = 0.01
I0811 04:24:53.561991 10215 solver.cpp:239] Iteration 14840 (5.55101 iter/s, 12.6103s/70 iters), loss = 0.159455
I0811 04:24:53.562018 10215 solver.cpp:258]     Train net output #0: loss = 0.159456 (* 1 = 0.159456 loss)
I0811 04:24:53.562024 10215 sgd_solver.cpp:112] Iteration 14840, lr = 0.01
I0811 04:25:06.180356 10215 solver.cpp:239] Iteration 14910 (5.54763 iter/s, 12.618s/70 iters), loss = 0.252536
I0811 04:25:06.180522 10215 solver.cpp:258]     Train net output #0: loss = 0.252537 (* 1 = 0.252537 loss)
I0811 04:25:06.180529 10215 sgd_solver.cpp:112] Iteration 14910, lr = 0.01
I0811 04:25:18.804090 10215 solver.cpp:239] Iteration 14980 (5.54533 iter/s, 12.6232s/70 iters), loss = 0.0105404
I0811 04:25:18.804116 10215 solver.cpp:258]     Train net output #0: loss = 0.0105408 (* 1 = 0.0105408 loss)
I0811 04:25:18.804121 10215 sgd_solver.cpp:112] Iteration 14980, lr = 0.01
I0811 04:25:31.418501 10215 solver.cpp:239] Iteration 15050 (5.54937 iter/s, 12.614s/70 iters), loss = 0.0293489
I0811 04:25:31.418530 10215 solver.cpp:258]     Train net output #0: loss = 0.0293492 (* 1 = 0.0293492 loss)
I0811 04:25:31.418536 10215 sgd_solver.cpp:112] Iteration 15050, lr = 0.01
I0811 04:25:44.047034 10215 solver.cpp:239] Iteration 15120 (5.54317 iter/s, 12.6282s/70 iters), loss = 0.0457204
I0811 04:25:44.047157 10215 solver.cpp:258]     Train net output #0: loss = 0.0457207 (* 1 = 0.0457207 loss)
I0811 04:25:44.047176 10215 sgd_solver.cpp:112] Iteration 15120, lr = 0.01
I0811 04:25:48.771011 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:25:53.514827 10215 solver.cpp:347] Iteration 15174, Testing net (#0)
I0811 04:25:53.514842 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:26:09.062345 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:26:10.519521 10215 solver.cpp:414]     Test net output #0: accuracy = 0.989334
I0811 04:26:10.519546 10215 solver.cpp:414]     Test net output #1: loss = 0.0368995 (* 1 = 0.0368995 loss)
I0811 04:26:13.589789 10215 solver.cpp:239] Iteration 15190 (2.36952 iter/s, 29.5418s/70 iters), loss = 0.0372995
I0811 04:26:13.589817 10215 solver.cpp:258]     Train net output #0: loss = 0.0372998 (* 1 = 0.0372998 loss)
I0811 04:26:13.589821 10215 sgd_solver.cpp:112] Iteration 15190, lr = 0.01
I0811 04:26:26.219463 10215 solver.cpp:239] Iteration 15260 (5.54267 iter/s, 12.6293s/70 iters), loss = 0.00993157
I0811 04:26:26.219599 10215 solver.cpp:258]     Train net output #0: loss = 0.00993184 (* 1 = 0.00993184 loss)
I0811 04:26:26.219607 10215 sgd_solver.cpp:112] Iteration 15260, lr = 0.01
I0811 04:26:38.830135 10215 solver.cpp:239] Iteration 15330 (5.55106 iter/s, 12.6102s/70 iters), loss = 0.106015
I0811 04:26:38.830163 10215 solver.cpp:258]     Train net output #0: loss = 0.106015 (* 1 = 0.106015 loss)
I0811 04:26:38.830168 10215 sgd_solver.cpp:112] Iteration 15330, lr = 0.01
I0811 04:26:51.467193 10215 solver.cpp:239] Iteration 15400 (5.53943 iter/s, 12.6367s/70 iters), loss = 0.1034
I0811 04:26:51.467221 10215 solver.cpp:258]     Train net output #0: loss = 0.1034 (* 1 = 0.1034 loss)
I0811 04:26:51.467227 10215 sgd_solver.cpp:112] Iteration 15400, lr = 0.01
I0811 04:27:04.091907 10215 solver.cpp:239] Iteration 15470 (5.54484 iter/s, 12.6243s/70 iters), loss = 0.0249812
I0811 04:27:04.092054 10215 solver.cpp:258]     Train net output #0: loss = 0.0249814 (* 1 = 0.0249814 loss)
I0811 04:27:04.092062 10215 sgd_solver.cpp:112] Iteration 15470, lr = 0.01
I0811 04:27:16.712241 10215 solver.cpp:239] Iteration 15540 (5.54682 iter/s, 12.6198s/70 iters), loss = 0.0361487
I0811 04:27:16.712270 10215 solver.cpp:258]     Train net output #0: loss = 0.0361489 (* 1 = 0.0361489 loss)
I0811 04:27:16.712275 10215 sgd_solver.cpp:112] Iteration 15540, lr = 0.01
I0811 04:27:29.316100 10215 solver.cpp:239] Iteration 15610 (5.55402 iter/s, 12.6035s/70 iters), loss = 0.0649951
I0811 04:27:29.316129 10215 solver.cpp:258]     Train net output #0: loss = 0.0649953 (* 1 = 0.0649953 loss)
I0811 04:27:29.316135 10215 sgd_solver.cpp:112] Iteration 15610, lr = 0.01
I0811 04:27:41.947383 10215 solver.cpp:239] Iteration 15680 (5.54196 iter/s, 12.6309s/70 iters), loss = 0.0502763
I0811 04:27:41.947448 10215 solver.cpp:258]     Train net output #0: loss = 0.0502765 (* 1 = 0.0502765 loss)
I0811 04:27:41.947454 10215 sgd_solver.cpp:112] Iteration 15680, lr = 0.01
I0811 04:27:46.869519 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:27:51.784708 10215 solver.cpp:347] Iteration 15736, Testing net (#0)
I0811 04:27:51.784723 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:28:07.250674 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:28:08.760313 10215 solver.cpp:414]     Test net output #0: accuracy = 0.984834
I0811 04:28:08.760335 10215 solver.cpp:414]     Test net output #1: loss = 0.0457383 (* 1 = 0.0457383 loss)
I0811 04:28:11.470716 10215 solver.cpp:239] Iteration 15750 (2.37107 iter/s, 29.5225s/70 iters), loss = 0.00285978
I0811 04:28:11.470743 10215 solver.cpp:258]     Train net output #0: loss = 0.00285997 (* 1 = 0.00285997 loss)
I0811 04:28:11.470749 10215 sgd_solver.cpp:112] Iteration 15750, lr = 0.01
I0811 04:28:24.094817 10215 solver.cpp:239] Iteration 15820 (5.54512 iter/s, 12.6237s/70 iters), loss = 0.0718158
I0811 04:28:24.094966 10215 solver.cpp:258]     Train net output #0: loss = 0.071816 (* 1 = 0.071816 loss)
I0811 04:28:24.094972 10215 sgd_solver.cpp:112] Iteration 15820, lr = 0.01
I0811 04:28:36.695144 10215 solver.cpp:239] Iteration 15890 (5.55563 iter/s, 12.5998s/70 iters), loss = 0.0704741
I0811 04:28:36.695171 10215 solver.cpp:258]     Train net output #0: loss = 0.0704743 (* 1 = 0.0704743 loss)
I0811 04:28:36.695176 10215 sgd_solver.cpp:112] Iteration 15890, lr = 0.01
I0811 04:28:49.321578 10215 solver.cpp:239] Iteration 15960 (5.54409 iter/s, 12.6261s/70 iters), loss = 0.0331217
I0811 04:28:49.321605 10215 solver.cpp:258]     Train net output #0: loss = 0.0331219 (* 1 = 0.0331219 loss)
I0811 04:28:49.321611 10215 sgd_solver.cpp:112] Iteration 15960, lr = 0.01
I0811 04:29:01.950192 10215 solver.cpp:239] Iteration 16030 (5.54313 iter/s, 12.6282s/70 iters), loss = 0.0437476
I0811 04:29:01.950273 10215 solver.cpp:258]     Train net output #0: loss = 0.0437478 (* 1 = 0.0437478 loss)
I0811 04:29:01.950292 10215 sgd_solver.cpp:112] Iteration 16030, lr = 0.01
I0811 04:29:14.555855 10215 solver.cpp:239] Iteration 16100 (5.55325 iter/s, 12.6052s/70 iters), loss = 0.0154201
I0811 04:29:14.555881 10215 solver.cpp:258]     Train net output #0: loss = 0.0154204 (* 1 = 0.0154204 loss)
I0811 04:29:14.555887 10215 sgd_solver.cpp:112] Iteration 16100, lr = 0.01
I0811 04:29:27.154923 10215 solver.cpp:239] Iteration 16170 (5.55613 iter/s, 12.5987s/70 iters), loss = 0.0166606
I0811 04:29:27.154950 10215 solver.cpp:258]     Train net output #0: loss = 0.0166608 (* 1 = 0.0166608 loss)
I0811 04:29:27.154955 10215 sgd_solver.cpp:112] Iteration 16170, lr = 0.01
I0811 04:29:39.768086 10215 solver.cpp:239] Iteration 16240 (5.54992 iter/s, 12.6128s/70 iters), loss = 0.0131521
I0811 04:29:39.768214 10215 solver.cpp:258]     Train net output #0: loss = 0.0131523 (* 1 = 0.0131523 loss)
I0811 04:29:39.768223 10215 sgd_solver.cpp:112] Iteration 16240, lr = 0.01
I0811 04:29:44.883498 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:29:49.954948 10215 solver.cpp:347] Iteration 16298, Testing net (#0)
I0811 04:29:49.954963 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:30:01.607847 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:30:05.356591 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:30:06.930413 10215 solver.cpp:414]     Test net output #0: accuracy = 0.990501
I0811 04:30:06.930436 10215 solver.cpp:414]     Test net output #1: loss = 0.0276878 (* 1 = 0.0276878 loss)
I0811 04:30:09.275722 10215 solver.cpp:239] Iteration 16310 (2.37234 iter/s, 29.5067s/70 iters), loss = 0.0192759
I0811 04:30:09.275751 10215 solver.cpp:258]     Train net output #0: loss = 0.0192761 (* 1 = 0.0192761 loss)
I0811 04:30:09.275758 10215 sgd_solver.cpp:112] Iteration 16310, lr = 0.01
I0811 04:30:21.900302 10215 solver.cpp:239] Iteration 16380 (5.5449 iter/s, 12.6242s/70 iters), loss = 0.0381673
I0811 04:30:21.900458 10215 solver.cpp:258]     Train net output #0: loss = 0.0381675 (* 1 = 0.0381675 loss)
I0811 04:30:21.900477 10215 sgd_solver.cpp:112] Iteration 16380, lr = 0.01
I0811 04:30:34.531095 10215 solver.cpp:239] Iteration 16450 (5.54223 iter/s, 12.6303s/70 iters), loss = 0.122911
I0811 04:30:34.531123 10215 solver.cpp:258]     Train net output #0: loss = 0.122911 (* 1 = 0.122911 loss)
I0811 04:30:34.531129 10215 sgd_solver.cpp:112] Iteration 16450, lr = 0.01
I0811 04:30:47.150396 10215 solver.cpp:239] Iteration 16520 (5.54722 iter/s, 12.6189s/70 iters), loss = 0.0128568
I0811 04:30:47.150424 10215 solver.cpp:258]     Train net output #0: loss = 0.012857 (* 1 = 0.012857 loss)
I0811 04:30:47.150430 10215 sgd_solver.cpp:112] Iteration 16520, lr = 0.01
I0811 04:30:59.773495 10215 solver.cpp:239] Iteration 16590 (5.54555 iter/s, 12.6227s/70 iters), loss = 0.0102713
I0811 04:30:59.773545 10215 solver.cpp:258]     Train net output #0: loss = 0.0102716 (* 1 = 0.0102716 loss)
I0811 04:30:59.773551 10215 sgd_solver.cpp:112] Iteration 16590, lr = 0.01
I0811 04:31:12.395908 10215 solver.cpp:239] Iteration 16660 (5.54587 iter/s, 12.622s/70 iters), loss = 0.070098
I0811 04:31:12.395939 10215 solver.cpp:258]     Train net output #0: loss = 0.0700982 (* 1 = 0.0700982 loss)
I0811 04:31:12.395946 10215 sgd_solver.cpp:112] Iteration 16660, lr = 0.01
I0811 04:31:25.018311 10215 solver.cpp:239] Iteration 16730 (5.54586 iter/s, 12.622s/70 iters), loss = 0.00233151
I0811 04:31:25.018337 10215 solver.cpp:258]     Train net output #0: loss = 0.00233176 (* 1 = 0.00233176 loss)
I0811 04:31:25.018343 10215 sgd_solver.cpp:112] Iteration 16730, lr = 0.01
I0811 04:31:37.632845 10215 solver.cpp:239] Iteration 16800 (5.54932 iter/s, 12.6142s/70 iters), loss = 0.181928
I0811 04:31:37.632889 10215 solver.cpp:258]     Train net output #0: loss = 0.181928 (* 1 = 0.181928 loss)
I0811 04:31:37.632894 10215 sgd_solver.cpp:112] Iteration 16800, lr = 0.01
I0811 04:31:42.930685 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:31:48.190907 10215 solver.cpp:347] Iteration 16860, Testing net (#0)
I0811 04:31:48.190920 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:32:03.753612 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:32:05.372514 10215 solver.cpp:414]     Test net output #0: accuracy = 0.977001
I0811 04:32:05.372537 10215 solver.cpp:414]     Test net output #1: loss = 0.0710598 (* 1 = 0.0710598 loss)
I0811 04:32:07.363703 10215 solver.cpp:239] Iteration 16870 (2.35452 iter/s, 29.73s/70 iters), loss = 0.0583393
I0811 04:32:07.363731 10215 solver.cpp:258]     Train net output #0: loss = 0.0583396 (* 1 = 0.0583396 loss)
I0811 04:32:07.363737 10215 sgd_solver.cpp:112] Iteration 16870, lr = 0.01
I0811 04:32:19.976953 10215 solver.cpp:239] Iteration 16940 (5.54988 iter/s, 12.6129s/70 iters), loss = 0.0358729
I0811 04:32:19.976996 10215 solver.cpp:258]     Train net output #0: loss = 0.0358732 (* 1 = 0.0358732 loss)
I0811 04:32:19.977003 10215 sgd_solver.cpp:112] Iteration 16940, lr = 0.01
I0811 04:32:32.613723 10215 solver.cpp:239] Iteration 17010 (5.53956 iter/s, 12.6364s/70 iters), loss = 0.00945832
I0811 04:32:32.613759 10215 solver.cpp:258]     Train net output #0: loss = 0.00945864 (* 1 = 0.00945864 loss)
I0811 04:32:32.613765 10215 sgd_solver.cpp:112] Iteration 17010, lr = 0.01
I0811 04:32:45.238387 10215 solver.cpp:239] Iteration 17080 (5.54487 iter/s, 12.6243s/70 iters), loss = 0.100668
I0811 04:32:45.238417 10215 solver.cpp:258]     Train net output #0: loss = 0.100668 (* 1 = 0.100668 loss)
I0811 04:32:45.238423 10215 sgd_solver.cpp:112] Iteration 17080, lr = 0.01
I0811 04:32:57.868440 10215 solver.cpp:239] Iteration 17150 (5.5425 iter/s, 12.6297s/70 iters), loss = 0.0201732
I0811 04:32:57.868502 10215 solver.cpp:258]     Train net output #0: loss = 0.0201735 (* 1 = 0.0201735 loss)
I0811 04:32:57.868510 10215 sgd_solver.cpp:112] Iteration 17150, lr = 0.01
I0811 04:33:10.483598 10215 solver.cpp:239] Iteration 17220 (5.54906 iter/s, 12.6148s/70 iters), loss = 0.0506073
I0811 04:33:10.483626 10215 solver.cpp:258]     Train net output #0: loss = 0.0506076 (* 1 = 0.0506076 loss)
I0811 04:33:10.483633 10215 sgd_solver.cpp:112] Iteration 17220, lr = 0.01
I0811 04:33:23.099588 10215 solver.cpp:239] Iteration 17290 (5.54868 iter/s, 12.6156s/70 iters), loss = 0.0490936
I0811 04:33:23.099615 10215 solver.cpp:258]     Train net output #0: loss = 0.049094 (* 1 = 0.049094 loss)
I0811 04:33:23.099622 10215 sgd_solver.cpp:112] Iteration 17290, lr = 0.01
I0811 04:33:35.729763 10215 solver.cpp:239] Iteration 17360 (5.54245 iter/s, 12.6298s/70 iters), loss = 0.0448639
I0811 04:33:35.729851 10215 solver.cpp:258]     Train net output #0: loss = 0.0448643 (* 1 = 0.0448643 loss)
I0811 04:33:35.729871 10215 sgd_solver.cpp:112] Iteration 17360, lr = 0.01
I0811 04:33:41.221330 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:33:46.642098 10215 solver.cpp:347] Iteration 17422, Testing net (#0)
I0811 04:33:46.642112 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:34:01.967193 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:34:03.645964 10215 solver.cpp:414]     Test net output #0: accuracy = 0.984667
I0811 04:34:03.645987 10215 solver.cpp:414]     Test net output #1: loss = 0.0572301 (* 1 = 0.0572301 loss)
I0811 04:34:05.275372 10215 solver.cpp:239] Iteration 17430 (2.36929 iter/s, 29.5447s/70 iters), loss = 0.142536
I0811 04:34:05.275399 10215 solver.cpp:258]     Train net output #0: loss = 0.142536 (* 1 = 0.142536 loss)
I0811 04:34:05.275405 10215 sgd_solver.cpp:112] Iteration 17430, lr = 0.01
I0811 04:34:17.880790 10215 solver.cpp:239] Iteration 17500 (5.55333 iter/s, 12.605s/70 iters), loss = 0.0244305
I0811 04:34:17.880915 10215 solver.cpp:258]     Train net output #0: loss = 0.0244308 (* 1 = 0.0244308 loss)
I0811 04:34:17.880923 10215 sgd_solver.cpp:112] Iteration 17500, lr = 0.01
I0811 04:34:30.502782 10215 solver.cpp:239] Iteration 17570 (5.54608 iter/s, 12.6215s/70 iters), loss = 0.067499
I0811 04:34:30.502811 10215 solver.cpp:258]     Train net output #0: loss = 0.0674993 (* 1 = 0.0674993 loss)
I0811 04:34:30.502817 10215 sgd_solver.cpp:112] Iteration 17570, lr = 0.01
I0811 04:34:43.113337 10215 solver.cpp:239] Iteration 17640 (5.55107 iter/s, 12.6102s/70 iters), loss = 0.0136323
I0811 04:34:43.113364 10215 solver.cpp:258]     Train net output #0: loss = 0.0136326 (* 1 = 0.0136326 loss)
I0811 04:34:43.113369 10215 sgd_solver.cpp:112] Iteration 17640, lr = 0.01
I0811 04:34:55.726876 10215 solver.cpp:239] Iteration 17710 (5.54976 iter/s, 12.6132s/70 iters), loss = 0.0363385
I0811 04:34:55.727003 10215 solver.cpp:258]     Train net output #0: loss = 0.0363388 (* 1 = 0.0363388 loss)
I0811 04:34:55.727022 10215 sgd_solver.cpp:112] Iteration 17710, lr = 0.01
I0811 04:35:08.341173 10215 solver.cpp:239] Iteration 17780 (5.54946 iter/s, 12.6138s/70 iters), loss = 0.140075
I0811 04:35:08.341200 10215 solver.cpp:258]     Train net output #0: loss = 0.140075 (* 1 = 0.140075 loss)
I0811 04:35:08.341205 10215 sgd_solver.cpp:112] Iteration 17780, lr = 0.01
I0811 04:35:20.962493 10215 solver.cpp:239] Iteration 17850 (5.54634 iter/s, 12.6209s/70 iters), loss = 0.0551365
I0811 04:35:20.962524 10215 solver.cpp:258]     Train net output #0: loss = 0.0551369 (* 1 = 0.0551369 loss)
I0811 04:35:20.962530 10215 sgd_solver.cpp:112] Iteration 17850, lr = 0.01
I0811 04:35:33.572980 10215 solver.cpp:239] Iteration 17920 (5.5511 iter/s, 12.6101s/70 iters), loss = 0.00133042
I0811 04:35:33.573083 10215 solver.cpp:258]     Train net output #0: loss = 0.00133075 (* 1 = 0.00133075 loss)
I0811 04:35:33.573103 10215 sgd_solver.cpp:112] Iteration 17920, lr = 0.01
I0811 04:35:39.239915 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:35:44.830446 10215 solver.cpp:347] Iteration 17984, Testing net (#0)
I0811 04:35:44.830461 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:36:00.099225 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:36:01.823314 10215 solver.cpp:414]     Test net output #0: accuracy = 0.991834
I0811 04:36:01.823338 10215 solver.cpp:414]     Test net output #1: loss = 0.0250342 (* 1 = 0.0250342 loss)
I0811 04:36:03.084219 10215 solver.cpp:239] Iteration 17990 (2.37205 iter/s, 29.5103s/70 iters), loss = 0.00100047
I0811 04:36:03.084247 10215 solver.cpp:258]     Train net output #0: loss = 0.00100081 (* 1 = 0.00100081 loss)
I0811 04:36:03.084254 10215 sgd_solver.cpp:112] Iteration 17990, lr = 0.01
I0811 04:36:15.705339 10215 solver.cpp:239] Iteration 18060 (5.54642 iter/s, 12.6207s/70 iters), loss = 0.0206952
I0811 04:36:15.705483 10215 solver.cpp:258]     Train net output #0: loss = 0.0206955 (* 1 = 0.0206955 loss)
I0811 04:36:15.705492 10215 sgd_solver.cpp:112] Iteration 18060, lr = 0.01
I0811 04:36:28.317813 10215 solver.cpp:239] Iteration 18130 (5.55027 iter/s, 12.612s/70 iters), loss = 0.0314949
I0811 04:36:28.317842 10215 solver.cpp:258]     Train net output #0: loss = 0.0314952 (* 1 = 0.0314952 loss)
I0811 04:36:28.317847 10215 sgd_solver.cpp:112] Iteration 18130, lr = 0.01
I0811 04:36:40.918448 10215 solver.cpp:239] Iteration 18200 (5.55544 iter/s, 12.6003s/70 iters), loss = 0.00872768
I0811 04:36:40.918480 10215 solver.cpp:258]     Train net output #0: loss = 0.00872799 (* 1 = 0.00872799 loss)
I0811 04:36:40.918488 10215 sgd_solver.cpp:112] Iteration 18200, lr = 0.01
I0811 04:36:53.529600 10215 solver.cpp:239] Iteration 18270 (5.55081 iter/s, 12.6108s/70 iters), loss = 0.000746757
I0811 04:36:53.529763 10215 solver.cpp:258]     Train net output #0: loss = 0.000747053 (* 1 = 0.000747053 loss)
I0811 04:36:53.529772 10215 sgd_solver.cpp:112] Iteration 18270, lr = 0.01
I0811 04:37:06.143682 10215 solver.cpp:239] Iteration 18340 (5.54958 iter/s, 12.6136s/70 iters), loss = 0.027668
I0811 04:37:06.143710 10215 solver.cpp:258]     Train net output #0: loss = 0.0276683 (* 1 = 0.0276683 loss)
I0811 04:37:06.143715 10215 sgd_solver.cpp:112] Iteration 18340, lr = 0.01
I0811 04:37:18.755102 10215 solver.cpp:239] Iteration 18410 (5.55069 iter/s, 12.611s/70 iters), loss = 0.103658
I0811 04:37:18.755129 10215 solver.cpp:258]     Train net output #0: loss = 0.103658 (* 1 = 0.103658 loss)
I0811 04:37:18.755136 10215 sgd_solver.cpp:112] Iteration 18410, lr = 0.01
I0811 04:37:31.380342 10215 solver.cpp:239] Iteration 18480 (5.54461 iter/s, 12.6249s/70 iters), loss = 0.0155934
I0811 04:37:31.380486 10215 solver.cpp:258]     Train net output #0: loss = 0.0155937 (* 1 = 0.0155937 loss)
I0811 04:37:31.380493 10215 sgd_solver.cpp:112] Iteration 18480, lr = 0.01
I0811 04:37:37.362115 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:37:43.018774 10215 solver.cpp:347] Iteration 18546, Testing net (#0)
I0811 04:37:43.018786 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:37:58.187372 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:37:58.746652 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:37:59.945209 10215 solver.cpp:414]     Test net output #0: accuracy = 0.988167
I0811 04:37:59.945233 10215 solver.cpp:414]     Test net output #1: loss = 0.0356407 (* 1 = 0.0356407 loss)
I0811 04:38:00.852140 10215 solver.cpp:239] Iteration 18550 (2.37523 iter/s, 29.4709s/70 iters), loss = 0.00623848
I0811 04:38:00.852167 10215 solver.cpp:258]     Train net output #0: loss = 0.00623884 (* 1 = 0.00623884 loss)
I0811 04:38:00.852174 10215 sgd_solver.cpp:112] Iteration 18550, lr = 0.001
I0811 04:38:13.474305 10215 solver.cpp:239] Iteration 18620 (5.54596 iter/s, 12.6218s/70 iters), loss = 0.0351985
I0811 04:38:13.474464 10215 solver.cpp:258]     Train net output #0: loss = 0.0351989 (* 1 = 0.0351989 loss)
I0811 04:38:13.474472 10215 sgd_solver.cpp:112] Iteration 18620, lr = 0.001
I0811 04:38:26.089035 10215 solver.cpp:239] Iteration 18690 (5.54929 iter/s, 12.6142s/70 iters), loss = 0.00308678
I0811 04:38:26.089064 10215 solver.cpp:258]     Train net output #0: loss = 0.00308714 (* 1 = 0.00308714 loss)
I0811 04:38:26.089071 10215 sgd_solver.cpp:112] Iteration 18690, lr = 0.001
I0811 04:38:38.700018 10215 solver.cpp:239] Iteration 18760 (5.55088 iter/s, 12.6106s/70 iters), loss = 0.222733
I0811 04:38:38.700045 10215 solver.cpp:258]     Train net output #0: loss = 0.222734 (* 1 = 0.222734 loss)
I0811 04:38:38.700052 10215 sgd_solver.cpp:112] Iteration 18760, lr = 0.001
I0811 04:38:51.320734 10215 solver.cpp:239] Iteration 18830 (5.5466 iter/s, 12.6203s/70 iters), loss = 0.0158587
I0811 04:38:51.320870 10215 solver.cpp:258]     Train net output #0: loss = 0.0158591 (* 1 = 0.0158591 loss)
I0811 04:38:51.320878 10215 sgd_solver.cpp:112] Iteration 18830, lr = 0.001
I0811 04:39:03.933881 10215 solver.cpp:239] Iteration 18900 (5.54997 iter/s, 12.6127s/70 iters), loss = 0.000478432
I0811 04:39:03.933928 10215 solver.cpp:258]     Train net output #0: loss = 0.000478788 (* 1 = 0.000478788 loss)
I0811 04:39:03.933934 10215 sgd_solver.cpp:112] Iteration 18900, lr = 0.001
I0811 04:39:16.558030 10215 solver.cpp:239] Iteration 18970 (5.5451 iter/s, 12.6238s/70 iters), loss = 0.00662663
I0811 04:39:16.558058 10215 solver.cpp:258]     Train net output #0: loss = 0.00662699 (* 1 = 0.00662699 loss)
I0811 04:39:16.558064 10215 sgd_solver.cpp:112] Iteration 18970, lr = 0.001
I0811 04:39:29.171027 10215 solver.cpp:239] Iteration 19040 (5.54999 iter/s, 12.6126s/70 iters), loss = 0.00032571
I0811 04:39:29.171159 10215 solver.cpp:258]     Train net output #0: loss = 0.000326055 (* 1 = 0.000326055 loss)
I0811 04:39:29.171166 10215 sgd_solver.cpp:112] Iteration 19040, lr = 0.001
I0811 04:39:35.343204 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:39:41.169929 10215 solver.cpp:347] Iteration 19108, Testing net (#0)
I0811 04:39:41.169941 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:39:56.368211 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:39:58.197510 10215 solver.cpp:414]     Test net output #0: accuracy = 0.995334
I0811 04:39:58.197530 10215 solver.cpp:414]     Test net output #1: loss = 0.0148312 (* 1 = 0.0148312 loss)
I0811 04:39:58.740622 10215 solver.cpp:239] Iteration 19110 (2.36737 iter/s, 29.5687s/70 iters), loss = 0.000145629
I0811 04:39:58.740648 10215 solver.cpp:258]     Train net output #0: loss = 0.000145995 (* 1 = 0.000145995 loss)
I0811 04:39:58.740654 10215 sgd_solver.cpp:112] Iteration 19110, lr = 0.001
I0811 04:40:11.368858 10215 solver.cpp:239] Iteration 19180 (5.5433 iter/s, 12.6279s/70 iters), loss = 0.000434875
I0811 04:40:11.368991 10215 solver.cpp:258]     Train net output #0: loss = 0.000435228 (* 1 = 0.000435228 loss)
I0811 04:40:11.368999 10215 sgd_solver.cpp:112] Iteration 19180, lr = 0.001
I0811 04:40:23.986588 10215 solver.cpp:239] Iteration 19250 (5.54796 iter/s, 12.6173s/70 iters), loss = 0.00365716
I0811 04:40:23.986618 10215 solver.cpp:258]     Train net output #0: loss = 0.00365753 (* 1 = 0.00365753 loss)
I0811 04:40:23.986625 10215 sgd_solver.cpp:112] Iteration 19250, lr = 0.001
I0811 04:40:36.600473 10215 solver.cpp:239] Iteration 19320 (5.5496 iter/s, 12.6135s/70 iters), loss = 0.00720575
I0811 04:40:36.600500 10215 solver.cpp:258]     Train net output #0: loss = 0.00720612 (* 1 = 0.00720612 loss)
I0811 04:40:36.600507 10215 sgd_solver.cpp:112] Iteration 19320, lr = 0.001
I0811 04:40:49.233016 10215 solver.cpp:239] Iteration 19390 (5.54141 iter/s, 12.6322s/70 iters), loss = 0.035514
I0811 04:40:49.233151 10215 solver.cpp:258]     Train net output #0: loss = 0.0355144 (* 1 = 0.0355144 loss)
I0811 04:40:49.233158 10215 sgd_solver.cpp:112] Iteration 19390, lr = 0.001
I0811 04:41:01.835363 10215 solver.cpp:239] Iteration 19460 (5.55473 iter/s, 12.6019s/70 iters), loss = 0.000424984
I0811 04:41:01.835391 10215 solver.cpp:258]     Train net output #0: loss = 0.000425362 (* 1 = 0.000425362 loss)
I0811 04:41:01.835395 10215 sgd_solver.cpp:112] Iteration 19460, lr = 0.001
I0811 04:41:14.437707 10215 solver.cpp:239] Iteration 19530 (5.55469 iter/s, 12.602s/70 iters), loss = 0.00177725
I0811 04:41:14.437734 10215 solver.cpp:258]     Train net output #0: loss = 0.00177765 (* 1 = 0.00177765 loss)
I0811 04:41:14.437741 10215 sgd_solver.cpp:112] Iteration 19530, lr = 0.001
I0811 04:41:27.058027 10215 solver.cpp:239] Iteration 19600 (5.54677 iter/s, 12.6199s/70 iters), loss = 0.00128194
I0811 04:41:27.058109 10215 solver.cpp:258]     Train net output #0: loss = 0.00128234 (* 1 = 0.00128234 loss)
I0811 04:41:27.058118 10215 sgd_solver.cpp:112] Iteration 19600, lr = 0.001
I0811 04:41:33.419869 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:41:39.429675 10215 solver.cpp:347] Iteration 19670, Testing net (#0)
I0811 04:41:39.429690 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:41:54.571079 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:41:56.445863 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9965
I0811 04:41:56.445885 10215 solver.cpp:414]     Test net output #1: loss = 0.0124507 (* 1 = 0.0124507 loss)
I0811 04:41:56.628769 10215 solver.cpp:239] Iteration 19670 (2.36728 iter/s, 29.5699s/70 iters), loss = 0.0373812
I0811 04:41:56.629983 10215 solver.cpp:258]     Train net output #0: loss = 0.0373816 (* 1 = 0.0373816 loss)
I0811 04:41:56.629994 10215 sgd_solver.cpp:112] Iteration 19670, lr = 0.001
I0811 04:42:09.260428 10215 solver.cpp:239] Iteration 19740 (5.54231 iter/s, 12.6301s/70 iters), loss = 0.0127461
I0811 04:42:09.260599 10215 solver.cpp:258]     Train net output #0: loss = 0.0127465 (* 1 = 0.0127465 loss)
I0811 04:42:09.260607 10215 sgd_solver.cpp:112] Iteration 19740, lr = 0.001
I0811 04:42:21.875870 10215 solver.cpp:239] Iteration 19810 (5.54897 iter/s, 12.6149s/70 iters), loss = 0.000218171
I0811 04:42:21.875898 10215 solver.cpp:258]     Train net output #0: loss = 0.000218593 (* 1 = 0.000218593 loss)
I0811 04:42:21.875905 10215 sgd_solver.cpp:112] Iteration 19810, lr = 0.001
I0811 04:42:34.499601 10215 solver.cpp:239] Iteration 19880 (5.54528 iter/s, 12.6234s/70 iters), loss = 0.00206475
I0811 04:42:34.499630 10215 solver.cpp:258]     Train net output #0: loss = 0.00206518 (* 1 = 0.00206518 loss)
I0811 04:42:34.499636 10215 sgd_solver.cpp:112] Iteration 19880, lr = 0.001
I0811 04:42:47.121516 10215 solver.cpp:239] Iteration 19950 (5.54607 iter/s, 12.6215s/70 iters), loss = 0.00170733
I0811 04:42:47.121642 10215 solver.cpp:258]     Train net output #0: loss = 0.00170775 (* 1 = 0.00170775 loss)
I0811 04:42:47.121661 10215 sgd_solver.cpp:112] Iteration 19950, lr = 0.001
I0811 04:42:59.746810 10215 solver.cpp:239] Iteration 20020 (5.54463 iter/s, 12.6248s/70 iters), loss = 0.000271024
I0811 04:42:59.746837 10215 solver.cpp:258]     Train net output #0: loss = 0.000271442 (* 1 = 0.000271442 loss)
I0811 04:42:59.746842 10215 sgd_solver.cpp:112] Iteration 20020, lr = 0.001
I0811 04:43:12.360422 10215 solver.cpp:239] Iteration 20090 (5.54972 iter/s, 12.6132s/70 iters), loss = 0.000158335
I0811 04:43:12.360451 10215 solver.cpp:258]     Train net output #0: loss = 0.000158748 (* 1 = 0.000158748 loss)
I0811 04:43:12.360457 10215 sgd_solver.cpp:112] Iteration 20090, lr = 0.001
I0811 04:43:24.993357 10215 solver.cpp:239] Iteration 20160 (5.54124 iter/s, 12.6326s/70 iters), loss = 0.0040001
I0811 04:43:24.993520 10215 solver.cpp:258]     Train net output #0: loss = 0.00400051 (* 1 = 0.00400051 loss)
I0811 04:43:24.993528 10215 sgd_solver.cpp:112] Iteration 20160, lr = 0.001
I0811 04:43:31.532115 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:43:37.619580 10215 solver.cpp:239] Iteration 20230 (5.54424 iter/s, 12.6257s/70 iters), loss = 0.00841657
I0811 04:43:37.619607 10215 solver.cpp:258]     Train net output #0: loss = 0.00841698 (* 1 = 0.00841698 loss)
I0811 04:43:37.619612 10215 sgd_solver.cpp:112] Iteration 20230, lr = 0.001
I0811 04:43:37.717422 10215 solver.cpp:347] Iteration 20232, Testing net (#0)
I0811 04:43:37.717434 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:43:52.781721 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:43:54.698974 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996333
I0811 04:43:54.698999 10215 solver.cpp:414]     Test net output #1: loss = 0.0110412 (* 1 = 0.0110412 loss)
I0811 04:44:07.149502 10215 solver.cpp:239] Iteration 20300 (2.37054 iter/s, 29.5291s/70 iters), loss = 0.00475237
I0811 04:44:07.149654 10215 solver.cpp:258]     Train net output #0: loss = 0.00475277 (* 1 = 0.00475277 loss)
I0811 04:44:07.149662 10215 sgd_solver.cpp:112] Iteration 20300, lr = 0.001
I0811 04:44:19.777184 10215 solver.cpp:239] Iteration 20370 (5.54359 iter/s, 12.6272s/70 iters), loss = 0.000216539
I0811 04:44:19.777211 10215 solver.cpp:258]     Train net output #0: loss = 0.000216933 (* 1 = 0.000216933 loss)
I0811 04:44:19.777218 10215 sgd_solver.cpp:112] Iteration 20370, lr = 0.001
I0811 04:44:32.400547 10215 solver.cpp:239] Iteration 20440 (5.54544 iter/s, 12.623s/70 iters), loss = 0.000372254
I0811 04:44:32.400588 10215 solver.cpp:258]     Train net output #0: loss = 0.000372657 (* 1 = 0.000372657 loss)
I0811 04:44:32.400594 10215 sgd_solver.cpp:112] Iteration 20440, lr = 0.001
I0811 04:44:45.035989 10215 solver.cpp:239] Iteration 20510 (5.54014 iter/s, 12.6351s/70 iters), loss = 0.000513005
I0811 04:44:45.036077 10215 solver.cpp:258]     Train net output #0: loss = 0.000513396 (* 1 = 0.000513396 loss)
I0811 04:44:45.036095 10215 sgd_solver.cpp:112] Iteration 20510, lr = 0.001
I0811 04:44:57.675954 10215 solver.cpp:239] Iteration 20580 (5.53818 iter/s, 12.6395s/70 iters), loss = 0.000105588
I0811 04:44:57.675983 10215 solver.cpp:258]     Train net output #0: loss = 0.000105988 (* 1 = 0.000105988 loss)
I0811 04:44:57.675989 10215 sgd_solver.cpp:112] Iteration 20580, lr = 0.001
I0811 04:45:10.294785 10215 solver.cpp:239] Iteration 20650 (5.54743 iter/s, 12.6185s/70 iters), loss = 0.0014687
I0811 04:45:10.294811 10215 solver.cpp:258]     Train net output #0: loss = 0.00146911 (* 1 = 0.00146911 loss)
I0811 04:45:10.294816 10215 sgd_solver.cpp:112] Iteration 20650, lr = 0.001
I0811 04:45:22.931630 10215 solver.cpp:239] Iteration 20720 (5.53952 iter/s, 12.6365s/70 iters), loss = 0.0331471
I0811 04:45:22.931769 10215 solver.cpp:258]     Train net output #0: loss = 0.0331475 (* 1 = 0.0331475 loss)
I0811 04:45:22.931777 10215 sgd_solver.cpp:112] Iteration 20720, lr = 0.001
I0811 04:45:29.667564 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:45:35.543771 10215 solver.cpp:239] Iteration 20790 (5.55042 iter/s, 12.6117s/70 iters), loss = 0.00037177
I0811 04:45:35.543802 10215 solver.cpp:258]     Train net output #0: loss = 0.000372194 (* 1 = 0.000372194 loss)
I0811 04:45:35.543808 10215 sgd_solver.cpp:112] Iteration 20790, lr = 0.001
I0811 04:45:36.000506 10215 solver.cpp:347] Iteration 20794, Testing net (#0)
I0811 04:45:36.000520 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:45:50.969456 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:45:52.940865 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996334
I0811 04:45:52.940981 10215 solver.cpp:414]     Test net output #1: loss = 0.011007 (* 1 = 0.011007 loss)
I0811 04:46:05.028501 10215 solver.cpp:239] Iteration 20860 (2.37418 iter/s, 29.4839s/70 iters), loss = 0.00408434
I0811 04:46:05.028528 10215 solver.cpp:258]     Train net output #0: loss = 0.00408478 (* 1 = 0.00408478 loss)
I0811 04:46:05.028534 10215 sgd_solver.cpp:112] Iteration 20860, lr = 0.001
I0811 04:46:17.652199 10215 solver.cpp:239] Iteration 20930 (5.54529 iter/s, 12.6233s/70 iters), loss = 0.0022555
I0811 04:46:17.652227 10215 solver.cpp:258]     Train net output #0: loss = 0.00225591 (* 1 = 0.00225591 loss)
I0811 04:46:17.652233 10215 sgd_solver.cpp:112] Iteration 20930, lr = 0.001
I0811 04:46:30.286098 10215 solver.cpp:239] Iteration 21000 (5.54081 iter/s, 12.6335s/70 iters), loss = 0.000974044
I0811 04:46:30.286237 10215 solver.cpp:258]     Train net output #0: loss = 0.000974452 (* 1 = 0.000974452 loss)
I0811 04:46:30.286243 10215 sgd_solver.cpp:112] Iteration 21000, lr = 0.001
I0811 04:46:42.911396 10215 solver.cpp:239] Iteration 21070 (5.54463 iter/s, 12.6248s/70 iters), loss = 0.000150886
I0811 04:46:42.911425 10215 solver.cpp:258]     Train net output #0: loss = 0.000151299 (* 1 = 0.000151299 loss)
I0811 04:46:42.911432 10215 sgd_solver.cpp:112] Iteration 21070, lr = 0.001
I0811 04:46:55.535416 10215 solver.cpp:239] Iteration 21140 (5.54515 iter/s, 12.6236s/70 iters), loss = 0.000835518
I0811 04:46:55.535464 10215 solver.cpp:258]     Train net output #0: loss = 0.000835931 (* 1 = 0.000835931 loss)
I0811 04:46:55.535470 10215 sgd_solver.cpp:112] Iteration 21140, lr = 0.001
I0811 04:47:08.160460 10215 solver.cpp:239] Iteration 21210 (5.54471 iter/s, 12.6247s/70 iters), loss = 9.52268e-05
I0811 04:47:08.160601 10215 solver.cpp:258]     Train net output #0: loss = 9.56367e-05 (* 1 = 9.56367e-05 loss)
I0811 04:47:08.160609 10215 sgd_solver.cpp:112] Iteration 21210, lr = 0.001
I0811 04:47:20.786938 10215 solver.cpp:239] Iteration 21280 (5.54412 iter/s, 12.626s/70 iters), loss = 0.0150805
I0811 04:47:20.786965 10215 solver.cpp:258]     Train net output #0: loss = 0.0150809 (* 1 = 0.0150809 loss)
I0811 04:47:20.786972 10215 sgd_solver.cpp:112] Iteration 21280, lr = 0.001
I0811 04:47:27.702672 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:47:33.408932 10215 solver.cpp:239] Iteration 21350 (5.54604 iter/s, 12.6216s/70 iters), loss = 0.000175022
I0811 04:47:33.408960 10215 solver.cpp:258]     Train net output #0: loss = 0.000175455 (* 1 = 0.000175455 loss)
I0811 04:47:33.408965 10215 sgd_solver.cpp:112] Iteration 21350, lr = 0.001
I0811 04:47:34.228883 10215 solver.cpp:347] Iteration 21356, Testing net (#0)
I0811 04:47:34.228898 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:47:37.269867 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:47:49.173924 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:47:51.203953 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996334
I0811 04:47:51.203976 10215 solver.cpp:414]     Test net output #1: loss = 0.00996108 (* 1 = 0.00996108 loss)
I0811 04:48:02.938110 10215 solver.cpp:239] Iteration 21420 (2.3706 iter/s, 29.5284s/70 iters), loss = 0.00248381
I0811 04:48:02.938136 10215 solver.cpp:258]     Train net output #0: loss = 0.00248424 (* 1 = 0.00248424 loss)
I0811 04:48:02.938143 10215 sgd_solver.cpp:112] Iteration 21420, lr = 0.001
I0811 04:48:15.553097 10215 solver.cpp:239] Iteration 21490 (5.54912 iter/s, 12.6146s/70 iters), loss = 0.00422537
I0811 04:48:15.553124 10215 solver.cpp:258]     Train net output #0: loss = 0.00422583 (* 1 = 0.00422583 loss)
I0811 04:48:15.553129 10215 sgd_solver.cpp:112] Iteration 21490, lr = 0.001
I0811 04:48:28.184638 10215 solver.cpp:239] Iteration 21560 (5.54185 iter/s, 12.6312s/70 iters), loss = 0.000187617
I0811 04:48:28.184824 10215 solver.cpp:258]     Train net output #0: loss = 0.000188076 (* 1 = 0.000188076 loss)
I0811 04:48:28.184833 10215 sgd_solver.cpp:112] Iteration 21560, lr = 0.001
I0811 04:48:40.800743 10215 solver.cpp:239] Iteration 21630 (5.5487 iter/s, 12.6156s/70 iters), loss = 0.000974353
I0811 04:48:40.800770 10215 solver.cpp:258]     Train net output #0: loss = 0.000974803 (* 1 = 0.000974803 loss)
I0811 04:48:40.800776 10215 sgd_solver.cpp:112] Iteration 21630, lr = 0.001
I0811 04:48:53.433112 10215 solver.cpp:239] Iteration 21700 (5.54148 iter/s, 12.632s/70 iters), loss = 0.000247407
I0811 04:48:53.433141 10215 solver.cpp:258]     Train net output #0: loss = 0.000247862 (* 1 = 0.000247862 loss)
I0811 04:48:53.433148 10215 sgd_solver.cpp:112] Iteration 21700, lr = 0.001
I0811 04:49:06.068606 10215 solver.cpp:239] Iteration 21770 (5.54011 iter/s, 12.6351s/70 iters), loss = 0.000271153
I0811 04:49:06.068744 10215 solver.cpp:258]     Train net output #0: loss = 0.000271609 (* 1 = 0.000271609 loss)
I0811 04:49:06.068751 10215 sgd_solver.cpp:112] Iteration 21770, lr = 0.001
I0811 04:49:18.696022 10215 solver.cpp:239] Iteration 21840 (5.5437 iter/s, 12.6269s/70 iters), loss = 0.000257306
I0811 04:49:18.696053 10215 solver.cpp:258]     Train net output #0: loss = 0.000257767 (* 1 = 0.000257767 loss)
I0811 04:49:18.696059 10215 sgd_solver.cpp:112] Iteration 21840, lr = 0.001
I0811 04:49:25.821460 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:49:31.320458 10215 solver.cpp:239] Iteration 21910 (5.54497 iter/s, 12.6241s/70 iters), loss = 0.00669973
I0811 04:49:31.320487 10215 solver.cpp:258]     Train net output #0: loss = 0.00670019 (* 1 = 0.00670019 loss)
I0811 04:49:31.320492 10215 sgd_solver.cpp:112] Iteration 21910, lr = 0.001
I0811 04:49:32.497673 10215 solver.cpp:347] Iteration 21918, Testing net (#0)
I0811 04:49:32.497687 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:49:47.390803 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:49:49.466995 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9965
I0811 04:49:49.467020 10215 solver.cpp:414]     Test net output #1: loss = 0.00988955 (* 1 = 0.00988955 loss)
I0811 04:50:00.816303 10215 solver.cpp:239] Iteration 21980 (2.37328 iter/s, 29.495s/70 iters), loss = 0.00187958
I0811 04:50:00.816331 10215 solver.cpp:258]     Train net output #0: loss = 0.00188004 (* 1 = 0.00188004 loss)
I0811 04:50:00.816337 10215 sgd_solver.cpp:112] Iteration 21980, lr = 0.001
I0811 04:50:13.428514 10215 solver.cpp:239] Iteration 22050 (5.55034 iter/s, 12.6118s/70 iters), loss = 0.00614463
I0811 04:50:13.428540 10215 solver.cpp:258]     Train net output #0: loss = 0.00614509 (* 1 = 0.00614509 loss)
I0811 04:50:13.428545 10215 sgd_solver.cpp:112] Iteration 22050, lr = 0.001
I0811 04:50:26.039919 10215 solver.cpp:239] Iteration 22120 (5.55069 iter/s, 12.611s/70 iters), loss = 0.00389932
I0811 04:50:26.040060 10215 solver.cpp:258]     Train net output #0: loss = 0.00389978 (* 1 = 0.00389978 loss)
I0811 04:50:26.040068 10215 sgd_solver.cpp:112] Iteration 22120, lr = 0.001
I0811 04:50:38.639248 10215 solver.cpp:239] Iteration 22190 (5.55606 iter/s, 12.5988s/70 iters), loss = 0.00360126
I0811 04:50:38.639276 10215 solver.cpp:258]     Train net output #0: loss = 0.00360173 (* 1 = 0.00360173 loss)
I0811 04:50:38.639282 10215 sgd_solver.cpp:112] Iteration 22190, lr = 0.001
I0811 04:50:51.261453 10215 solver.cpp:239] Iteration 22260 (5.54595 iter/s, 12.6218s/70 iters), loss = 0.000312163
I0811 04:50:51.261484 10215 solver.cpp:258]     Train net output #0: loss = 0.000312629 (* 1 = 0.000312629 loss)
I0811 04:50:51.261490 10215 sgd_solver.cpp:112] Iteration 22260, lr = 0.001
I0811 04:51:03.894399 10215 solver.cpp:239] Iteration 22330 (5.54123 iter/s, 12.6326s/70 iters), loss = 0.000188105
I0811 04:51:03.894485 10215 solver.cpp:258]     Train net output #0: loss = 0.000188582 (* 1 = 0.000188582 loss)
I0811 04:51:03.894492 10215 sgd_solver.cpp:112] Iteration 22330, lr = 0.001
I0811 04:51:16.521852 10215 solver.cpp:239] Iteration 22400 (5.54366 iter/s, 12.627s/70 iters), loss = 0.00539659
I0811 04:51:16.521880 10215 solver.cpp:258]     Train net output #0: loss = 0.00539708 (* 1 = 0.00539708 loss)
I0811 04:51:16.521886 10215 sgd_solver.cpp:112] Iteration 22400, lr = 0.001
I0811 04:51:23.821576 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:51:29.145910 10215 solver.cpp:239] Iteration 22470 (5.54513 iter/s, 12.6237s/70 iters), loss = 0.022228
I0811 04:51:29.145936 10215 solver.cpp:258]     Train net output #0: loss = 0.0222284 (* 1 = 0.0222284 loss)
I0811 04:51:29.145942 10215 sgd_solver.cpp:112] Iteration 22470, lr = 0.001
I0811 04:51:30.683405 10215 solver.cpp:464] Snapshotting to binary proto file snapshot_iter_22480.caffemodel
I0811 04:51:30.778764 10215 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshot_iter_22480.solverstate
I0811 04:51:30.783351 10215 solver.cpp:347] Iteration 22480, Testing net (#0)
I0811 04:51:30.783362 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:51:45.745708 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:51:47.866628 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996834
I0811 04:51:47.866652 10215 solver.cpp:414]     Test net output #1: loss = 0.00916944 (* 1 = 0.00916944 loss)
I0811 04:51:58.879889 10215 solver.cpp:239] Iteration 22540 (2.35427 iter/s, 29.7331s/70 iters), loss = 0.000968616
I0811 04:51:58.879918 10215 solver.cpp:258]     Train net output #0: loss = 0.000969094 (* 1 = 0.000969094 loss)
I0811 04:51:58.879925 10215 sgd_solver.cpp:112] Iteration 22540, lr = 0.001
I0811 04:52:11.496316 10215 solver.cpp:239] Iteration 22610 (5.54849 iter/s, 12.6161s/70 iters), loss = 6.98045e-05
I0811 04:52:11.496346 10215 solver.cpp:258]     Train net output #0: loss = 7.0278e-05 (* 1 = 7.0278e-05 loss)
I0811 04:52:11.496352 10215 sgd_solver.cpp:112] Iteration 22610, lr = 0.001
I0811 04:52:24.119959 10215 solver.cpp:239] Iteration 22680 (5.54532 iter/s, 12.6233s/70 iters), loss = 0.0259728
I0811 04:52:24.120016 10215 solver.cpp:258]     Train net output #0: loss = 0.0259733 (* 1 = 0.0259733 loss)
I0811 04:52:24.120023 10215 sgd_solver.cpp:112] Iteration 22680, lr = 0.001
I0811 04:52:36.743019 10215 solver.cpp:239] Iteration 22750 (5.54558 iter/s, 12.6227s/70 iters), loss = 0.000683636
I0811 04:52:36.743046 10215 solver.cpp:258]     Train net output #0: loss = 0.000684123 (* 1 = 0.000684123 loss)
I0811 04:52:36.743052 10215 sgd_solver.cpp:112] Iteration 22750, lr = 0.001
I0811 04:52:49.355429 10215 solver.cpp:239] Iteration 22820 (5.55025 iter/s, 12.612s/70 iters), loss = 0.000256978
I0811 04:52:49.355459 10215 solver.cpp:258]     Train net output #0: loss = 0.000257499 (* 1 = 0.000257499 loss)
I0811 04:52:49.355465 10215 sgd_solver.cpp:112] Iteration 22820, lr = 0.001
I0811 04:53:01.987949 10215 solver.cpp:239] Iteration 22890 (5.54142 iter/s, 12.6321s/70 iters), loss = 0.000156529
I0811 04:53:01.988078 10215 solver.cpp:258]     Train net output #0: loss = 0.000157042 (* 1 = 0.000157042 loss)
I0811 04:53:01.988097 10215 sgd_solver.cpp:112] Iteration 22890, lr = 0.001
I0811 04:53:14.602689 10215 solver.cpp:239] Iteration 22960 (5.54927 iter/s, 12.6143s/70 iters), loss = 0.00122869
I0811 04:53:14.602715 10215 solver.cpp:258]     Train net output #0: loss = 0.0012292 (* 1 = 0.0012292 loss)
I0811 04:53:14.602721 10215 sgd_solver.cpp:112] Iteration 22960, lr = 0.001
I0811 04:53:22.196292 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:53:27.225652 10215 solver.cpp:239] Iteration 23030 (5.54561 iter/s, 12.6226s/70 iters), loss = 0.00431225
I0811 04:53:27.225679 10215 solver.cpp:258]     Train net output #0: loss = 0.00431276 (* 1 = 0.00431276 loss)
I0811 04:53:27.225684 10215 sgd_solver.cpp:112] Iteration 23030, lr = 0.001
I0811 04:53:29.124707 10215 solver.cpp:347] Iteration 23042, Testing net (#0)
I0811 04:53:29.124720 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:53:43.884006 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:53:46.078286 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996167
I0811 04:53:46.078310 10215 solver.cpp:414]     Test net output #1: loss = 0.0101402 (* 1 = 0.0101402 loss)
I0811 04:53:56.711684 10215 solver.cpp:239] Iteration 23100 (2.37407 iter/s, 29.4852s/70 iters), loss = 0.00105421
I0811 04:53:56.711710 10215 solver.cpp:258]     Train net output #0: loss = 0.00105472 (* 1 = 0.00105472 loss)
I0811 04:53:56.711715 10215 sgd_solver.cpp:112] Iteration 23100, lr = 0.001
I0811 04:54:09.335264 10215 solver.cpp:239] Iteration 23170 (5.54534 iter/s, 12.6232s/70 iters), loss = 0.0742276
I0811 04:54:09.335296 10215 solver.cpp:258]     Train net output #0: loss = 0.0742281 (* 1 = 0.0742281 loss)
I0811 04:54:09.335302 10215 sgd_solver.cpp:112] Iteration 23170, lr = 0.001
I0811 04:54:21.957629 10215 solver.cpp:239] Iteration 23240 (5.54588 iter/s, 12.622s/70 iters), loss = 0.0028073
I0811 04:54:21.957736 10215 solver.cpp:258]     Train net output #0: loss = 0.00280782 (* 1 = 0.00280782 loss)
I0811 04:54:21.957742 10215 sgd_solver.cpp:112] Iteration 23240, lr = 0.001
I0811 04:54:34.570688 10215 solver.cpp:239] Iteration 23310 (5.55001 iter/s, 12.6126s/70 iters), loss = 0.00169473
I0811 04:54:34.570755 10215 solver.cpp:258]     Train net output #0: loss = 0.00169524 (* 1 = 0.00169524 loss)
I0811 04:54:34.570761 10215 sgd_solver.cpp:112] Iteration 23310, lr = 0.001
I0811 04:54:47.196858 10215 solver.cpp:239] Iteration 23380 (5.54421 iter/s, 12.6258s/70 iters), loss = 0.00463474
I0811 04:54:47.196890 10215 solver.cpp:258]     Train net output #0: loss = 0.00463525 (* 1 = 0.00463525 loss)
I0811 04:54:47.196897 10215 sgd_solver.cpp:112] Iteration 23380, lr = 0.001
I0811 04:54:59.827278 10215 solver.cpp:239] Iteration 23450 (5.54234 iter/s, 12.63s/70 iters), loss = 0.00265211
I0811 04:54:59.827462 10215 solver.cpp:258]     Train net output #0: loss = 0.00265263 (* 1 = 0.00265263 loss)
I0811 04:54:59.827471 10215 sgd_solver.cpp:112] Iteration 23450, lr = 0.001
I0811 04:55:12.450248 10215 solver.cpp:239] Iteration 23520 (5.54568 iter/s, 12.6224s/70 iters), loss = 1.73358e-05
I0811 04:55:12.450278 10215 solver.cpp:258]     Train net output #0: loss = 1.78514e-05 (* 1 = 1.78514e-05 loss)
I0811 04:55:12.450282 10215 sgd_solver.cpp:112] Iteration 23520, lr = 0.001
I0811 04:55:20.238342 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:55:25.077771 10215 solver.cpp:239] Iteration 23590 (5.54361 iter/s, 12.6272s/70 iters), loss = 0.000600578
I0811 04:55:25.077798 10215 solver.cpp:258]     Train net output #0: loss = 0.000601088 (* 1 = 0.000601088 loss)
I0811 04:55:25.077805 10215 sgd_solver.cpp:112] Iteration 23590, lr = 0.001
I0811 04:55:27.334589 10215 solver.cpp:347] Iteration 23604, Testing net (#0)
I0811 04:55:27.334615 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:55:34.391556 10215 blocking_queue.cpp:49] Waiting for data
I0811 04:55:42.175048 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:55:44.411919 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 04:55:44.411942 10215 solver.cpp:414]     Test net output #1: loss = 0.00966279 (* 1 = 0.00966279 loss)
I0811 04:55:54.692848 10215 solver.cpp:239] Iteration 23660 (2.36373 iter/s, 29.6143s/70 iters), loss = 0.00375976
I0811 04:55:54.692876 10215 solver.cpp:258]     Train net output #0: loss = 0.00376027 (* 1 = 0.00376027 loss)
I0811 04:55:54.692883 10215 sgd_solver.cpp:112] Iteration 23660, lr = 0.001
I0811 04:56:07.309664 10215 solver.cpp:239] Iteration 23730 (5.54832 iter/s, 12.6164s/70 iters), loss = 0.00105907
I0811 04:56:07.309803 10215 solver.cpp:258]     Train net output #0: loss = 0.00105958 (* 1 = 0.00105958 loss)
I0811 04:56:07.309809 10215 sgd_solver.cpp:112] Iteration 23730, lr = 0.001
I0811 04:56:19.919205 10215 solver.cpp:239] Iteration 23800 (5.55156 iter/s, 12.6091s/70 iters), loss = 0.0304396
I0811 04:56:19.919234 10215 solver.cpp:258]     Train net output #0: loss = 0.0304401 (* 1 = 0.0304401 loss)
I0811 04:56:19.919240 10215 sgd_solver.cpp:112] Iteration 23800, lr = 0.001
I0811 04:56:32.530448 10215 solver.cpp:239] Iteration 23870 (5.55077 iter/s, 12.6109s/70 iters), loss = 0.00102389
I0811 04:56:32.530478 10215 solver.cpp:258]     Train net output #0: loss = 0.0010244 (* 1 = 0.0010244 loss)
I0811 04:56:32.530483 10215 sgd_solver.cpp:112] Iteration 23870, lr = 0.001
I0811 04:56:45.152273 10215 solver.cpp:239] Iteration 23940 (5.54611 iter/s, 12.6215s/70 iters), loss = 0.012575
I0811 04:56:45.152403 10215 solver.cpp:258]     Train net output #0: loss = 0.0125756 (* 1 = 0.0125756 loss)
I0811 04:56:45.152411 10215 sgd_solver.cpp:112] Iteration 23940, lr = 0.001
I0811 04:56:57.756593 10215 solver.cpp:239] Iteration 24010 (5.55386 iter/s, 12.6039s/70 iters), loss = 0.0164815
I0811 04:56:57.756621 10215 solver.cpp:258]     Train net output #0: loss = 0.016482 (* 1 = 0.016482 loss)
I0811 04:56:57.756628 10215 sgd_solver.cpp:112] Iteration 24010, lr = 0.001
I0811 04:57:10.379314 10215 solver.cpp:239] Iteration 24080 (5.54572 iter/s, 12.6223s/70 iters), loss = 0.0844168
I0811 04:57:10.379341 10215 solver.cpp:258]     Train net output #0: loss = 0.0844173 (* 1 = 0.0844173 loss)
I0811 04:57:10.379348 10215 sgd_solver.cpp:112] Iteration 24080, lr = 0.001
I0811 04:57:18.372336 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:57:23.015360 10215 solver.cpp:239] Iteration 24150 (5.53987 iter/s, 12.6357s/70 iters), loss = 0.000257179
I0811 04:57:23.015388 10215 solver.cpp:258]     Train net output #0: loss = 0.000257705 (* 1 = 0.000257705 loss)
I0811 04:57:23.015394 10215 sgd_solver.cpp:112] Iteration 24150, lr = 0.001
I0811 04:57:25.638620 10215 solver.cpp:347] Iteration 24166, Testing net (#0)
I0811 04:57:25.638635 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:57:40.252354 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:57:42.531335 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9965
I0811 04:57:42.531358 10215 solver.cpp:414]     Test net output #1: loss = 0.00924742 (* 1 = 0.00924742 loss)
I0811 04:57:52.438501 10215 solver.cpp:239] Iteration 24220 (2.37915 iter/s, 29.4223s/70 iters), loss = 0.281583
I0811 04:57:52.438652 10215 solver.cpp:258]     Train net output #0: loss = 0.281583 (* 1 = 0.281583 loss)
I0811 04:57:52.438660 10215 sgd_solver.cpp:112] Iteration 24220, lr = 0.001
I0811 04:58:05.064929 10215 solver.cpp:239] Iteration 24290 (5.54414 iter/s, 12.6259s/70 iters), loss = 0.00627171
I0811 04:58:05.064957 10215 solver.cpp:258]     Train net output #0: loss = 0.00627223 (* 1 = 0.00627223 loss)
I0811 04:58:05.064963 10215 sgd_solver.cpp:112] Iteration 24290, lr = 0.001
I0811 04:58:17.689337 10215 solver.cpp:239] Iteration 24360 (5.54498 iter/s, 12.624s/70 iters), loss = 0.0369454
I0811 04:58:17.689365 10215 solver.cpp:258]     Train net output #0: loss = 0.0369459 (* 1 = 0.0369459 loss)
I0811 04:58:17.689370 10215 sgd_solver.cpp:112] Iteration 24360, lr = 0.001
I0811 04:58:30.322540 10215 solver.cpp:239] Iteration 24430 (5.54112 iter/s, 12.6328s/70 iters), loss = 0.00105149
I0811 04:58:30.322682 10215 solver.cpp:258]     Train net output #0: loss = 0.00105201 (* 1 = 0.00105201 loss)
I0811 04:58:30.322690 10215 sgd_solver.cpp:112] Iteration 24430, lr = 0.001
I0811 04:58:42.946192 10215 solver.cpp:239] Iteration 24500 (5.54536 iter/s, 12.6232s/70 iters), loss = 3.34689e-05
I0811 04:58:42.946221 10215 solver.cpp:258]     Train net output #0: loss = 3.3993e-05 (* 1 = 3.3993e-05 loss)
I0811 04:58:42.946226 10215 sgd_solver.cpp:112] Iteration 24500, lr = 0.001
I0811 04:58:55.568014 10215 solver.cpp:239] Iteration 24570 (5.54611 iter/s, 12.6215s/70 iters), loss = 0.00173403
I0811 04:58:55.568042 10215 solver.cpp:258]     Train net output #0: loss = 0.00173457 (* 1 = 0.00173457 loss)
I0811 04:58:55.568048 10215 sgd_solver.cpp:112] Iteration 24570, lr = 0.001
I0811 04:59:08.193914 10215 solver.cpp:239] Iteration 24640 (5.54432 iter/s, 12.6255s/70 iters), loss = 6.91526e-05
I0811 04:59:08.194056 10215 solver.cpp:258]     Train net output #0: loss = 6.96872e-05 (* 1 = 6.96872e-05 loss)
I0811 04:59:08.194064 10215 sgd_solver.cpp:112] Iteration 24640, lr = 0.001
I0811 04:59:16.365314 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:59:20.820058 10215 solver.cpp:239] Iteration 24710 (5.54427 iter/s, 12.6257s/70 iters), loss = 0.000114003
I0811 04:59:20.820088 10215 solver.cpp:258]     Train net output #0: loss = 0.000114528 (* 1 = 0.000114528 loss)
I0811 04:59:20.820094 10215 sgd_solver.cpp:112] Iteration 24710, lr = 0.001
I0811 04:59:23.797946 10215 solver.cpp:347] Iteration 24728, Testing net (#0)
I0811 04:59:23.797960 10215 net.cpp:676] Ignoring source layer train-data
I0811 04:59:38.417331 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 04:59:40.749506 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996334
I0811 04:59:40.749528 10215 solver.cpp:414]     Test net output #1: loss = 0.00963402 (* 1 = 0.00963402 loss)
I0811 04:59:50.317704 10215 solver.cpp:239] Iteration 24780 (2.37314 iter/s, 29.4968s/70 iters), loss = 0.00547236
I0811 04:59:50.317731 10215 solver.cpp:258]     Train net output #0: loss = 0.00547287 (* 1 = 0.00547287 loss)
I0811 04:59:50.317737 10215 sgd_solver.cpp:112] Iteration 24780, lr = 0.001
I0811 05:00:02.932430 10215 solver.cpp:239] Iteration 24850 (5.54923 iter/s, 12.6144s/70 iters), loss = 0.00885446
I0811 05:00:02.932457 10215 solver.cpp:258]     Train net output #0: loss = 0.00885497 (* 1 = 0.00885497 loss)
I0811 05:00:02.932463 10215 sgd_solver.cpp:112] Iteration 24850, lr = 0.001
I0811 05:00:15.540591 10215 solver.cpp:239] Iteration 24920 (5.55212 iter/s, 12.6078s/70 iters), loss = 0.00119361
I0811 05:00:15.540683 10215 solver.cpp:258]     Train net output #0: loss = 0.00119412 (* 1 = 0.00119412 loss)
I0811 05:00:15.540690 10215 sgd_solver.cpp:112] Iteration 24920, lr = 0.001
I0811 05:00:28.165729 10215 solver.cpp:239] Iteration 24990 (5.54468 iter/s, 12.6247s/70 iters), loss = 8.06674e-05
I0811 05:00:28.165757 10215 solver.cpp:258]     Train net output #0: loss = 8.1172e-05 (* 1 = 8.1172e-05 loss)
I0811 05:00:28.165763 10215 sgd_solver.cpp:112] Iteration 24990, lr = 0.001
I0811 05:00:40.784678 10215 solver.cpp:239] Iteration 25060 (5.54738 iter/s, 12.6186s/70 iters), loss = 0.000436091
I0811 05:00:40.784705 10215 solver.cpp:258]     Train net output #0: loss = 0.000436587 (* 1 = 0.000436587 loss)
I0811 05:00:40.784711 10215 sgd_solver.cpp:112] Iteration 25060, lr = 0.001
I0811 05:00:53.399937 10215 solver.cpp:239] Iteration 25130 (5.549 iter/s, 12.6149s/70 iters), loss = 0.000278127
I0811 05:00:53.400013 10215 solver.cpp:258]     Train net output #0: loss = 0.000278609 (* 1 = 0.000278609 loss)
I0811 05:00:53.400020 10215 sgd_solver.cpp:112] Iteration 25130, lr = 0.001
I0811 05:01:06.036319 10215 solver.cpp:239] Iteration 25200 (5.53974 iter/s, 12.636s/70 iters), loss = 0.0535765
I0811 05:01:06.036345 10215 solver.cpp:258]     Train net output #0: loss = 0.053577 (* 1 = 0.053577 loss)
I0811 05:01:06.036351 10215 sgd_solver.cpp:112] Iteration 25200, lr = 0.001
I0811 05:01:14.402180 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:01:18.659616 10215 solver.cpp:239] Iteration 25270 (5.54546 iter/s, 12.6229s/70 iters), loss = 0.00399195
I0811 05:01:18.659643 10215 solver.cpp:258]     Train net output #0: loss = 0.00399242 (* 1 = 0.00399242 loss)
I0811 05:01:18.659649 10215 sgd_solver.cpp:112] Iteration 25270, lr = 0.001
I0811 05:01:22.004139 10215 solver.cpp:347] Iteration 25290, Testing net (#0)
I0811 05:01:22.004153 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:01:36.583883 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:01:38.981344 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996667
I0811 05:01:38.981369 10215 solver.cpp:414]     Test net output #1: loss = 0.00871025 (* 1 = 0.00871025 loss)
I0811 05:01:48.183859 10215 solver.cpp:239] Iteration 25340 (2.371 iter/s, 29.5234s/70 iters), loss = 0.000129087
I0811 05:01:48.183887 10215 solver.cpp:258]     Train net output #0: loss = 0.000129556 (* 1 = 0.000129556 loss)
I0811 05:01:48.183892 10215 sgd_solver.cpp:112] Iteration 25340, lr = 0.001
I0811 05:02:00.815802 10215 solver.cpp:239] Iteration 25410 (5.54167 iter/s, 12.6316s/70 iters), loss = 0.00101122
I0811 05:02:00.815829 10215 solver.cpp:258]     Train net output #0: loss = 0.00101169 (* 1 = 0.00101169 loss)
I0811 05:02:00.815835 10215 sgd_solver.cpp:112] Iteration 25410, lr = 0.001
I0811 05:02:13.445749 10215 solver.cpp:239] Iteration 25480 (5.54255 iter/s, 12.6296s/70 iters), loss = 0.000141844
I0811 05:02:13.445888 10215 solver.cpp:258]     Train net output #0: loss = 0.000142309 (* 1 = 0.000142309 loss)
I0811 05:02:13.445896 10215 sgd_solver.cpp:112] Iteration 25480, lr = 0.001
I0811 05:02:26.073113 10215 solver.cpp:239] Iteration 25550 (5.54373 iter/s, 12.6269s/70 iters), loss = 0.131432
I0811 05:02:26.073144 10215 solver.cpp:258]     Train net output #0: loss = 0.131432 (* 1 = 0.131432 loss)
I0811 05:02:26.073150 10215 sgd_solver.cpp:112] Iteration 25550, lr = 0.001
I0811 05:02:38.700567 10215 solver.cpp:239] Iteration 25620 (5.54364 iter/s, 12.6271s/70 iters), loss = 0.000397606
I0811 05:02:38.700594 10215 solver.cpp:258]     Train net output #0: loss = 0.000398082 (* 1 = 0.000398082 loss)
I0811 05:02:38.700600 10215 sgd_solver.cpp:112] Iteration 25620, lr = 0.001
I0811 05:02:51.322954 10215 solver.cpp:239] Iteration 25690 (5.54587 iter/s, 12.622s/70 iters), loss = 0.0144935
I0811 05:02:51.323073 10215 solver.cpp:258]     Train net output #0: loss = 0.014494 (* 1 = 0.014494 loss)
I0811 05:02:51.323093 10215 sgd_solver.cpp:112] Iteration 25690, lr = 0.001
I0811 05:03:03.945163 10215 solver.cpp:239] Iteration 25760 (5.54599 iter/s, 12.6217s/70 iters), loss = 0.0013324
I0811 05:03:03.945195 10215 solver.cpp:258]     Train net output #0: loss = 0.00133288 (* 1 = 0.00133288 loss)
I0811 05:03:03.945202 10215 sgd_solver.cpp:112] Iteration 25760, lr = 0.001
I0811 05:03:12.485652 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:03:16.561977 10215 solver.cpp:239] Iteration 25830 (5.54832 iter/s, 12.6164s/70 iters), loss = 0.0094636
I0811 05:03:16.562005 10215 solver.cpp:258]     Train net output #0: loss = 0.00946408 (* 1 = 0.00946408 loss)
I0811 05:03:16.562011 10215 sgd_solver.cpp:112] Iteration 25830, lr = 0.001
I0811 05:03:20.270357 10215 solver.cpp:347] Iteration 25852, Testing net (#0)
I0811 05:03:20.270372 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:03:31.452666 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:03:34.858907 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:03:37.283607 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996667
I0811 05:03:37.283632 10215 solver.cpp:414]     Test net output #1: loss = 0.00898042 (* 1 = 0.00898042 loss)
I0811 05:03:46.128523 10215 solver.cpp:239] Iteration 25900 (2.36761 iter/s, 29.5657s/70 iters), loss = 1.09375e-05
I0811 05:03:46.128551 10215 solver.cpp:258]     Train net output #0: loss = 1.14113e-05 (* 1 = 1.14113e-05 loss)
I0811 05:03:46.128557 10215 sgd_solver.cpp:112] Iteration 25900, lr = 0.001
I0811 05:03:58.770731 10215 solver.cpp:239] Iteration 25970 (5.53717 iter/s, 12.6418s/70 iters), loss = 7.7441e-05
I0811 05:03:58.770757 10215 solver.cpp:258]     Train net output #0: loss = 7.79138e-05 (* 1 = 7.79138e-05 loss)
I0811 05:03:58.770763 10215 sgd_solver.cpp:112] Iteration 25970, lr = 0.001
I0811 05:04:11.378017 10215 solver.cpp:239] Iteration 26040 (5.55251 iter/s, 12.6069s/70 iters), loss = 0.0058964
I0811 05:04:11.378062 10215 solver.cpp:258]     Train net output #0: loss = 0.00589687 (* 1 = 0.00589687 loss)
I0811 05:04:11.378067 10215 sgd_solver.cpp:112] Iteration 26040, lr = 0.001
I0811 05:04:23.999125 10215 solver.cpp:239] Iteration 26110 (5.54644 iter/s, 12.6207s/70 iters), loss = 4.47274e-05
I0811 05:04:23.999155 10215 solver.cpp:258]     Train net output #0: loss = 4.51999e-05 (* 1 = 4.51999e-05 loss)
I0811 05:04:23.999161 10215 sgd_solver.cpp:112] Iteration 26110, lr = 0.001
I0811 05:04:36.632450 10215 solver.cpp:239] Iteration 26180 (5.54106 iter/s, 12.633s/70 iters), loss = 0.0203203
I0811 05:04:36.632477 10215 solver.cpp:258]     Train net output #0: loss = 0.0203207 (* 1 = 0.0203207 loss)
I0811 05:04:36.632483 10215 sgd_solver.cpp:112] Iteration 26180, lr = 0.001
I0811 05:04:49.234505 10215 solver.cpp:239] Iteration 26250 (5.55481 iter/s, 12.6017s/70 iters), loss = 0.000156734
I0811 05:04:49.234633 10215 solver.cpp:258]     Train net output #0: loss = 0.000157205 (* 1 = 0.000157205 loss)
I0811 05:04:49.234652 10215 sgd_solver.cpp:112] Iteration 26250, lr = 0.001
I0811 05:05:01.856717 10215 solver.cpp:239] Iteration 26320 (5.54599 iter/s, 12.6217s/70 iters), loss = 4.144e-05
I0811 05:05:01.856743 10215 solver.cpp:258]     Train net output #0: loss = 4.19074e-05 (* 1 = 4.19074e-05 loss)
I0811 05:05:01.856750 10215 sgd_solver.cpp:112] Iteration 26320, lr = 0.001
I0811 05:05:10.573575 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:05:14.469908 10215 solver.cpp:239] Iteration 26390 (5.54991 iter/s, 12.6128s/70 iters), loss = 0.0129842
I0811 05:05:14.469934 10215 solver.cpp:258]     Train net output #0: loss = 0.0129846 (* 1 = 0.0129846 loss)
I0811 05:05:14.469940 10215 sgd_solver.cpp:112] Iteration 26390, lr = 0.001
I0811 05:05:18.536164 10215 solver.cpp:347] Iteration 26414, Testing net (#0)
I0811 05:05:18.536180 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:05:32.968753 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:05:35.457953 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 05:05:35.457976 10215 solver.cpp:414]     Test net output #1: loss = 0.00923744 (* 1 = 0.00923744 loss)
I0811 05:05:43.942060 10215 solver.cpp:239] Iteration 26460 (2.37519 iter/s, 29.4713s/70 iters), loss = 9.2526e-05
I0811 05:05:43.942090 10215 solver.cpp:258]     Train net output #0: loss = 9.29854e-05 (* 1 = 9.29854e-05 loss)
I0811 05:05:43.942095 10215 sgd_solver.cpp:112] Iteration 26460, lr = 0.001
I0811 05:05:56.556015 10215 solver.cpp:239] Iteration 26530 (5.54957 iter/s, 12.6136s/70 iters), loss = 4.53671e-05
I0811 05:05:56.556042 10215 solver.cpp:258]     Train net output #0: loss = 4.581e-05 (* 1 = 4.581e-05 loss)
I0811 05:05:56.556047 10215 sgd_solver.cpp:112] Iteration 26530, lr = 0.001
I0811 05:06:09.179481 10215 solver.cpp:239] Iteration 26600 (5.54539 iter/s, 12.6231s/70 iters), loss = 0.0511075
I0811 05:06:09.179630 10215 solver.cpp:258]     Train net output #0: loss = 0.0511079 (* 1 = 0.0511079 loss)
I0811 05:06:09.179638 10215 sgd_solver.cpp:112] Iteration 26600, lr = 0.001
I0811 05:06:21.779098 10215 solver.cpp:239] Iteration 26670 (5.55594 iter/s, 12.5991s/70 iters), loss = 3.46769e-05
I0811 05:06:21.779126 10215 solver.cpp:258]     Train net output #0: loss = 3.51175e-05 (* 1 = 3.51175e-05 loss)
I0811 05:06:21.779131 10215 sgd_solver.cpp:112] Iteration 26670, lr = 0.001
I0811 05:06:34.403664 10215 solver.cpp:239] Iteration 26740 (5.54491 iter/s, 12.6242s/70 iters), loss = 0.00524042
I0811 05:06:34.403692 10215 solver.cpp:258]     Train net output #0: loss = 0.00524085 (* 1 = 0.00524085 loss)
I0811 05:06:34.403698 10215 sgd_solver.cpp:112] Iteration 26740, lr = 0.001
I0811 05:06:47.016803 10215 solver.cpp:239] Iteration 26810 (5.54993 iter/s, 12.6128s/70 iters), loss = 0.00334079
I0811 05:06:47.016942 10215 solver.cpp:258]     Train net output #0: loss = 0.00334122 (* 1 = 0.00334122 loss)
I0811 05:06:47.016948 10215 sgd_solver.cpp:112] Iteration 26810, lr = 0.001
I0811 05:06:59.643321 10215 solver.cpp:239] Iteration 26880 (5.54409 iter/s, 12.626s/70 iters), loss = 0.000380598
I0811 05:06:59.643350 10215 solver.cpp:258]     Train net output #0: loss = 0.000381027 (* 1 = 0.000381027 loss)
I0811 05:06:59.643355 10215 sgd_solver.cpp:112] Iteration 26880, lr = 0.001
I0811 05:07:08.569584 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:07:12.274803 10215 solver.cpp:239] Iteration 26950 (5.54187 iter/s, 12.6311s/70 iters), loss = 0.000462346
I0811 05:07:12.274832 10215 solver.cpp:258]     Train net output #0: loss = 0.000462757 (* 1 = 0.000462757 loss)
I0811 05:07:12.274838 10215 sgd_solver.cpp:112] Iteration 26950, lr = 0.001
I0811 05:07:16.689725 10215 solver.cpp:347] Iteration 26976, Testing net (#0)
I0811 05:07:16.689741 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:07:31.169492 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:07:33.711216 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996834
I0811 05:07:33.711241 10215 solver.cpp:414]     Test net output #1: loss = 0.00907395 (* 1 = 0.00907395 loss)
I0811 05:07:41.832800 10215 solver.cpp:239] Iteration 27020 (2.36829 iter/s, 29.5572s/70 iters), loss = 0.000835774
I0811 05:07:41.832828 10215 solver.cpp:258]     Train net output #0: loss = 0.000836174 (* 1 = 0.000836174 loss)
I0811 05:07:41.832834 10215 sgd_solver.cpp:112] Iteration 27020, lr = 0.001
I0811 05:07:54.453886 10215 solver.cpp:239] Iteration 27090 (5.54644 iter/s, 12.6207s/70 iters), loss = 0.000966804
I0811 05:07:54.453913 10215 solver.cpp:258]     Train net output #0: loss = 0.0009672 (* 1 = 0.0009672 loss)
I0811 05:07:54.453919 10215 sgd_solver.cpp:112] Iteration 27090, lr = 0.001
I0811 05:08:07.067095 10215 solver.cpp:239] Iteration 27160 (5.5499 iter/s, 12.6128s/70 iters), loss = 3.67255e-05
I0811 05:08:07.067268 10215 solver.cpp:258]     Train net output #0: loss = 3.7122e-05 (* 1 = 3.7122e-05 loss)
I0811 05:08:07.067276 10215 sgd_solver.cpp:112] Iteration 27160, lr = 0.001
I0811 05:08:19.679836 10215 solver.cpp:239] Iteration 27230 (5.55017 iter/s, 12.6122s/70 iters), loss = 0.000201056
I0811 05:08:19.679862 10215 solver.cpp:258]     Train net output #0: loss = 0.000201456 (* 1 = 0.000201456 loss)
I0811 05:08:19.679868 10215 sgd_solver.cpp:112] Iteration 27230, lr = 0.001
I0811 05:08:32.303378 10215 solver.cpp:239] Iteration 27300 (5.54536 iter/s, 12.6232s/70 iters), loss = 0.000129051
I0811 05:08:32.303406 10215 solver.cpp:258]     Train net output #0: loss = 0.000129449 (* 1 = 0.000129449 loss)
I0811 05:08:32.303411 10215 sgd_solver.cpp:112] Iteration 27300, lr = 0.001
I0811 05:08:44.913875 10215 solver.cpp:239] Iteration 27370 (5.55109 iter/s, 12.6101s/70 iters), loss = 0.00138601
I0811 05:08:44.914014 10215 solver.cpp:258]     Train net output #0: loss = 0.00138641 (* 1 = 0.00138641 loss)
I0811 05:08:44.914022 10215 sgd_solver.cpp:112] Iteration 27370, lr = 0.001
I0811 05:08:57.526578 10215 solver.cpp:239] Iteration 27440 (5.55017 iter/s, 12.6122s/70 iters), loss = 0.00301546
I0811 05:08:57.526603 10215 solver.cpp:258]     Train net output #0: loss = 0.00301586 (* 1 = 0.00301586 loss)
I0811 05:08:57.526609 10215 sgd_solver.cpp:112] Iteration 27440, lr = 0.001
I0811 05:09:06.748910 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:09:10.151979 10215 solver.cpp:239] Iteration 27510 (5.54454 iter/s, 12.625s/70 iters), loss = 0.000364834
I0811 05:09:10.152006 10215 solver.cpp:258]     Train net output #0: loss = 0.000365228 (* 1 = 0.000365228 loss)
I0811 05:09:10.152012 10215 sgd_solver.cpp:112] Iteration 27510, lr = 0.001
I0811 05:09:14.938052 10215 solver.cpp:347] Iteration 27538, Testing net (#0)
I0811 05:09:14.938123 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:09:29.307662 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:09:31.910310 10215 solver.cpp:414]     Test net output #0: accuracy = 0.996334
I0811 05:09:31.910332 10215 solver.cpp:414]     Test net output #1: loss = 0.0102907 (* 1 = 0.0102907 loss)
I0811 05:09:39.667053 10215 solver.cpp:239] Iteration 27580 (2.37174 iter/s, 29.5143s/70 iters), loss = 0.00311772
I0811 05:09:39.667083 10215 solver.cpp:258]     Train net output #0: loss = 0.00311812 (* 1 = 0.00311812 loss)
I0811 05:09:39.667089 10215 sgd_solver.cpp:112] Iteration 27580, lr = 0.001
I0811 05:09:52.285620 10215 solver.cpp:239] Iteration 27650 (5.54755 iter/s, 12.6182s/70 iters), loss = 4.03868e-05
I0811 05:09:52.285665 10215 solver.cpp:258]     Train net output #0: loss = 4.07853e-05 (* 1 = 4.07853e-05 loss)
I0811 05:09:52.285670 10215 sgd_solver.cpp:112] Iteration 27650, lr = 0.001
I0811 05:10:04.896322 10215 solver.cpp:239] Iteration 27720 (5.55101 iter/s, 12.6103s/70 iters), loss = 3.0824e-05
I0811 05:10:04.896350 10215 solver.cpp:258]     Train net output #0: loss = 3.12264e-05 (* 1 = 3.12264e-05 loss)
I0811 05:10:04.896355 10215 sgd_solver.cpp:112] Iteration 27720, lr = 0.001
I0811 05:10:17.518448 10215 solver.cpp:239] Iteration 27790 (5.54598 iter/s, 12.6218s/70 iters), loss = 7.98887e-05
I0811 05:10:17.518478 10215 solver.cpp:258]     Train net output #0: loss = 8.02905e-05 (* 1 = 8.02905e-05 loss)
I0811 05:10:17.518484 10215 sgd_solver.cpp:112] Iteration 27790, lr = 0.001
I0811 05:10:30.120807 10215 solver.cpp:239] Iteration 27860 (5.55468 iter/s, 12.602s/70 iters), loss = 0.0109226
I0811 05:10:30.120893 10215 solver.cpp:258]     Train net output #0: loss = 0.010923 (* 1 = 0.010923 loss)
I0811 05:10:30.120911 10215 sgd_solver.cpp:112] Iteration 27860, lr = 0.001
I0811 05:10:42.733369 10215 solver.cpp:239] Iteration 27930 (5.55021 iter/s, 12.6121s/70 iters), loss = 0.00409478
I0811 05:10:42.733397 10215 solver.cpp:258]     Train net output #0: loss = 0.00409519 (* 1 = 0.00409519 loss)
I0811 05:10:42.733402 10215 sgd_solver.cpp:112] Iteration 27930, lr = 0.001
I0811 05:10:55.354135 10215 solver.cpp:239] Iteration 28000 (5.54658 iter/s, 12.6204s/70 iters), loss = 0.000514645
I0811 05:10:55.354166 10215 solver.cpp:258]     Train net output #0: loss = 0.000515055 (* 1 = 0.000515055 loss)
I0811 05:10:55.354172 10215 sgd_solver.cpp:112] Iteration 28000, lr = 0.001
I0811 05:11:04.775347 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:11:07.981652 10215 solver.cpp:239] Iteration 28070 (5.54361 iter/s, 12.6271s/70 iters), loss = 0.010951
I0811 05:11:07.981678 10215 solver.cpp:258]     Train net output #0: loss = 0.0109514 (* 1 = 0.0109514 loss)
I0811 05:11:07.981683 10215 sgd_solver.cpp:112] Iteration 28070, lr = 0.001
I0811 05:11:13.136364 10215 solver.cpp:347] Iteration 28100, Testing net (#0)
I0811 05:11:13.136379 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:11:27.532373 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:11:28.327913 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:11:30.187608 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997
I0811 05:11:30.187633 10215 solver.cpp:414]     Test net output #1: loss = 0.00859407 (* 1 = 0.00859407 loss)
I0811 05:11:37.583349 10215 solver.cpp:239] Iteration 28140 (2.36479 iter/s, 29.6009s/70 iters), loss = 8.00093e-07
I0811 05:11:37.583492 10215 solver.cpp:258]     Train net output #0: loss = 1.20328e-06 (* 1 = 1.20328e-06 loss)
I0811 05:11:37.583499 10215 sgd_solver.cpp:112] Iteration 28140, lr = 0.001
I0811 05:11:50.203958 10215 solver.cpp:239] Iteration 28210 (5.5467 iter/s, 12.6201s/70 iters), loss = 0.0393133
I0811 05:11:50.203984 10215 solver.cpp:258]     Train net output #0: loss = 0.0393137 (* 1 = 0.0393137 loss)
I0811 05:11:50.203989 10215 sgd_solver.cpp:112] Iteration 28210, lr = 0.001
I0811 05:12:02.830317 10215 solver.cpp:239] Iteration 28280 (5.54412 iter/s, 12.626s/70 iters), loss = 1.95756e-05
I0811 05:12:02.830344 10215 solver.cpp:258]     Train net output #0: loss = 1.99907e-05 (* 1 = 1.99907e-05 loss)
I0811 05:12:02.830350 10215 sgd_solver.cpp:112] Iteration 28280, lr = 0.001
I0811 05:12:15.455044 10215 solver.cpp:239] Iteration 28350 (5.54484 iter/s, 12.6243s/70 iters), loss = 0.000685165
I0811 05:12:15.455106 10215 solver.cpp:258]     Train net output #0: loss = 0.000685582 (* 1 = 0.000685582 loss)
I0811 05:12:15.455113 10215 sgd_solver.cpp:112] Iteration 28350, lr = 0.001
I0811 05:12:28.079459 10215 solver.cpp:239] Iteration 28420 (5.54499 iter/s, 12.624s/70 iters), loss = 0.000249133
I0811 05:12:28.079486 10215 solver.cpp:258]     Train net output #0: loss = 0.000249541 (* 1 = 0.000249541 loss)
I0811 05:12:28.079493 10215 sgd_solver.cpp:112] Iteration 28420, lr = 0.001
I0811 05:12:40.703994 10215 solver.cpp:239] Iteration 28490 (5.54492 iter/s, 12.6242s/70 iters), loss = 9.63323e-05
I0811 05:12:40.704020 10215 solver.cpp:258]     Train net output #0: loss = 9.67399e-05 (* 1 = 9.67399e-05 loss)
I0811 05:12:40.704026 10215 sgd_solver.cpp:112] Iteration 28490, lr = 0.001
I0811 05:12:53.321892 10215 solver.cpp:239] Iteration 28560 (5.54784 iter/s, 12.6175s/70 iters), loss = 6.8667e-05
I0811 05:12:53.321957 10215 solver.cpp:258]     Train net output #0: loss = 6.90725e-05 (* 1 = 6.90725e-05 loss)
I0811 05:12:53.321964 10215 sgd_solver.cpp:112] Iteration 28560, lr = 0.001
I0811 05:13:02.925891 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:13:05.944861 10215 solver.cpp:239] Iteration 28630 (5.54563 iter/s, 12.6226s/70 iters), loss = 7.09318e-05
I0811 05:13:05.944890 10215 solver.cpp:258]     Train net output #0: loss = 7.13392e-05 (* 1 = 7.13392e-05 loss)
I0811 05:13:05.944895 10215 sgd_solver.cpp:112] Iteration 28630, lr = 0.001
I0811 05:13:11.456580 10215 solver.cpp:347] Iteration 28662, Testing net (#0)
I0811 05:13:11.456596 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:13:25.692555 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:13:28.402947 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 05:13:28.402971 10215 solver.cpp:414]     Test net output #1: loss = 0.00821554 (* 1 = 0.00821554 loss)
I0811 05:13:35.437608 10215 solver.cpp:239] Iteration 28700 (2.37353 iter/s, 29.4919s/70 iters), loss = 8.8545e-05
I0811 05:13:35.437639 10215 solver.cpp:258]     Train net output #0: loss = 8.89527e-05 (* 1 = 8.89527e-05 loss)
I0811 05:13:35.437645 10215 sgd_solver.cpp:112] Iteration 28700, lr = 0.001
I0811 05:13:48.048487 10215 solver.cpp:239] Iteration 28770 (5.55093 iter/s, 12.6105s/70 iters), loss = 0.0097606
I0811 05:13:48.048513 10215 solver.cpp:258]     Train net output #0: loss = 0.009761 (* 1 = 0.009761 loss)
I0811 05:13:48.048519 10215 sgd_solver.cpp:112] Iteration 28770, lr = 0.001
I0811 05:14:00.676693 10215 solver.cpp:239] Iteration 28840 (5.54331 iter/s, 12.6278s/70 iters), loss = 2.87616e-05
I0811 05:14:00.676857 10215 solver.cpp:258]     Train net output #0: loss = 2.91568e-05 (* 1 = 2.91568e-05 loss)
I0811 05:14:00.676878 10215 sgd_solver.cpp:112] Iteration 28840, lr = 0.001
I0811 05:14:13.305733 10215 solver.cpp:239] Iteration 28910 (5.543 iter/s, 12.6285s/70 iters), loss = 0.000243596
I0811 05:14:13.305760 10215 solver.cpp:258]     Train net output #0: loss = 0.000243995 (* 1 = 0.000243995 loss)
I0811 05:14:13.305768 10215 sgd_solver.cpp:112] Iteration 28910, lr = 0.001
I0811 05:14:25.945073 10215 solver.cpp:239] Iteration 28980 (5.53843 iter/s, 12.639s/70 iters), loss = 0.000505574
I0811 05:14:25.945101 10215 solver.cpp:258]     Train net output #0: loss = 0.000505967 (* 1 = 0.000505967 loss)
I0811 05:14:25.945107 10215 sgd_solver.cpp:112] Iteration 28980, lr = 0.001
I0811 05:14:38.573598 10215 solver.cpp:239] Iteration 29050 (5.54317 iter/s, 12.6282s/70 iters), loss = 0.0145817
I0811 05:14:38.573736 10215 solver.cpp:258]     Train net output #0: loss = 0.0145821 (* 1 = 0.0145821 loss)
I0811 05:14:38.573743 10215 sgd_solver.cpp:112] Iteration 29050, lr = 0.001
I0811 05:14:51.189337 10215 solver.cpp:239] Iteration 29120 (5.54883 iter/s, 12.6153s/70 iters), loss = 0.00137258
I0811 05:14:51.189363 10215 solver.cpp:258]     Train net output #0: loss = 0.00137294 (* 1 = 0.00137294 loss)
I0811 05:14:51.189369 10215 sgd_solver.cpp:112] Iteration 29120, lr = 0.001
I0811 05:15:00.991565 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:15:03.816876 10215 solver.cpp:239] Iteration 29190 (5.5436 iter/s, 12.6272s/70 iters), loss = 0.000391044
I0811 05:15:03.816903 10215 solver.cpp:258]     Train net output #0: loss = 0.00039141 (* 1 = 0.00039141 loss)
I0811 05:15:03.816910 10215 sgd_solver.cpp:112] Iteration 29190, lr = 0.001
I0811 05:15:09.682976 10215 solver.cpp:347] Iteration 29224, Testing net (#0)
I0811 05:15:09.683087 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:15:24.689813 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:15:27.582654 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9965
I0811 05:15:27.582681 10215 solver.cpp:414]     Test net output #1: loss = 0.00926353 (* 1 = 0.00926353 loss)
I0811 05:15:34.249539 10215 solver.cpp:239] Iteration 29260 (2.30022 iter/s, 30.4318s/70 iters), loss = 0.00119691
I0811 05:15:34.249572 10215 solver.cpp:258]     Train net output #0: loss = 0.00119728 (* 1 = 0.00119728 loss)
I0811 05:15:34.249577 10215 sgd_solver.cpp:112] Iteration 29260, lr = 0.001
I0811 05:15:46.881842 10215 solver.cpp:239] Iteration 29330 (5.54151 iter/s, 12.6319s/70 iters), loss = 0.000517324
I0811 05:15:46.881963 10215 solver.cpp:258]     Train net output #0: loss = 0.000517688 (* 1 = 0.000517688 loss)
I0811 05:15:46.881983 10215 sgd_solver.cpp:112] Iteration 29330, lr = 0.001
I0811 05:15:59.502028 10215 solver.cpp:239] Iteration 29400 (5.54687 iter/s, 12.6197s/70 iters), loss = 0.000247443
I0811 05:15:59.502058 10215 solver.cpp:258]     Train net output #0: loss = 0.000247799 (* 1 = 0.000247799 loss)
I0811 05:15:59.502064 10215 sgd_solver.cpp:112] Iteration 29400, lr = 0.001
I0811 05:16:12.122637 10215 solver.cpp:239] Iteration 29470 (5.54666 iter/s, 12.6202s/70 iters), loss = 0.0532514
I0811 05:16:12.122676 10215 solver.cpp:258]     Train net output #0: loss = 0.0532518 (* 1 = 0.0532518 loss)
I0811 05:16:12.122683 10215 sgd_solver.cpp:112] Iteration 29470, lr = 0.001
I0811 05:16:24.747923 10215 solver.cpp:239] Iteration 29540 (5.5446 iter/s, 12.6249s/70 iters), loss = 0.000935789
I0811 05:16:24.748090 10215 solver.cpp:258]     Train net output #0: loss = 0.000936161 (* 1 = 0.000936161 loss)
I0811 05:16:24.748096 10215 sgd_solver.cpp:112] Iteration 29540, lr = 0.001
I0811 05:16:37.378942 10215 solver.cpp:239] Iteration 29610 (5.54214 iter/s, 12.6305s/70 iters), loss = 8.35038e-05
I0811 05:16:37.378971 10215 solver.cpp:258]     Train net output #0: loss = 8.38801e-05 (* 1 = 8.38801e-05 loss)
I0811 05:16:37.378978 10215 sgd_solver.cpp:112] Iteration 29610, lr = 0.001
I0811 05:16:49.999496 10215 solver.cpp:239] Iteration 29680 (5.54667 iter/s, 12.6202s/70 iters), loss = 7.21697e-05
I0811 05:16:49.999527 10215 solver.cpp:258]     Train net output #0: loss = 7.25488e-05 (* 1 = 7.25488e-05 loss)
I0811 05:16:49.999533 10215 sgd_solver.cpp:112] Iteration 29680, lr = 0.001
I0811 05:16:59.970886 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:17:02.612186 10215 solver.cpp:239] Iteration 29750 (5.55013 iter/s, 12.6123s/70 iters), loss = 0.000438478
I0811 05:17:02.612216 10215 solver.cpp:258]     Train net output #0: loss = 0.000438857 (* 1 = 0.000438857 loss)
I0811 05:17:02.612222 10215 sgd_solver.cpp:112] Iteration 29750, lr = 0.001
I0811 05:17:08.829354 10215 solver.cpp:347] Iteration 29786, Testing net (#0)
I0811 05:17:08.829368 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:17:23.000691 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:17:25.781827 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 05:17:25.781850 10215 solver.cpp:414]     Test net output #1: loss = 0.00855917 (* 1 = 0.00855917 loss)
I0811 05:17:32.100889 10215 solver.cpp:239] Iteration 29820 (2.37386 iter/s, 29.4879s/70 iters), loss = 0.000675885
I0811 05:17:32.101001 10215 solver.cpp:258]     Train net output #0: loss = 0.000676272 (* 1 = 0.000676272 loss)
I0811 05:17:32.101019 10215 sgd_solver.cpp:112] Iteration 29820, lr = 0.001
I0811 05:17:44.734670 10215 solver.cpp:239] Iteration 29890 (5.5409 iter/s, 12.6333s/70 iters), loss = 0.000343873
I0811 05:17:44.734699 10215 solver.cpp:258]     Train net output #0: loss = 0.000344261 (* 1 = 0.000344261 loss)
I0811 05:17:44.734704 10215 sgd_solver.cpp:112] Iteration 29890, lr = 0.001
I0811 05:17:57.360846 10215 solver.cpp:239] Iteration 29960 (5.5442 iter/s, 12.6258s/70 iters), loss = 0.000166949
I0811 05:17:57.360873 10215 solver.cpp:258]     Train net output #0: loss = 0.000167343 (* 1 = 0.000167343 loss)
I0811 05:17:57.360879 10215 sgd_solver.cpp:112] Iteration 29960, lr = 0.001
I0811 05:18:09.992003 10215 solver.cpp:239] Iteration 30030 (5.54202 iter/s, 12.6308s/70 iters), loss = 0.000111657
I0811 05:18:09.992171 10215 solver.cpp:258]     Train net output #0: loss = 0.000112052 (* 1 = 0.000112052 loss)
I0811 05:18:09.992177 10215 sgd_solver.cpp:112] Iteration 30030, lr = 0.001
I0811 05:18:22.619961 10215 solver.cpp:239] Iteration 30100 (5.54347 iter/s, 12.6275s/70 iters), loss = 0.00270212
I0811 05:18:22.619989 10215 solver.cpp:258]     Train net output #0: loss = 0.00270251 (* 1 = 0.00270251 loss)
I0811 05:18:22.619995 10215 sgd_solver.cpp:112] Iteration 30100, lr = 0.001
I0811 05:18:35.251509 10215 solver.cpp:239] Iteration 30170 (5.54184 iter/s, 12.6312s/70 iters), loss = 0.00110749
I0811 05:18:35.251536 10215 solver.cpp:258]     Train net output #0: loss = 0.00110789 (* 1 = 0.00110789 loss)
I0811 05:18:35.251543 10215 sgd_solver.cpp:112] Iteration 30170, lr = 0.001
I0811 05:18:47.868762 10215 solver.cpp:239] Iteration 30240 (5.54812 iter/s, 12.6169s/70 iters), loss = 5.99563e-05
I0811 05:18:47.868903 10215 solver.cpp:258]     Train net output #0: loss = 6.03546e-05 (* 1 = 6.03546e-05 loss)
I0811 05:18:47.868911 10215 sgd_solver.cpp:112] Iteration 30240, lr = 0.001
I0811 05:18:58.026432 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:19:00.485857 10215 solver.cpp:239] Iteration 30310 (5.54824 iter/s, 12.6166s/70 iters), loss = 0.00286026
I0811 05:19:00.485884 10215 solver.cpp:258]     Train net output #0: loss = 0.00286066 (* 1 = 0.00286066 loss)
I0811 05:19:00.485889 10215 sgd_solver.cpp:112] Iteration 30310, lr = 0.001
I0811 05:19:07.080209 10215 solver.cpp:347] Iteration 30348, Testing net (#0)
I0811 05:19:07.080224 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:19:21.158650 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:19:24.013612 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 05:19:24.013636 10215 solver.cpp:414]     Test net output #1: loss = 0.00671145 (* 1 = 0.00671145 loss)
I0811 05:19:29.973580 10215 solver.cpp:239] Iteration 30380 (2.37394 iter/s, 29.4869s/70 iters), loss = 0.000539775
I0811 05:19:29.973610 10215 solver.cpp:258]     Train net output #0: loss = 0.000540167 (* 1 = 0.000540167 loss)
I0811 05:19:29.973616 10215 sgd_solver.cpp:112] Iteration 30380, lr = 0.001
I0811 05:19:42.597872 10215 solver.cpp:239] Iteration 30450 (5.54503 iter/s, 12.6239s/70 iters), loss = 0.000328001
I0811 05:19:42.597899 10215 solver.cpp:258]     Train net output #0: loss = 0.000328393 (* 1 = 0.000328393 loss)
I0811 05:19:42.597905 10215 sgd_solver.cpp:112] Iteration 30450, lr = 0.001
I0811 05:19:55.213016 10215 solver.cpp:239] Iteration 30520 (5.54905 iter/s, 12.6148s/70 iters), loss = 0.000404818
I0811 05:19:55.213136 10215 solver.cpp:258]     Train net output #0: loss = 0.000405215 (* 1 = 0.000405215 loss)
I0811 05:19:55.213155 10215 sgd_solver.cpp:112] Iteration 30520, lr = 0.001
I0811 05:20:07.833207 10215 solver.cpp:239] Iteration 30590 (5.54687 iter/s, 12.6197s/70 iters), loss = 2.76048e-05
I0811 05:20:07.833236 10215 solver.cpp:258]     Train net output #0: loss = 2.8e-05 (* 1 = 2.8e-05 loss)
I0811 05:20:07.833242 10215 sgd_solver.cpp:112] Iteration 30590, lr = 0.001
I0811 05:20:20.452528 10215 solver.cpp:239] Iteration 30660 (5.54721 iter/s, 12.6189s/70 iters), loss = 0.000243884
I0811 05:20:20.452556 10215 solver.cpp:258]     Train net output #0: loss = 0.000244267 (* 1 = 0.000244267 loss)
I0811 05:20:20.452563 10215 sgd_solver.cpp:112] Iteration 30660, lr = 0.001
I0811 05:20:33.066038 10215 solver.cpp:239] Iteration 30730 (5.54977 iter/s, 12.6131s/70 iters), loss = 0.00470921
I0811 05:20:33.066169 10215 solver.cpp:258]     Train net output #0: loss = 0.00470959 (* 1 = 0.00470959 loss)
I0811 05:20:33.066176 10215 sgd_solver.cpp:112] Iteration 30730, lr = 0.001
I0811 05:20:45.695771 10215 solver.cpp:239] Iteration 30800 (5.54268 iter/s, 12.6293s/70 iters), loss = 0.000271014
I0811 05:20:45.695801 10215 solver.cpp:258]     Train net output #0: loss = 0.000271401 (* 1 = 0.000271401 loss)
I0811 05:20:45.695806 10215 sgd_solver.cpp:112] Iteration 30800, lr = 0.001
I0811 05:20:56.067597 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:20:58.331912 10215 solver.cpp:239] Iteration 30870 (5.53983 iter/s, 12.6358s/70 iters), loss = 3.06867e-05
I0811 05:20:58.331940 10215 solver.cpp:258]     Train net output #0: loss = 3.10682e-05 (* 1 = 3.10682e-05 loss)
I0811 05:20:58.331946 10215 sgd_solver.cpp:112] Iteration 30870, lr = 0.001
I0811 05:21:05.290236 10215 solver.cpp:347] Iteration 30910, Testing net (#0)
I0811 05:21:05.290303 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:21:07.700232 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:21:19.403445 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:21:22.322480 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 05:21:22.322504 10215 solver.cpp:414]     Test net output #1: loss = 0.00653495 (* 1 = 0.00653495 loss)
I0811 05:21:27.921089 10215 solver.cpp:239] Iteration 30940 (2.3658 iter/s, 29.5884s/70 iters), loss = 4.07771e-05
I0811 05:21:27.921116 10215 solver.cpp:258]     Train net output #0: loss = 4.11678e-05 (* 1 = 4.11678e-05 loss)
I0811 05:21:27.921121 10215 sgd_solver.cpp:112] Iteration 30940, lr = 0.001
I0811 05:21:40.546758 10215 solver.cpp:239] Iteration 31010 (5.54442 iter/s, 12.6253s/70 iters), loss = 0.000104043
I0811 05:21:40.546922 10215 solver.cpp:258]     Train net output #0: loss = 0.000104429 (* 1 = 0.000104429 loss)
I0811 05:21:40.546931 10215 sgd_solver.cpp:112] Iteration 31010, lr = 0.001
I0811 05:21:53.158639 10215 solver.cpp:239] Iteration 31080 (5.55055 iter/s, 12.6114s/70 iters), loss = 0.000671904
I0811 05:21:53.158681 10215 solver.cpp:258]     Train net output #0: loss = 0.000672288 (* 1 = 0.000672288 loss)
I0811 05:21:53.158687 10215 sgd_solver.cpp:112] Iteration 31080, lr = 0.001
I0811 05:22:05.787587 10215 solver.cpp:239] Iteration 31150 (5.54299 iter/s, 12.6286s/70 iters), loss = 0.00157786
I0811 05:22:05.787616 10215 solver.cpp:258]     Train net output #0: loss = 0.00157824 (* 1 = 0.00157824 loss)
I0811 05:22:05.787622 10215 sgd_solver.cpp:112] Iteration 31150, lr = 0.001
I0811 05:22:18.414479 10215 solver.cpp:239] Iteration 31220 (5.54389 iter/s, 12.6265s/70 iters), loss = 0.00315748
I0811 05:22:18.414644 10215 solver.cpp:258]     Train net output #0: loss = 0.00315787 (* 1 = 0.00315787 loss)
I0811 05:22:18.414654 10215 sgd_solver.cpp:112] Iteration 31220, lr = 0.001
I0811 05:22:31.027920 10215 solver.cpp:239] Iteration 31290 (5.54986 iter/s, 12.6129s/70 iters), loss = 0.0538502
I0811 05:22:31.027947 10215 solver.cpp:258]     Train net output #0: loss = 0.0538506 (* 1 = 0.0538506 loss)
I0811 05:22:31.027952 10215 sgd_solver.cpp:112] Iteration 31290, lr = 0.001
I0811 05:22:43.654179 10215 solver.cpp:239] Iteration 31360 (5.54416 iter/s, 12.6259s/70 iters), loss = 0.00021307
I0811 05:22:43.654208 10215 solver.cpp:258]     Train net output #0: loss = 0.000213456 (* 1 = 0.000213456 loss)
I0811 05:22:43.654213 10215 sgd_solver.cpp:112] Iteration 31360, lr = 0.001
I0811 05:22:54.222214 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:22:56.293879 10215 solver.cpp:239] Iteration 31430 (5.53827 iter/s, 12.6393s/70 iters), loss = 2.74399e-05
I0811 05:22:56.293907 10215 solver.cpp:258]     Train net output #0: loss = 2.7822e-05 (* 1 = 2.7822e-05 loss)
I0811 05:22:56.293913 10215 sgd_solver.cpp:112] Iteration 31430, lr = 0.001
I0811 05:23:03.612418 10215 solver.cpp:347] Iteration 31472, Testing net (#0)
I0811 05:23:03.612434 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:23:17.612401 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:23:20.569056 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997
I0811 05:23:20.569078 10215 solver.cpp:414]     Test net output #1: loss = 0.00741161 (* 1 = 0.00741161 loss)
I0811 05:23:25.801599 10215 solver.cpp:239] Iteration 31500 (2.37233 iter/s, 29.5069s/70 iters), loss = 2.4359e-05
I0811 05:23:25.801739 10215 solver.cpp:258]     Train net output #0: loss = 2.47409e-05 (* 1 = 2.47409e-05 loss)
I0811 05:23:25.801748 10215 sgd_solver.cpp:112] Iteration 31500, lr = 0.001
I0811 05:23:38.444005 10215 solver.cpp:239] Iteration 31570 (5.53713 iter/s, 12.6419s/70 iters), loss = 0.000261954
I0811 05:23:38.444031 10215 solver.cpp:258]     Train net output #0: loss = 0.00026232 (* 1 = 0.00026232 loss)
I0811 05:23:38.444037 10215 sgd_solver.cpp:112] Iteration 31570, lr = 0.001
I0811 05:23:51.058532 10215 solver.cpp:239] Iteration 31640 (5.54932 iter/s, 12.6142s/70 iters), loss = 0.00993528
I0811 05:23:51.058580 10215 solver.cpp:258]     Train net output #0: loss = 0.00993565 (* 1 = 0.00993565 loss)
I0811 05:23:51.058588 10215 sgd_solver.cpp:112] Iteration 31640, lr = 0.001
I0811 05:24:03.676960 10215 solver.cpp:239] Iteration 31710 (5.54762 iter/s, 12.618s/70 iters), loss = 7.57679e-05
I0811 05:24:03.677099 10215 solver.cpp:258]     Train net output #0: loss = 7.61288e-05 (* 1 = 7.61288e-05 loss)
I0811 05:24:03.677119 10215 sgd_solver.cpp:112] Iteration 31710, lr = 0.001
I0811 05:24:16.308900 10215 solver.cpp:239] Iteration 31780 (5.54172 iter/s, 12.6315s/70 iters), loss = 0.00400911
I0811 05:24:16.308928 10215 solver.cpp:258]     Train net output #0: loss = 0.00400948 (* 1 = 0.00400948 loss)
I0811 05:24:16.308933 10215 sgd_solver.cpp:112] Iteration 31780, lr = 0.001
I0811 05:24:28.918893 10215 solver.cpp:239] Iteration 31850 (5.55132 iter/s, 12.6096s/70 iters), loss = 0.0106732
I0811 05:24:28.918920 10215 solver.cpp:258]     Train net output #0: loss = 0.0106736 (* 1 = 0.0106736 loss)
I0811 05:24:28.918926 10215 sgd_solver.cpp:112] Iteration 31850, lr = 0.001
I0811 05:24:41.550014 10215 solver.cpp:239] Iteration 31920 (5.54203 iter/s, 12.6308s/70 iters), loss = 0.000754981
I0811 05:24:41.550169 10215 solver.cpp:258]     Train net output #0: loss = 0.000755348 (* 1 = 0.000755348 loss)
I0811 05:24:41.550177 10215 sgd_solver.cpp:112] Iteration 31920, lr = 0.001
I0811 05:24:52.395112 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:24:54.179430 10215 solver.cpp:239] Iteration 31990 (5.54283 iter/s, 12.6289s/70 iters), loss = 0.0556107
I0811 05:24:54.179456 10215 solver.cpp:258]     Train net output #0: loss = 0.055611 (* 1 = 0.055611 loss)
I0811 05:24:54.179462 10215 sgd_solver.cpp:112] Iteration 31990, lr = 0.001
I0811 05:25:01.856204 10215 solver.cpp:347] Iteration 32034, Testing net (#0)
I0811 05:25:01.856220 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:25:15.845491 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:25:18.840970 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997
I0811 05:25:18.840993 10215 solver.cpp:414]     Test net output #1: loss = 0.00782477 (* 1 = 0.00782477 loss)
I0811 05:25:23.719542 10215 solver.cpp:239] Iteration 32060 (2.36973 iter/s, 29.5393s/70 iters), loss = 0.000381158
I0811 05:25:23.719569 10215 solver.cpp:258]     Train net output #0: loss = 0.000381521 (* 1 = 0.000381521 loss)
I0811 05:25:23.719575 10215 sgd_solver.cpp:112] Iteration 32060, lr = 0.001
I0811 05:25:36.353165 10215 solver.cpp:239] Iteration 32130 (5.54093 iter/s, 12.6333s/70 iters), loss = 8.45047e-06
I0811 05:25:36.353193 10215 solver.cpp:258]     Train net output #0: loss = 8.81645e-06 (* 1 = 8.81645e-06 loss)
I0811 05:25:36.353199 10215 sgd_solver.cpp:112] Iteration 32130, lr = 0.001
I0811 05:25:48.972760 10215 solver.cpp:239] Iteration 32200 (5.54709 iter/s, 12.6192s/70 iters), loss = 0.000132562
I0811 05:25:48.972901 10215 solver.cpp:258]     Train net output #0: loss = 0.000132929 (* 1 = 0.000132929 loss)
I0811 05:25:48.972908 10215 sgd_solver.cpp:112] Iteration 32200, lr = 0.001
I0811 05:26:01.589798 10215 solver.cpp:239] Iteration 32270 (5.54827 iter/s, 12.6166s/70 iters), loss = 0.0524073
I0811 05:26:01.589826 10215 solver.cpp:258]     Train net output #0: loss = 0.0524077 (* 1 = 0.0524077 loss)
I0811 05:26:01.589831 10215 sgd_solver.cpp:112] Iteration 32270, lr = 0.001
I0811 05:26:14.195153 10215 solver.cpp:239] Iteration 32340 (5.55336 iter/s, 12.605s/70 iters), loss = 1.67741e-05
I0811 05:26:14.195180 10215 solver.cpp:258]     Train net output #0: loss = 1.71436e-05 (* 1 = 1.71436e-05 loss)
I0811 05:26:14.195186 10215 sgd_solver.cpp:112] Iteration 32340, lr = 0.001
I0811 05:26:26.817091 10215 solver.cpp:239] Iteration 32410 (5.54607 iter/s, 12.6216s/70 iters), loss = 1.62361e-05
I0811 05:26:26.817231 10215 solver.cpp:258]     Train net output #0: loss = 1.66081e-05 (* 1 = 1.66081e-05 loss)
I0811 05:26:26.817239 10215 sgd_solver.cpp:112] Iteration 32410, lr = 0.001
I0811 05:26:39.448794 10215 solver.cpp:239] Iteration 32480 (5.54183 iter/s, 12.6312s/70 iters), loss = 0.000253302
I0811 05:26:39.448830 10215 solver.cpp:258]     Train net output #0: loss = 0.000253677 (* 1 = 0.000253677 loss)
I0811 05:26:39.448837 10215 sgd_solver.cpp:112] Iteration 32480, lr = 0.001
I0811 05:26:50.465801 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:26:52.063024 10215 solver.cpp:239] Iteration 32550 (5.54945 iter/s, 12.6139s/70 iters), loss = 8.80983e-05
I0811 05:26:52.063052 10215 solver.cpp:258]     Train net output #0: loss = 8.84668e-05 (* 1 = 8.84668e-05 loss)
I0811 05:26:52.063058 10215 sgd_solver.cpp:112] Iteration 32550, lr = 0.001
I0811 05:27:00.093281 10215 solver.cpp:347] Iteration 32596, Testing net (#0)
I0811 05:27:00.093327 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:27:14.029641 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:27:17.080377 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 05:27:17.080401 10215 solver.cpp:414]     Test net output #1: loss = 0.00715259 (* 1 = 0.00715259 loss)
I0811 05:27:21.586567 10215 solver.cpp:239] Iteration 32620 (2.37105 iter/s, 29.5227s/70 iters), loss = 0.00079252
I0811 05:27:21.586594 10215 solver.cpp:258]     Train net output #0: loss = 0.00079288 (* 1 = 0.00079288 loss)
I0811 05:27:21.586601 10215 sgd_solver.cpp:112] Iteration 32620, lr = 0.001
I0811 05:27:34.199426 10215 solver.cpp:239] Iteration 32690 (5.55006 iter/s, 12.6125s/70 iters), loss = 0.00702471
I0811 05:27:34.199594 10215 solver.cpp:258]     Train net output #0: loss = 0.00702506 (* 1 = 0.00702506 loss)
I0811 05:27:34.199601 10215 sgd_solver.cpp:112] Iteration 32690, lr = 0.001
I0811 05:27:46.825125 10215 solver.cpp:239] Iteration 32760 (5.54447 iter/s, 12.6252s/70 iters), loss = 0.000345459
I0811 05:27:46.825152 10215 solver.cpp:258]     Train net output #0: loss = 0.000345811 (* 1 = 0.000345811 loss)
I0811 05:27:46.825158 10215 sgd_solver.cpp:112] Iteration 32760, lr = 0.001
I0811 05:27:59.448086 10215 solver.cpp:239] Iteration 32830 (5.54561 iter/s, 12.6226s/70 iters), loss = 0.000107711
I0811 05:27:59.448114 10215 solver.cpp:258]     Train net output #0: loss = 0.000108063 (* 1 = 0.000108063 loss)
I0811 05:27:59.448120 10215 sgd_solver.cpp:112] Iteration 32830, lr = 0.001
I0811 05:28:12.079598 10215 solver.cpp:239] Iteration 32900 (5.54186 iter/s, 12.6311s/70 iters), loss = 3.76355e-05
I0811 05:28:12.079695 10215 solver.cpp:258]     Train net output #0: loss = 3.79846e-05 (* 1 = 3.79846e-05 loss)
I0811 05:28:12.079701 10215 sgd_solver.cpp:112] Iteration 32900, lr = 0.001
I0811 05:28:24.696426 10215 solver.cpp:239] Iteration 32970 (5.54833 iter/s, 12.6164s/70 iters), loss = 5.4564e-05
I0811 05:28:24.696454 10215 solver.cpp:258]     Train net output #0: loss = 5.49093e-05 (* 1 = 5.49093e-05 loss)
I0811 05:28:24.696460 10215 sgd_solver.cpp:112] Iteration 32970, lr = 0.001
I0811 05:28:37.320111 10215 solver.cpp:239] Iteration 33040 (5.5453 iter/s, 12.6233s/70 iters), loss = 0.00481847
I0811 05:28:37.320139 10215 solver.cpp:258]     Train net output #0: loss = 0.0048188 (* 1 = 0.0048188 loss)
I0811 05:28:37.320145 10215 sgd_solver.cpp:112] Iteration 33040, lr = 0.001
I0811 05:28:48.554052 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:28:49.957103 10215 solver.cpp:239] Iteration 33110 (5.53946 iter/s, 12.6366s/70 iters), loss = 3.94137e-05
I0811 05:28:49.957129 10215 solver.cpp:258]     Train net output #0: loss = 3.97495e-05 (* 1 = 3.97495e-05 loss)
I0811 05:28:49.957134 10215 sgd_solver.cpp:112] Iteration 33110, lr = 0.001
I0811 05:28:58.346752 10215 solver.cpp:347] Iteration 33158, Testing net (#0)
I0811 05:28:58.346766 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:29:05.067844 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:29:12.493858 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:29:15.620388 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 05:29:15.620411 10215 solver.cpp:414]     Test net output #1: loss = 0.00815326 (* 1 = 0.00815326 loss)
I0811 05:29:19.773489 10215 solver.cpp:239] Iteration 33180 (2.34777 iter/s, 29.8156s/70 iters), loss = 0.0866551
I0811 05:29:19.773632 10215 solver.cpp:258]     Train net output #0: loss = 0.0866554 (* 1 = 0.0866554 loss)
I0811 05:29:19.773639 10215 sgd_solver.cpp:112] Iteration 33180, lr = 0.001
I0811 05:29:32.398634 10215 solver.cpp:239] Iteration 33250 (5.5447 iter/s, 12.6247s/70 iters), loss = 0.0218231
I0811 05:29:32.398661 10215 solver.cpp:258]     Train net output #0: loss = 0.0218235 (* 1 = 0.0218235 loss)
I0811 05:29:32.398666 10215 sgd_solver.cpp:112] Iteration 33250, lr = 0.001
I0811 05:29:45.024466 10215 solver.cpp:239] Iteration 33320 (5.54435 iter/s, 12.6255s/70 iters), loss = 0.000543368
I0811 05:29:45.024493 10215 solver.cpp:258]     Train net output #0: loss = 0.0005437 (* 1 = 0.0005437 loss)
I0811 05:29:45.024499 10215 sgd_solver.cpp:112] Iteration 33320, lr = 0.001
I0811 05:29:57.635215 10215 solver.cpp:239] Iteration 33390 (5.55098 iter/s, 12.6104s/70 iters), loss = 0.000371603
I0811 05:29:57.635385 10215 solver.cpp:258]     Train net output #0: loss = 0.000371931 (* 1 = 0.000371931 loss)
I0811 05:29:57.635393 10215 sgd_solver.cpp:112] Iteration 33390, lr = 0.001
I0811 05:30:10.259578 10215 solver.cpp:239] Iteration 33460 (5.54506 iter/s, 12.6238s/70 iters), loss = 1.93755e-05
I0811 05:30:10.259611 10215 solver.cpp:258]     Train net output #0: loss = 1.97018e-05 (* 1 = 1.97018e-05 loss)
I0811 05:30:10.259618 10215 sgd_solver.cpp:112] Iteration 33460, lr = 0.001
I0811 05:30:22.860198 10215 solver.cpp:239] Iteration 33530 (5.55545 iter/s, 12.6002s/70 iters), loss = 0.000504669
I0811 05:30:22.860225 10215 solver.cpp:258]     Train net output #0: loss = 0.000505003 (* 1 = 0.000505003 loss)
I0811 05:30:22.860231 10215 sgd_solver.cpp:112] Iteration 33530, lr = 0.001
I0811 05:30:35.486837 10215 solver.cpp:239] Iteration 33600 (5.544 iter/s, 12.6263s/70 iters), loss = 0.0131808
I0811 05:30:35.486922 10215 solver.cpp:258]     Train net output #0: loss = 0.0131811 (* 1 = 0.0131811 loss)
I0811 05:30:35.486941 10215 sgd_solver.cpp:112] Iteration 33600, lr = 0.001
I0811 05:30:46.912075 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:30:48.116255 10215 solver.cpp:239] Iteration 33670 (5.5428 iter/s, 12.629s/70 iters), loss = 0.000124361
I0811 05:30:48.116281 10215 solver.cpp:258]     Train net output #0: loss = 0.000124687 (* 1 = 0.000124687 loss)
I0811 05:30:48.116287 10215 sgd_solver.cpp:112] Iteration 33670, lr = 0.001
I0811 05:30:56.866892 10215 solver.cpp:464] Snapshotting to binary proto file snapshot_iter_33720.caffemodel
I0811 05:30:56.962162 10215 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshot_iter_33720.solverstate
I0811 05:30:56.966840 10215 solver.cpp:347] Iteration 33720, Testing net (#0)
I0811 05:30:56.966850 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:31:10.773829 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:31:13.941045 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 05:31:13.941069 10215 solver.cpp:414]     Test net output #1: loss = 0.00957227 (* 1 = 0.00957227 loss)
I0811 05:31:17.734431 10215 solver.cpp:239] Iteration 33740 (2.36348 iter/s, 29.6174s/70 iters), loss = 0.000526088
I0811 05:31:17.734458 10215 solver.cpp:258]     Train net output #0: loss = 0.000526418 (* 1 = 0.000526418 loss)
I0811 05:31:17.734465 10215 sgd_solver.cpp:112] Iteration 33740, lr = 0.001
I0811 05:31:30.360316 10215 solver.cpp:239] Iteration 33810 (5.54433 iter/s, 12.6255s/70 iters), loss = 6.90699e-05
I0811 05:31:30.360345 10215 solver.cpp:258]     Train net output #0: loss = 6.93994e-05 (* 1 = 6.93994e-05 loss)
I0811 05:31:30.360352 10215 sgd_solver.cpp:112] Iteration 33810, lr = 0.001
I0811 05:31:42.983487 10215 solver.cpp:239] Iteration 33880 (5.54552 iter/s, 12.6228s/70 iters), loss = 2.06293e-05
I0811 05:31:42.983531 10215 solver.cpp:258]     Train net output #0: loss = 2.09595e-05 (* 1 = 2.09595e-05 loss)
I0811 05:31:42.983537 10215 sgd_solver.cpp:112] Iteration 33880, lr = 0.001
I0811 05:31:55.606808 10215 solver.cpp:239] Iteration 33950 (5.54546 iter/s, 12.6229s/70 iters), loss = 5.40888e-05
I0811 05:31:55.606838 10215 solver.cpp:258]     Train net output #0: loss = 5.44193e-05 (* 1 = 5.44193e-05 loss)
I0811 05:31:55.606844 10215 sgd_solver.cpp:112] Iteration 33950, lr = 0.001
I0811 05:32:08.218070 10215 solver.cpp:239] Iteration 34020 (5.55076 iter/s, 12.6109s/70 iters), loss = 6.91667e-05
I0811 05:32:08.218097 10215 solver.cpp:258]     Train net output #0: loss = 6.95059e-05 (* 1 = 6.95059e-05 loss)
I0811 05:32:08.218103 10215 sgd_solver.cpp:112] Iteration 34020, lr = 0.001
I0811 05:32:20.844066 10215 solver.cpp:239] Iteration 34090 (5.54428 iter/s, 12.6256s/70 iters), loss = 0.000992861
I0811 05:32:20.844164 10215 solver.cpp:258]     Train net output #0: loss = 0.00099319 (* 1 = 0.00099319 loss)
I0811 05:32:20.844172 10215 sgd_solver.cpp:112] Iteration 34090, lr = 0.001
I0811 05:32:33.455799 10215 solver.cpp:239] Iteration 34160 (5.55057 iter/s, 12.6113s/70 iters), loss = 2.99683e-05
I0811 05:32:33.455827 10215 solver.cpp:258]     Train net output #0: loss = 3.02976e-05 (* 1 = 3.02976e-05 loss)
I0811 05:32:33.455833 10215 sgd_solver.cpp:112] Iteration 34160, lr = 0.001
I0811 05:32:45.054680 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:32:46.079862 10215 solver.cpp:239] Iteration 34230 (5.54513 iter/s, 12.6237s/70 iters), loss = 0.000270361
I0811 05:32:46.079888 10215 solver.cpp:258]     Train net output #0: loss = 0.000270695 (* 1 = 0.000270695 loss)
I0811 05:32:46.079895 10215 sgd_solver.cpp:112] Iteration 34230, lr = 0.001
I0811 05:32:55.199553 10215 solver.cpp:347] Iteration 34282, Testing net (#0)
I0811 05:32:55.199605 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:33:08.984997 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:33:12.208734 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 05:33:12.208758 10215 solver.cpp:414]     Test net output #1: loss = 0.00789599 (* 1 = 0.00789599 loss)
I0811 05:33:15.648550 10215 solver.cpp:239] Iteration 34300 (2.36744 iter/s, 29.5679s/70 iters), loss = 6.11874e-05
I0811 05:33:15.648578 10215 solver.cpp:258]     Train net output #0: loss = 6.15214e-05 (* 1 = 6.15214e-05 loss)
I0811 05:33:15.648584 10215 sgd_solver.cpp:112] Iteration 34300, lr = 0.001
I0811 05:33:28.257886 10215 solver.cpp:239] Iteration 34370 (5.55161 iter/s, 12.609s/70 iters), loss = 5.85298e-05
I0811 05:33:28.258031 10215 solver.cpp:258]     Train net output #0: loss = 5.88479e-05 (* 1 = 5.88479e-05 loss)
I0811 05:33:28.258039 10215 sgd_solver.cpp:112] Iteration 34370, lr = 0.001
I0811 05:33:40.858321 10215 solver.cpp:239] Iteration 34440 (5.55558 iter/s, 12.5999s/70 iters), loss = 0.000232777
I0811 05:33:40.858352 10215 solver.cpp:258]     Train net output #0: loss = 0.000233101 (* 1 = 0.000233101 loss)
I0811 05:33:40.858358 10215 sgd_solver.cpp:112] Iteration 34440, lr = 0.001
I0811 05:33:53.488564 10215 solver.cpp:239] Iteration 34510 (5.54242 iter/s, 12.6299s/70 iters), loss = 0.00581934
I0811 05:33:53.488595 10215 solver.cpp:258]     Train net output #0: loss = 0.00581966 (* 1 = 0.00581966 loss)
I0811 05:33:53.488600 10215 sgd_solver.cpp:112] Iteration 34510, lr = 0.001
I0811 05:34:06.096390 10215 solver.cpp:239] Iteration 34580 (5.55227 iter/s, 12.6075s/70 iters), loss = 0.000463305
I0811 05:34:06.096446 10215 solver.cpp:258]     Train net output #0: loss = 0.000463625 (* 1 = 0.000463625 loss)
I0811 05:34:06.096452 10215 sgd_solver.cpp:112] Iteration 34580, lr = 0.001
I0811 05:34:18.721823 10215 solver.cpp:239] Iteration 34650 (5.54454 iter/s, 12.625s/70 iters), loss = 0.000274552
I0811 05:34:18.721855 10215 solver.cpp:258]     Train net output #0: loss = 0.000274874 (* 1 = 0.000274874 loss)
I0811 05:34:18.721861 10215 sgd_solver.cpp:112] Iteration 34650, lr = 0.001
I0811 05:34:31.355680 10215 solver.cpp:239] Iteration 34720 (5.54083 iter/s, 12.6335s/70 iters), loss = 1.34968e-05
I0811 05:34:31.355707 10215 solver.cpp:258]     Train net output #0: loss = 1.3809e-05 (* 1 = 1.3809e-05 loss)
I0811 05:34:31.355713 10215 sgd_solver.cpp:112] Iteration 34720, lr = 0.001
I0811 05:34:43.144855 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:34:43.980350 10215 solver.cpp:239] Iteration 34790 (5.54486 iter/s, 12.6243s/70 iters), loss = 6.81126e-06
I0811 05:34:43.980381 10215 solver.cpp:258]     Train net output #0: loss = 7.10285e-06 (* 1 = 7.10285e-06 loss)
I0811 05:34:43.980388 10215 sgd_solver.cpp:112] Iteration 34790, lr = 0.001
I0811 05:34:53.458576 10215 solver.cpp:347] Iteration 34844, Testing net (#0)
I0811 05:34:53.458612 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:35:07.212031 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:35:10.454067 10215 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0811 05:35:10.454092 10215 solver.cpp:414]     Test net output #1: loss = 0.00714975 (* 1 = 0.00714975 loss)
I0811 05:35:13.528865 10215 solver.cpp:239] Iteration 34860 (2.36905 iter/s, 29.5477s/70 iters), loss = 0.00183055
I0811 05:35:13.528928 10215 solver.cpp:258]     Train net output #0: loss = 0.00183085 (* 1 = 0.00183085 loss)
I0811 05:35:13.528934 10215 sgd_solver.cpp:112] Iteration 34860, lr = 0.001
I0811 05:35:26.160794 10215 solver.cpp:239] Iteration 34930 (5.54169 iter/s, 12.6315s/70 iters), loss = 0.000685357
I0811 05:35:26.160820 10215 solver.cpp:258]     Train net output #0: loss = 0.000685665 (* 1 = 0.000685665 loss)
I0811 05:35:26.160825 10215 sgd_solver.cpp:112] Iteration 34930, lr = 0.001
I0811 05:35:38.784107 10215 solver.cpp:239] Iteration 35000 (5.54546 iter/s, 12.6229s/70 iters), loss = 4.99566e-05
I0811 05:35:38.784134 10215 solver.cpp:258]     Train net output #0: loss = 5.02677e-05 (* 1 = 5.02677e-05 loss)
I0811 05:35:38.784140 10215 sgd_solver.cpp:112] Iteration 35000, lr = 0.001
I0811 05:35:51.414613 10215 solver.cpp:239] Iteration 35070 (5.54231 iter/s, 12.6301s/70 iters), loss = 0.000185605
I0811 05:35:51.414752 10215 solver.cpp:258]     Train net output #0: loss = 0.000185914 (* 1 = 0.000185914 loss)
I0811 05:35:51.414757 10215 sgd_solver.cpp:112] Iteration 35070, lr = 0.001
I0811 05:36:04.035833 10215 solver.cpp:239] Iteration 35140 (5.54642 iter/s, 12.6208s/70 iters), loss = 0.00191764
I0811 05:36:04.035862 10215 solver.cpp:258]     Train net output #0: loss = 0.00191795 (* 1 = 0.00191795 loss)
I0811 05:36:04.035868 10215 sgd_solver.cpp:112] Iteration 35140, lr = 0.001
I0811 05:36:16.654583 10215 solver.cpp:239] Iteration 35210 (5.54747 iter/s, 12.6184s/70 iters), loss = 0.000313259
I0811 05:36:16.654623 10215 solver.cpp:258]     Train net output #0: loss = 0.000313564 (* 1 = 0.000313564 loss)
I0811 05:36:16.654629 10215 sgd_solver.cpp:112] Iteration 35210, lr = 0.001
I0811 05:36:29.263700 10215 solver.cpp:239] Iteration 35280 (5.55171 iter/s, 12.6087s/70 iters), loss = 0.000168417
I0811 05:36:29.263839 10215 solver.cpp:258]     Train net output #0: loss = 0.000168722 (* 1 = 0.000168722 loss)
I0811 05:36:29.263847 10215 sgd_solver.cpp:112] Iteration 35280, lr = 0.001
I0811 05:36:41.243511 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:36:41.880106 10215 solver.cpp:239] Iteration 35350 (5.54854 iter/s, 12.6159s/70 iters), loss = 0.0213042
I0811 05:36:41.880134 10215 solver.cpp:258]     Train net output #0: loss = 0.0213045 (* 1 = 0.0213045 loss)
I0811 05:36:41.880141 10215 sgd_solver.cpp:112] Iteration 35350, lr = 0.001
I0811 05:36:51.716742 10215 solver.cpp:347] Iteration 35406, Testing net (#0)
I0811 05:36:51.716756 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:37:02.216150 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:37:05.374359 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:37:08.684075 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 05:37:08.684099 10215 solver.cpp:414]     Test net output #1: loss = 0.00853766 (* 1 = 0.00853766 loss)
I0811 05:37:11.388553 10215 solver.cpp:239] Iteration 35420 (2.37227 iter/s, 29.5076s/70 iters), loss = 0.0010665
I0811 05:37:11.388581 10215 solver.cpp:258]     Train net output #0: loss = 0.00106682 (* 1 = 0.00106682 loss)
I0811 05:37:11.388587 10215 sgd_solver.cpp:112] Iteration 35420, lr = 0.001
I0811 05:37:23.999532 10215 solver.cpp:239] Iteration 35490 (5.55089 iter/s, 12.6106s/70 iters), loss = 8.94511e-05
I0811 05:37:23.999560 10215 solver.cpp:258]     Train net output #0: loss = 8.97669e-05 (* 1 = 8.97669e-05 loss)
I0811 05:37:23.999567 10215 sgd_solver.cpp:112] Iteration 35490, lr = 0.001
I0811 05:37:36.624402 10215 solver.cpp:239] Iteration 35560 (5.54477 iter/s, 12.6245s/70 iters), loss = 5.73031e-06
I0811 05:37:36.624455 10215 solver.cpp:258]     Train net output #0: loss = 6.04256e-06 (* 1 = 6.04256e-06 loss)
I0811 05:37:36.624462 10215 sgd_solver.cpp:112] Iteration 35560, lr = 0.001
I0811 05:37:49.257505 10215 solver.cpp:239] Iteration 35630 (5.54117 iter/s, 12.6327s/70 iters), loss = 0.000135131
I0811 05:37:49.257534 10215 solver.cpp:258]     Train net output #0: loss = 0.000135439 (* 1 = 0.000135439 loss)
I0811 05:37:49.257539 10215 sgd_solver.cpp:112] Iteration 35630, lr = 0.001
I0811 05:38:01.884716 10215 solver.cpp:239] Iteration 35700 (5.54375 iter/s, 12.6268s/70 iters), loss = 0.000391691
I0811 05:38:01.884742 10215 solver.cpp:258]     Train net output #0: loss = 0.000391994 (* 1 = 0.000391994 loss)
I0811 05:38:01.884748 10215 sgd_solver.cpp:112] Iteration 35700, lr = 0.001
I0811 05:38:14.510275 10215 solver.cpp:239] Iteration 35770 (5.54447 iter/s, 12.6252s/70 iters), loss = 0.000123834
I0811 05:38:14.510440 10215 solver.cpp:258]     Train net output #0: loss = 0.000124136 (* 1 = 0.000124136 loss)
I0811 05:38:14.510460 10215 sgd_solver.cpp:112] Iteration 35770, lr = 0.001
I0811 05:38:27.133359 10215 solver.cpp:239] Iteration 35840 (5.54562 iter/s, 12.6226s/70 iters), loss = 0.00138594
I0811 05:38:27.133386 10215 solver.cpp:258]     Train net output #0: loss = 0.00138624 (* 1 = 0.00138624 loss)
I0811 05:38:27.133393 10215 sgd_solver.cpp:112] Iteration 35840, lr = 0.001
I0811 05:38:39.307523 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:38:39.761929 10215 solver.cpp:239] Iteration 35910 (5.54315 iter/s, 12.6282s/70 iters), loss = 3.34698e-05
I0811 05:38:39.761958 10215 solver.cpp:258]     Train net output #0: loss = 3.37683e-05 (* 1 = 3.37683e-05 loss)
I0811 05:38:39.761963 10215 sgd_solver.cpp:112] Iteration 35910, lr = 0.001
I0811 05:38:49.953593 10215 solver.cpp:347] Iteration 35968, Testing net (#0)
I0811 05:38:49.953660 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:39:03.560413 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:39:06.913795 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 05:39:06.913820 10215 solver.cpp:414]     Test net output #1: loss = 0.00711136 (* 1 = 0.00711136 loss)
I0811 05:39:09.262706 10215 solver.cpp:239] Iteration 35980 (2.37289 iter/s, 29.5s/70 iters), loss = 0.00135303
I0811 05:39:09.262735 10215 solver.cpp:258]     Train net output #0: loss = 0.00135333 (* 1 = 0.00135333 loss)
I0811 05:39:09.262742 10215 sgd_solver.cpp:112] Iteration 35980, lr = 0.001
I0811 05:39:21.875694 10215 solver.cpp:239] Iteration 36050 (5.55 iter/s, 12.6126s/70 iters), loss = 5.18337e-05
I0811 05:39:21.875823 10215 solver.cpp:258]     Train net output #0: loss = 5.21317e-05 (* 1 = 5.21317e-05 loss)
I0811 05:39:21.875830 10215 sgd_solver.cpp:112] Iteration 36050, lr = 0.001
I0811 05:39:34.496847 10215 solver.cpp:239] Iteration 36120 (5.54645 iter/s, 12.6207s/70 iters), loss = 8.05896e-06
I0811 05:39:34.496877 10215 solver.cpp:258]     Train net output #0: loss = 8.35987e-06 (* 1 = 8.35987e-06 loss)
I0811 05:39:34.496883 10215 sgd_solver.cpp:112] Iteration 36120, lr = 0.001
I0811 05:39:47.112485 10215 solver.cpp:239] Iteration 36190 (5.54883 iter/s, 12.6153s/70 iters), loss = 0.00414287
I0811 05:39:47.112514 10215 solver.cpp:258]     Train net output #0: loss = 0.00414317 (* 1 = 0.00414317 loss)
I0811 05:39:47.112520 10215 sgd_solver.cpp:112] Iteration 36190, lr = 0.001
I0811 05:39:59.732280 10215 solver.cpp:239] Iteration 36260 (5.54701 iter/s, 12.6194s/70 iters), loss = 0.000162512
I0811 05:39:59.732339 10215 solver.cpp:258]     Train net output #0: loss = 0.000162815 (* 1 = 0.000162815 loss)
I0811 05:39:59.732357 10215 sgd_solver.cpp:112] Iteration 36260, lr = 0.001
I0811 05:40:12.352066 10215 solver.cpp:239] Iteration 36330 (5.54702 iter/s, 12.6194s/70 iters), loss = 0.00045641
I0811 05:40:12.352092 10215 solver.cpp:258]     Train net output #0: loss = 0.000456712 (* 1 = 0.000456712 loss)
I0811 05:40:12.352098 10215 sgd_solver.cpp:112] Iteration 36330, lr = 0.001
I0811 05:40:24.983451 10215 solver.cpp:239] Iteration 36400 (5.54191 iter/s, 12.631s/70 iters), loss = 8.79652e-05
I0811 05:40:24.983477 10215 solver.cpp:258]     Train net output #0: loss = 8.82682e-05 (* 1 = 8.82682e-05 loss)
I0811 05:40:24.983484 10215 sgd_solver.cpp:112] Iteration 36400, lr = 0.001
I0811 05:40:37.451270 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:40:37.606617 10215 solver.cpp:239] Iteration 36470 (5.54552 iter/s, 12.6228s/70 iters), loss = 1.08774e-05
I0811 05:40:37.606645 10215 solver.cpp:258]     Train net output #0: loss = 1.11822e-05 (* 1 = 1.11822e-05 loss)
I0811 05:40:37.606652 10215 sgd_solver.cpp:112] Iteration 36470, lr = 0.001
I0811 05:40:48.156466 10215 solver.cpp:347] Iteration 36530, Testing net (#0)
I0811 05:40:48.156479 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:41:01.697075 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:41:05.082942 10215 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0811 05:41:05.082965 10215 solver.cpp:414]     Test net output #1: loss = 0.00752564 (* 1 = 0.00752564 loss)
I0811 05:41:07.068878 10215 solver.cpp:239] Iteration 36540 (2.37599 iter/s, 29.4614s/70 iters), loss = 9.96115e-05
I0811 05:41:07.068904 10215 solver.cpp:258]     Train net output #0: loss = 9.99127e-05 (* 1 = 9.99127e-05 loss)
I0811 05:41:07.068910 10215 sgd_solver.cpp:112] Iteration 36540, lr = 0.001
I0811 05:41:19.679600 10215 solver.cpp:239] Iteration 36610 (5.551 iter/s, 12.6104s/70 iters), loss = 0.0111886
I0811 05:41:19.679730 10215 solver.cpp:258]     Train net output #0: loss = 0.0111889 (* 1 = 0.0111889 loss)
I0811 05:41:19.679738 10215 sgd_solver.cpp:112] Iteration 36610, lr = 0.001
I0811 05:41:32.313027 10215 solver.cpp:239] Iteration 36680 (5.54106 iter/s, 12.633s/70 iters), loss = 4.97323e-05
I0811 05:41:32.313053 10215 solver.cpp:258]     Train net output #0: loss = 5.00328e-05 (* 1 = 5.00328e-05 loss)
I0811 05:41:32.313058 10215 sgd_solver.cpp:112] Iteration 36680, lr = 0.001
I0811 05:41:44.914635 10215 solver.cpp:239] Iteration 36750 (5.55501 iter/s, 12.6012s/70 iters), loss = 0.0320442
I0811 05:41:44.914662 10215 solver.cpp:258]     Train net output #0: loss = 0.0320445 (* 1 = 0.0320445 loss)
I0811 05:41:44.914669 10215 sgd_solver.cpp:112] Iteration 36750, lr = 0.001
I0811 05:41:57.528273 10215 solver.cpp:239] Iteration 36820 (5.54971 iter/s, 12.6133s/70 iters), loss = 1.18629e-05
I0811 05:41:57.528405 10215 solver.cpp:258]     Train net output #0: loss = 1.21487e-05 (* 1 = 1.21487e-05 loss)
I0811 05:41:57.528414 10215 sgd_solver.cpp:112] Iteration 36820, lr = 0.001
I0811 05:42:10.139889 10215 solver.cpp:239] Iteration 36890 (5.55065 iter/s, 12.6111s/70 iters), loss = 2.86189e-05
I0811 05:42:10.139916 10215 solver.cpp:258]     Train net output #0: loss = 2.89236e-05 (* 1 = 2.89236e-05 loss)
I0811 05:42:10.139921 10215 sgd_solver.cpp:112] Iteration 36890, lr = 0.001
I0811 05:42:22.764003 10215 solver.cpp:239] Iteration 36960 (5.54511 iter/s, 12.6237s/70 iters), loss = 0.000101494
I0811 05:42:22.764030 10215 solver.cpp:258]     Train net output #0: loss = 0.000101796 (* 1 = 0.000101796 loss)
I0811 05:42:22.764035 10215 sgd_solver.cpp:112] Iteration 36960, lr = 0.001
I0811 05:42:35.384364 10215 solver.cpp:239] Iteration 37030 (5.54675 iter/s, 12.62s/70 iters), loss = 7.63257e-05
I0811 05:42:35.384428 10215 solver.cpp:258]     Train net output #0: loss = 7.66266e-05 (* 1 = 7.66266e-05 loss)
I0811 05:42:35.384433 10215 sgd_solver.cpp:112] Iteration 37030, lr = 0.001
I0811 05:42:35.421397 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:42:46.293488 10215 solver.cpp:347] Iteration 37092, Testing net (#0)
I0811 05:42:46.293504 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:42:59.812821 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:43:03.291434 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997833
I0811 05:43:03.291457 10215 solver.cpp:414]     Test net output #1: loss = 0.00778928 (* 1 = 0.00778928 loss)
I0811 05:43:04.919409 10215 solver.cpp:239] Iteration 37100 (2.37013 iter/s, 29.5342s/70 iters), loss = 0.00299516
I0811 05:43:04.919436 10215 solver.cpp:258]     Train net output #0: loss = 0.00299546 (* 1 = 0.00299546 loss)
I0811 05:43:04.919442 10215 sgd_solver.cpp:112] Iteration 37100, lr = 0.0001
I0811 05:43:17.544574 10215 solver.cpp:239] Iteration 37170 (5.54464 iter/s, 12.6248s/70 iters), loss = 4.13774e-05
I0811 05:43:17.544733 10215 solver.cpp:258]     Train net output #0: loss = 4.16837e-05 (* 1 = 4.16837e-05 loss)
I0811 05:43:17.544752 10215 sgd_solver.cpp:112] Iteration 37170, lr = 0.0001
I0811 05:43:30.155474 10215 solver.cpp:239] Iteration 37240 (5.55097 iter/s, 12.6104s/70 iters), loss = 2.63669e-05
I0811 05:43:30.155501 10215 solver.cpp:258]     Train net output #0: loss = 2.66653e-05 (* 1 = 2.66653e-05 loss)
I0811 05:43:30.155506 10215 sgd_solver.cpp:112] Iteration 37240, lr = 0.0001
I0811 05:43:42.778156 10215 solver.cpp:239] Iteration 37310 (5.54574 iter/s, 12.6223s/70 iters), loss = 2.25289e-05
I0811 05:43:42.778188 10215 solver.cpp:258]     Train net output #0: loss = 2.28285e-05 (* 1 = 2.28285e-05 loss)
I0811 05:43:42.778194 10215 sgd_solver.cpp:112] Iteration 37310, lr = 0.0001
I0811 05:43:55.398898 10215 solver.cpp:239] Iteration 37380 (5.54659 iter/s, 12.6204s/70 iters), loss = 0.000355761
I0811 05:43:55.398978 10215 solver.cpp:258]     Train net output #0: loss = 0.000356057 (* 1 = 0.000356057 loss)
I0811 05:43:55.398985 10215 sgd_solver.cpp:112] Iteration 37380, lr = 0.0001
I0811 05:44:08.012889 10215 solver.cpp:239] Iteration 37450 (5.54958 iter/s, 12.6136s/70 iters), loss = 1.35228e-06
I0811 05:44:08.012917 10215 solver.cpp:258]     Train net output #0: loss = 1.6466e-06 (* 1 = 1.6466e-06 loss)
I0811 05:44:08.012923 10215 sgd_solver.cpp:112] Iteration 37450, lr = 0.0001
I0811 05:44:20.638710 10215 solver.cpp:239] Iteration 37520 (5.54436 iter/s, 12.6254s/70 iters), loss = 0.000740432
I0811 05:44:20.638738 10215 solver.cpp:258]     Train net output #0: loss = 0.00074072 (* 1 = 0.00074072 loss)
I0811 05:44:20.638744 10215 sgd_solver.cpp:112] Iteration 37520, lr = 0.0001
I0811 05:44:33.255183 10215 solver.cpp:239] Iteration 37590 (5.54846 iter/s, 12.6161s/70 iters), loss = 0.000211278
I0811 05:44:33.255324 10215 solver.cpp:258]     Train net output #0: loss = 0.000211565 (* 1 = 0.000211565 loss)
I0811 05:44:33.255331 10215 sgd_solver.cpp:112] Iteration 37590, lr = 0.0001
I0811 05:44:33.479194 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:44:44.535467 10215 solver.cpp:347] Iteration 37654, Testing net (#0)
I0811 05:44:44.535483 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:44:58.034212 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:44:59.198017 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:45:01.540575 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997833
I0811 05:45:01.540596 10215 solver.cpp:414]     Test net output #1: loss = 0.0071456 (* 1 = 0.0071456 loss)
I0811 05:45:02.807790 10215 solver.cpp:239] Iteration 37660 (2.36873 iter/s, 29.5517s/70 iters), loss = 0.00600572
I0811 05:45:02.807816 10215 solver.cpp:258]     Train net output #0: loss = 0.00600601 (* 1 = 0.00600601 loss)
I0811 05:45:02.807821 10215 sgd_solver.cpp:112] Iteration 37660, lr = 0.0001
I0811 05:45:15.419353 10215 solver.cpp:239] Iteration 37730 (5.55063 iter/s, 12.6112s/70 iters), loss = 0.0013967
I0811 05:45:15.419482 10215 solver.cpp:258]     Train net output #0: loss = 0.00139699 (* 1 = 0.00139699 loss)
I0811 05:45:15.419502 10215 sgd_solver.cpp:112] Iteration 37730, lr = 0.0001
I0811 05:45:28.030483 10215 solver.cpp:239] Iteration 37800 (5.55086 iter/s, 12.6107s/70 iters), loss = 1.30947e-06
I0811 05:45:28.030510 10215 solver.cpp:258]     Train net output #0: loss = 1.6019e-06 (* 1 = 1.6019e-06 loss)
I0811 05:45:28.030515 10215 sgd_solver.cpp:112] Iteration 37800, lr = 0.0001
I0811 05:45:40.665974 10215 solver.cpp:239] Iteration 37870 (5.54011 iter/s, 12.6351s/70 iters), loss = 0.00102137
I0811 05:45:40.666004 10215 solver.cpp:258]     Train net output #0: loss = 0.00102166 (* 1 = 0.00102166 loss)
I0811 05:45:40.666010 10215 sgd_solver.cpp:112] Iteration 37870, lr = 0.0001
I0811 05:45:53.285593 10215 solver.cpp:239] Iteration 37940 (5.54708 iter/s, 12.6192s/70 iters), loss = 0.0343879
I0811 05:45:53.285734 10215 solver.cpp:258]     Train net output #0: loss = 0.0343882 (* 1 = 0.0343882 loss)
I0811 05:45:53.285742 10215 sgd_solver.cpp:112] Iteration 37940, lr = 0.0001
I0811 05:46:05.913542 10215 solver.cpp:239] Iteration 38010 (5.54347 iter/s, 12.6275s/70 iters), loss = 0.00787169
I0811 05:46:05.913570 10215 solver.cpp:258]     Train net output #0: loss = 0.00787198 (* 1 = 0.00787198 loss)
I0811 05:46:05.913575 10215 sgd_solver.cpp:112] Iteration 38010, lr = 0.0001
I0811 05:46:18.536522 10215 solver.cpp:239] Iteration 38080 (5.5456 iter/s, 12.6226s/70 iters), loss = 0.00152644
I0811 05:46:18.536551 10215 solver.cpp:258]     Train net output #0: loss = 0.00152673 (* 1 = 0.00152673 loss)
I0811 05:46:18.536557 10215 sgd_solver.cpp:112] Iteration 38080, lr = 0.0001
I0811 05:46:31.163851 10215 solver.cpp:239] Iteration 38150 (5.5437 iter/s, 12.627s/70 iters), loss = 1.4374e-05
I0811 05:46:31.164022 10215 solver.cpp:258]     Train net output #0: loss = 1.468e-05 (* 1 = 1.468e-05 loss)
I0811 05:46:31.164031 10215 sgd_solver.cpp:112] Iteration 38150, lr = 0.0001
I0811 05:46:31.576823 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:46:42.787559 10215 solver.cpp:347] Iteration 38216, Testing net (#0)
I0811 05:46:42.787572 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:46:56.110764 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:46:59.652062 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 05:46:59.652086 10215 solver.cpp:414]     Test net output #1: loss = 0.00699638 (* 1 = 0.00699638 loss)
I0811 05:47:00.556344 10215 solver.cpp:239] Iteration 38220 (2.38164 iter/s, 29.3915s/70 iters), loss = 0.00310886
I0811 05:47:00.556373 10215 solver.cpp:258]     Train net output #0: loss = 0.00310917 (* 1 = 0.00310917 loss)
I0811 05:47:00.556380 10215 sgd_solver.cpp:112] Iteration 38220, lr = 0.0001
I0811 05:47:13.176265 10215 solver.cpp:239] Iteration 38290 (5.54695 iter/s, 12.6195s/70 iters), loss = 0.00348337
I0811 05:47:13.176316 10215 solver.cpp:258]     Train net output #0: loss = 0.00348367 (* 1 = 0.00348367 loss)
I0811 05:47:13.176321 10215 sgd_solver.cpp:112] Iteration 38290, lr = 0.0001
I0811 05:47:25.799106 10215 solver.cpp:239] Iteration 38360 (5.54568 iter/s, 12.6224s/70 iters), loss = 2.51454e-05
I0811 05:47:25.799132 10215 solver.cpp:258]     Train net output #0: loss = 2.54463e-05 (* 1 = 2.54463e-05 loss)
I0811 05:47:25.799139 10215 sgd_solver.cpp:112] Iteration 38360, lr = 0.0001
I0811 05:47:38.425021 10215 solver.cpp:239] Iteration 38430 (5.54432 iter/s, 12.6255s/70 iters), loss = 4.10824e-05
I0811 05:47:38.425050 10215 solver.cpp:258]     Train net output #0: loss = 4.13847e-05 (* 1 = 4.13847e-05 loss)
I0811 05:47:38.425055 10215 sgd_solver.cpp:112] Iteration 38430, lr = 0.0001
I0811 05:47:51.045096 10215 solver.cpp:239] Iteration 38500 (5.54688 iter/s, 12.6197s/70 iters), loss = 1.131e-05
I0811 05:47:51.045238 10215 solver.cpp:258]     Train net output #0: loss = 1.16134e-05 (* 1 = 1.16134e-05 loss)
I0811 05:47:51.045246 10215 sgd_solver.cpp:112] Iteration 38500, lr = 0.0001
I0811 05:48:03.670676 10215 solver.cpp:239] Iteration 38570 (5.54451 iter/s, 12.6251s/70 iters), loss = 5.43259e-05
I0811 05:48:03.670706 10215 solver.cpp:258]     Train net output #0: loss = 5.46233e-05 (* 1 = 5.46233e-05 loss)
I0811 05:48:03.670711 10215 sgd_solver.cpp:112] Iteration 38570, lr = 0.0001
I0811 05:48:16.295964 10215 solver.cpp:239] Iteration 38640 (5.54459 iter/s, 12.6249s/70 iters), loss = 0.000122359
I0811 05:48:16.295995 10215 solver.cpp:258]     Train net output #0: loss = 0.000122653 (* 1 = 0.000122653 loss)
I0811 05:48:16.296002 10215 sgd_solver.cpp:112] Iteration 38640, lr = 0.0001
I0811 05:48:28.917369 10215 solver.cpp:239] Iteration 38710 (5.5463 iter/s, 12.621s/70 iters), loss = 0.000118525
I0811 05:48:28.917507 10215 solver.cpp:258]     Train net output #0: loss = 0.000118822 (* 1 = 0.000118822 loss)
I0811 05:48:28.917515 10215 sgd_solver.cpp:112] Iteration 38710, lr = 0.0001
I0811 05:48:29.515667 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:48:40.904942 10215 solver.cpp:347] Iteration 38778, Testing net (#0)
I0811 05:48:40.904956 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:48:54.289209 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:48:57.907301 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 05:48:57.907326 10215 solver.cpp:414]     Test net output #1: loss = 0.00730424 (* 1 = 0.00730424 loss)
I0811 05:48:58.450707 10215 solver.cpp:239] Iteration 38780 (2.37028 iter/s, 29.5324s/70 iters), loss = 0.000389089
I0811 05:48:58.450736 10215 solver.cpp:258]     Train net output #0: loss = 0.000389386 (* 1 = 0.000389386 loss)
I0811 05:48:58.450742 10215 sgd_solver.cpp:112] Iteration 38780, lr = 0.0001
I0811 05:49:11.078405 10215 solver.cpp:239] Iteration 38850 (5.54353 iter/s, 12.6273s/70 iters), loss = 0.000246365
I0811 05:49:11.078568 10215 solver.cpp:258]     Train net output #0: loss = 0.000246663 (* 1 = 0.000246663 loss)
I0811 05:49:11.078575 10215 sgd_solver.cpp:112] Iteration 38850, lr = 0.0001
I0811 05:49:23.698606 10215 solver.cpp:239] Iteration 38920 (5.54688 iter/s, 12.6197s/70 iters), loss = 2.35923e-05
I0811 05:49:23.698632 10215 solver.cpp:258]     Train net output #0: loss = 2.38905e-05 (* 1 = 2.38905e-05 loss)
I0811 05:49:23.698652 10215 sgd_solver.cpp:112] Iteration 38920, lr = 0.0001
I0811 05:49:36.312676 10215 solver.cpp:239] Iteration 38990 (5.54952 iter/s, 12.6137s/70 iters), loss = 0.00169254
I0811 05:49:36.312705 10215 solver.cpp:258]     Train net output #0: loss = 0.00169284 (* 1 = 0.00169284 loss)
I0811 05:49:36.312711 10215 sgd_solver.cpp:112] Iteration 38990, lr = 0.0001
I0811 05:49:48.935876 10215 solver.cpp:239] Iteration 39060 (5.54551 iter/s, 12.6228s/70 iters), loss = 0.00128062
I0811 05:49:48.935931 10215 solver.cpp:258]     Train net output #0: loss = 0.00128092 (* 1 = 0.00128092 loss)
I0811 05:49:48.935938 10215 sgd_solver.cpp:112] Iteration 39060, lr = 0.0001
I0811 05:50:01.535406 10215 solver.cpp:239] Iteration 39130 (5.55594 iter/s, 12.5991s/70 iters), loss = 0.00365527
I0811 05:50:01.535439 10215 solver.cpp:258]     Train net output #0: loss = 0.00365558 (* 1 = 0.00365558 loss)
I0811 05:50:01.535444 10215 sgd_solver.cpp:112] Iteration 39130, lr = 0.0001
I0811 05:50:14.158560 10215 solver.cpp:239] Iteration 39200 (5.54553 iter/s, 12.6228s/70 iters), loss = 1.26353e-05
I0811 05:50:14.158596 10215 solver.cpp:258]     Train net output #0: loss = 1.29411e-05 (* 1 = 1.29411e-05 loss)
I0811 05:50:14.158601 10215 sgd_solver.cpp:112] Iteration 39200, lr = 0.0001
I0811 05:50:26.771338 10215 solver.cpp:239] Iteration 39270 (5.55009 iter/s, 12.6124s/70 iters), loss = 0.00178177
I0811 05:50:26.771478 10215 solver.cpp:258]     Train net output #0: loss = 0.00178208 (* 1 = 0.00178208 loss)
I0811 05:50:26.771486 10215 sgd_solver.cpp:112] Iteration 39270, lr = 0.0001
I0811 05:50:27.564828 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:50:39.130398 10215 solver.cpp:347] Iteration 39340, Testing net (#0)
I0811 05:50:39.130412 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:50:52.491376 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:50:56.160892 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 05:50:56.160915 10215 solver.cpp:414]     Test net output #1: loss = 0.0074241 (* 1 = 0.0074241 loss)
I0811 05:50:56.344954 10215 solver.cpp:239] Iteration 39340 (2.36705 iter/s, 29.5727s/70 iters), loss = 1.37035e-05
I0811 05:50:56.346130 10215 solver.cpp:258]     Train net output #0: loss = 1.401e-05 (* 1 = 1.401e-05 loss)
I0811 05:50:56.346137 10215 sgd_solver.cpp:112] Iteration 39340, lr = 0.0001
I0811 05:51:08.973685 10215 solver.cpp:239] Iteration 39410 (5.54358 iter/s, 12.6272s/70 iters), loss = 0.000669272
I0811 05:51:08.973803 10215 solver.cpp:258]     Train net output #0: loss = 0.000669578 (* 1 = 0.000669578 loss)
I0811 05:51:08.973811 10215 sgd_solver.cpp:112] Iteration 39410, lr = 0.0001
I0811 05:51:21.595746 10215 solver.cpp:239] Iteration 39480 (5.54605 iter/s, 12.6216s/70 iters), loss = 0.0024199
I0811 05:51:21.595772 10215 solver.cpp:258]     Train net output #0: loss = 0.00242022 (* 1 = 0.00242022 loss)
I0811 05:51:21.595777 10215 sgd_solver.cpp:112] Iteration 39480, lr = 0.0001
I0811 05:51:34.223448 10215 solver.cpp:239] Iteration 39550 (5.54353 iter/s, 12.6273s/70 iters), loss = 0.000100697
I0811 05:51:34.223474 10215 solver.cpp:258]     Train net output #0: loss = 0.000101011 (* 1 = 0.000101011 loss)
I0811 05:51:34.223479 10215 sgd_solver.cpp:112] Iteration 39550, lr = 0.0001
I0811 05:51:46.834587 10215 solver.cpp:239] Iteration 39620 (5.55081 iter/s, 12.6108s/70 iters), loss = 0.00658639
I0811 05:51:46.834760 10215 solver.cpp:258]     Train net output #0: loss = 0.00658671 (* 1 = 0.00658671 loss)
I0811 05:51:46.834769 10215 sgd_solver.cpp:112] Iteration 39620, lr = 0.0001
I0811 05:51:59.457633 10215 solver.cpp:239] Iteration 39690 (5.54564 iter/s, 12.6225s/70 iters), loss = 1.229e-06
I0811 05:51:59.457659 10215 solver.cpp:258]     Train net output #0: loss = 1.54229e-06 (* 1 = 1.54229e-06 loss)
I0811 05:51:59.457666 10215 sgd_solver.cpp:112] Iteration 39690, lr = 0.0001
I0811 05:52:12.057996 10215 solver.cpp:239] Iteration 39760 (5.55556 iter/s, 12.6s/70 iters), loss = 0.000115228
I0811 05:52:12.058024 10215 solver.cpp:258]     Train net output #0: loss = 0.000115541 (* 1 = 0.000115541 loss)
I0811 05:52:12.058029 10215 sgd_solver.cpp:112] Iteration 39760, lr = 0.0001
I0811 05:52:24.690714 10215 solver.cpp:239] Iteration 39830 (5.54133 iter/s, 12.6323s/70 iters), loss = 0.00608003
I0811 05:52:24.690769 10215 solver.cpp:258]     Train net output #0: loss = 0.00608035 (* 1 = 0.00608035 loss)
I0811 05:52:24.690776 10215 sgd_solver.cpp:112] Iteration 39830, lr = 0.0001
I0811 05:52:25.670617 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:52:37.294281 10215 solver.cpp:239] Iteration 39900 (5.55416 iter/s, 12.6032s/70 iters), loss = 0.000911459
I0811 05:52:37.294308 10215 solver.cpp:258]     Train net output #0: loss = 0.000911775 (* 1 = 0.000911775 loss)
I0811 05:52:37.294314 10215 sgd_solver.cpp:112] Iteration 39900, lr = 0.0001
I0811 05:52:37.392891 10215 solver.cpp:347] Iteration 39902, Testing net (#0)
I0811 05:52:37.392904 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:52:50.660224 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:52:54.367583 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 05:52:54.367607 10215 solver.cpp:414]     Test net output #1: loss = 0.00733666 (* 1 = 0.00733666 loss)
I0811 05:53:06.815235 10215 solver.cpp:239] Iteration 39970 (2.37126 iter/s, 29.5201s/70 iters), loss = 0.000789537
I0811 05:53:06.815376 10215 solver.cpp:258]     Train net output #0: loss = 0.000789846 (* 1 = 0.000789846 loss)
I0811 05:53:06.815383 10215 sgd_solver.cpp:112] Iteration 39970, lr = 0.0001
I0811 05:53:19.439447 10215 solver.cpp:239] Iteration 40040 (5.54511 iter/s, 12.6237s/70 iters), loss = 0.000916844
I0811 05:53:19.439474 10215 solver.cpp:258]     Train net output #0: loss = 0.000917151 (* 1 = 0.000917151 loss)
I0811 05:53:19.439481 10215 sgd_solver.cpp:112] Iteration 40040, lr = 0.0001
I0811 05:53:32.040794 10215 solver.cpp:239] Iteration 40110 (5.55512 iter/s, 12.601s/70 iters), loss = 9.77842e-06
I0811 05:53:32.040822 10215 solver.cpp:258]     Train net output #0: loss = 1.00847e-05 (* 1 = 1.00847e-05 loss)
I0811 05:53:32.040828 10215 sgd_solver.cpp:112] Iteration 40110, lr = 0.0001
I0811 05:53:44.663592 10215 solver.cpp:239] Iteration 40180 (5.54568 iter/s, 12.6224s/70 iters), loss = 0.000258573
I0811 05:53:44.663738 10215 solver.cpp:258]     Train net output #0: loss = 0.00025888 (* 1 = 0.00025888 loss)
I0811 05:53:44.663744 10215 sgd_solver.cpp:112] Iteration 40180, lr = 0.0001
I0811 05:53:57.274009 10215 solver.cpp:239] Iteration 40250 (5.55118 iter/s, 12.6099s/70 iters), loss = 2.2999e-06
I0811 05:53:57.274039 10215 solver.cpp:258]     Train net output #0: loss = 2.61517e-06 (* 1 = 2.61517e-06 loss)
I0811 05:53:57.274044 10215 sgd_solver.cpp:112] Iteration 40250, lr = 0.0001
I0811 05:54:09.897469 10215 solver.cpp:239] Iteration 40320 (5.5454 iter/s, 12.6231s/70 iters), loss = 0.000123381
I0811 05:54:09.897495 10215 solver.cpp:258]     Train net output #0: loss = 0.00012368 (* 1 = 0.00012368 loss)
I0811 05:54:09.897501 10215 sgd_solver.cpp:112] Iteration 40320, lr = 0.0001
I0811 05:54:22.499675 10215 solver.cpp:239] Iteration 40390 (5.55475 iter/s, 12.6018s/70 iters), loss = 0.00238236
I0811 05:54:22.499826 10215 solver.cpp:258]     Train net output #0: loss = 0.00238266 (* 1 = 0.00238266 loss)
I0811 05:54:22.499835 10215 sgd_solver.cpp:112] Iteration 40390, lr = 0.0001
I0811 05:54:23.670878 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:54:35.124264 10215 solver.cpp:239] Iteration 40460 (5.54495 iter/s, 12.6241s/70 iters), loss = 0.00841438
I0811 05:54:35.124291 10215 solver.cpp:258]     Train net output #0: loss = 0.00841468 (* 1 = 0.00841468 loss)
I0811 05:54:35.124297 10215 sgd_solver.cpp:112] Iteration 40460, lr = 0.0001
I0811 05:54:35.579972 10215 solver.cpp:347] Iteration 40464, Testing net (#0)
I0811 05:54:35.579988 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:54:37.523541 10215 blocking_queue.cpp:49] Waiting for data
I0811 05:54:48.747359 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:54:52.520856 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 05:54:52.520983 10215 solver.cpp:414]     Test net output #1: loss = 0.00722477 (* 1 = 0.00722477 loss)
I0811 05:55:04.593261 10215 solver.cpp:239] Iteration 40530 (2.37544 iter/s, 29.4682s/70 iters), loss = 1.1038e-05
I0811 05:55:04.593287 10215 solver.cpp:258]     Train net output #0: loss = 1.13328e-05 (* 1 = 1.13328e-05 loss)
I0811 05:55:04.593293 10215 sgd_solver.cpp:112] Iteration 40530, lr = 0.0001
I0811 05:55:17.199717 10215 solver.cpp:239] Iteration 40600 (5.55287 iter/s, 12.6061s/70 iters), loss = 0.00073684
I0811 05:55:17.199743 10215 solver.cpp:258]     Train net output #0: loss = 0.000737133 (* 1 = 0.000737133 loss)
I0811 05:55:17.199748 10215 sgd_solver.cpp:112] Iteration 40600, lr = 0.0001
I0811 05:55:29.819777 10215 solver.cpp:239] Iteration 40670 (5.54689 iter/s, 12.6197s/70 iters), loss = 0.000597615
I0811 05:55:29.819916 10215 solver.cpp:258]     Train net output #0: loss = 0.000597906 (* 1 = 0.000597906 loss)
I0811 05:55:29.819923 10215 sgd_solver.cpp:112] Iteration 40670, lr = 0.0001
I0811 05:55:42.430855 10215 solver.cpp:239] Iteration 40740 (5.55089 iter/s, 12.6106s/70 iters), loss = 0.00125735
I0811 05:55:42.430883 10215 solver.cpp:258]     Train net output #0: loss = 0.00125764 (* 1 = 0.00125764 loss)
I0811 05:55:42.430889 10215 sgd_solver.cpp:112] Iteration 40740, lr = 0.0001
I0811 05:55:55.052980 10215 solver.cpp:239] Iteration 40810 (5.54598 iter/s, 12.6217s/70 iters), loss = 0.00108069
I0811 05:55:55.053010 10215 solver.cpp:258]     Train net output #0: loss = 0.00108098 (* 1 = 0.00108098 loss)
I0811 05:55:55.053016 10215 sgd_solver.cpp:112] Iteration 40810, lr = 0.0001
I0811 05:56:07.677932 10215 solver.cpp:239] Iteration 40880 (5.54474 iter/s, 12.6246s/70 iters), loss = 0.000304926
I0811 05:56:07.678076 10215 solver.cpp:258]     Train net output #0: loss = 0.000305235 (* 1 = 0.000305235 loss)
I0811 05:56:07.678083 10215 sgd_solver.cpp:112] Iteration 40880, lr = 0.0001
I0811 05:56:20.290541 10215 solver.cpp:239] Iteration 40950 (5.55022 iter/s, 12.6121s/70 iters), loss = 0.000187254
I0811 05:56:20.290575 10215 solver.cpp:258]     Train net output #0: loss = 0.000187567 (* 1 = 0.000187567 loss)
I0811 05:56:20.290581 10215 sgd_solver.cpp:112] Iteration 40950, lr = 0.0001
I0811 05:56:21.751508 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:56:32.912838 10215 solver.cpp:239] Iteration 41020 (5.54591 iter/s, 12.6219s/70 iters), loss = 0.0017137
I0811 05:56:32.912866 10215 solver.cpp:258]     Train net output #0: loss = 0.00171401 (* 1 = 0.00171401 loss)
I0811 05:56:32.912871 10215 sgd_solver.cpp:112] Iteration 41020, lr = 0.0001
I0811 05:56:33.730079 10215 solver.cpp:347] Iteration 41026, Testing net (#0)
I0811 05:56:33.730095 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:56:46.890096 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:56:50.701706 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 05:56:50.701730 10215 solver.cpp:414]     Test net output #1: loss = 0.00709737 (* 1 = 0.00709737 loss)
I0811 05:57:02.433274 10215 solver.cpp:239] Iteration 41090 (2.3713 iter/s, 29.5196s/70 iters), loss = 5.1266e-05
I0811 05:57:02.433301 10215 solver.cpp:258]     Train net output #0: loss = 5.15762e-05 (* 1 = 5.15762e-05 loss)
I0811 05:57:02.433307 10215 sgd_solver.cpp:112] Iteration 41090, lr = 0.0001
I0811 05:57:15.051684 10215 solver.cpp:239] Iteration 41160 (5.54761 iter/s, 12.618s/70 iters), loss = 0.00157435
I0811 05:57:15.051712 10215 solver.cpp:258]     Train net output #0: loss = 0.00157467 (* 1 = 0.00157467 loss)
I0811 05:57:15.051717 10215 sgd_solver.cpp:112] Iteration 41160, lr = 0.0001
I0811 05:57:27.659569 10215 solver.cpp:239] Iteration 41230 (5.55225 iter/s, 12.6075s/70 iters), loss = 1.10352e-05
I0811 05:57:27.659704 10215 solver.cpp:258]     Train net output #0: loss = 1.13504e-05 (* 1 = 1.13504e-05 loss)
I0811 05:57:27.659713 10215 sgd_solver.cpp:112] Iteration 41230, lr = 0.0001
I0811 05:57:40.267841 10215 solver.cpp:239] Iteration 41300 (5.55212 iter/s, 12.6078s/70 iters), loss = 8.8103e-05
I0811 05:57:40.267868 10215 solver.cpp:258]     Train net output #0: loss = 8.84182e-05 (* 1 = 8.84182e-05 loss)
I0811 05:57:40.267874 10215 sgd_solver.cpp:112] Iteration 41300, lr = 0.0001
I0811 05:57:52.893437 10215 solver.cpp:239] Iteration 41370 (5.54446 iter/s, 12.6252s/70 iters), loss = 7.62843e-05
I0811 05:57:52.893465 10215 solver.cpp:258]     Train net output #0: loss = 7.65914e-05 (* 1 = 7.65914e-05 loss)
I0811 05:57:52.893471 10215 sgd_solver.cpp:112] Iteration 41370, lr = 0.0001
I0811 05:58:05.509016 10215 solver.cpp:239] Iteration 41440 (5.54886 iter/s, 12.6152s/70 iters), loss = 4.34796e-05
I0811 05:58:05.509145 10215 solver.cpp:258]     Train net output #0: loss = 4.37964e-05 (* 1 = 4.37964e-05 loss)
I0811 05:58:05.509151 10215 sgd_solver.cpp:112] Iteration 41440, lr = 0.0001
I0811 05:58:18.136061 10215 solver.cpp:239] Iteration 41510 (5.54386 iter/s, 12.6266s/70 iters), loss = 0.000839376
I0811 05:58:18.136090 10215 solver.cpp:258]     Train net output #0: loss = 0.000839693 (* 1 = 0.000839693 loss)
I0811 05:58:18.136096 10215 sgd_solver.cpp:112] Iteration 41510, lr = 0.0001
I0811 05:58:19.791831 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:58:30.754231 10215 solver.cpp:239] Iteration 41580 (5.54772 iter/s, 12.6178s/70 iters), loss = 2.52132e-05
I0811 05:58:30.754259 10215 solver.cpp:258]     Train net output #0: loss = 2.55255e-05 (* 1 = 2.55255e-05 loss)
I0811 05:58:30.754266 10215 sgd_solver.cpp:112] Iteration 41580, lr = 0.0001
I0811 05:58:31.930115 10215 solver.cpp:347] Iteration 41588, Testing net (#0)
I0811 05:58:31.930130 10215 net.cpp:676] Ignoring source layer train-data
I0811 05:58:45.055400 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 05:58:48.925457 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 05:58:48.925480 10215 solver.cpp:414]     Test net output #1: loss = 0.00708434 (* 1 = 0.00708434 loss)
I0811 05:59:00.275816 10215 solver.cpp:239] Iteration 41650 (2.37121 iter/s, 29.5208s/70 iters), loss = 0.0119818
I0811 05:59:00.275851 10215 solver.cpp:258]     Train net output #0: loss = 0.0119821 (* 1 = 0.0119821 loss)
I0811 05:59:00.275857 10215 sgd_solver.cpp:112] Iteration 41650, lr = 0.0001
I0811 05:59:12.898514 10215 solver.cpp:239] Iteration 41720 (5.54573 iter/s, 12.6223s/70 iters), loss = 0.000173483
I0811 05:59:12.898540 10215 solver.cpp:258]     Train net output #0: loss = 0.000173798 (* 1 = 0.000173798 loss)
I0811 05:59:12.898545 10215 sgd_solver.cpp:112] Iteration 41720, lr = 0.0001
I0811 05:59:25.530310 10215 solver.cpp:239] Iteration 41790 (5.54173 iter/s, 12.6314s/70 iters), loss = 0.000107237
I0811 05:59:25.530450 10215 solver.cpp:258]     Train net output #0: loss = 0.000107552 (* 1 = 0.000107552 loss)
I0811 05:59:25.530458 10215 sgd_solver.cpp:112] Iteration 41790, lr = 0.0001
I0811 05:59:38.145071 10215 solver.cpp:239] Iteration 41860 (5.54927 iter/s, 12.6143s/70 iters), loss = 3.60714e-05
I0811 05:59:38.145102 10215 solver.cpp:258]     Train net output #0: loss = 3.63875e-05 (* 1 = 3.63875e-05 loss)
I0811 05:59:38.145107 10215 sgd_solver.cpp:112] Iteration 41860, lr = 0.0001
I0811 05:59:50.758548 10215 solver.cpp:239] Iteration 41930 (5.54978 iter/s, 12.6131s/70 iters), loss = 5.3551e-06
I0811 05:59:50.758586 10215 solver.cpp:258]     Train net output #0: loss = 5.67006e-06 (* 1 = 5.67006e-06 loss)
I0811 05:59:50.758594 10215 sgd_solver.cpp:112] Iteration 41930, lr = 0.0001
I0811 06:00:03.381306 10215 solver.cpp:239] Iteration 42000 (5.54571 iter/s, 12.6224s/70 iters), loss = 3.10452e-05
I0811 06:00:03.381425 10215 solver.cpp:258]     Train net output #0: loss = 3.13586e-05 (* 1 = 3.13586e-05 loss)
I0811 06:00:03.381433 10215 sgd_solver.cpp:112] Iteration 42000, lr = 0.0001
I0811 06:00:15.985219 10215 solver.cpp:239] Iteration 42070 (5.55403 iter/s, 12.6035s/70 iters), loss = 0.00350985
I0811 06:00:15.985249 10215 solver.cpp:258]     Train net output #0: loss = 0.00351017 (* 1 = 0.00351017 loss)
I0811 06:00:15.985255 10215 sgd_solver.cpp:112] Iteration 42070, lr = 0.0001
I0811 06:00:17.831238 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:00:28.597061 10215 solver.cpp:239] Iteration 42140 (5.5505 iter/s, 12.6115s/70 iters), loss = 0.0494352
I0811 06:00:28.597088 10215 solver.cpp:258]     Train net output #0: loss = 0.0494355 (* 1 = 0.0494355 loss)
I0811 06:00:28.597095 10215 sgd_solver.cpp:112] Iteration 42140, lr = 0.0001
I0811 06:00:30.136596 10215 solver.cpp:347] Iteration 42150, Testing net (#0)
I0811 06:00:30.136612 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:00:43.124485 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:00:47.052600 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:00:47.052624 10215 solver.cpp:414]     Test net output #1: loss = 0.0071987 (* 1 = 0.0071987 loss)
I0811 06:00:58.056018 10215 solver.cpp:239] Iteration 42210 (2.37625 iter/s, 29.4581s/70 iters), loss = 0.000168471
I0811 06:00:58.056046 10215 solver.cpp:258]     Train net output #0: loss = 0.000168784 (* 1 = 0.000168784 loss)
I0811 06:00:58.056051 10215 sgd_solver.cpp:112] Iteration 42210, lr = 0.0001
I0811 06:01:10.671730 10215 solver.cpp:239] Iteration 42280 (5.5488 iter/s, 12.6153s/70 iters), loss = 0.000145448
I0811 06:01:10.671756 10215 solver.cpp:258]     Train net output #0: loss = 0.000145761 (* 1 = 0.000145761 loss)
I0811 06:01:10.671761 10215 sgd_solver.cpp:112] Iteration 42280, lr = 0.0001
I0811 06:01:23.278805 10215 solver.cpp:239] Iteration 42350 (5.5526 iter/s, 12.6067s/70 iters), loss = 0.0002928
I0811 06:01:23.278890 10215 solver.cpp:258]     Train net output #0: loss = 0.000293114 (* 1 = 0.000293114 loss)
I0811 06:01:23.278909 10215 sgd_solver.cpp:112] Iteration 42350, lr = 0.0001
I0811 06:01:35.892359 10215 solver.cpp:239] Iteration 42420 (5.54978 iter/s, 12.6131s/70 iters), loss = 4.55793e-05
I0811 06:01:35.892390 10215 solver.cpp:258]     Train net output #0: loss = 4.58922e-05 (* 1 = 4.58922e-05 loss)
I0811 06:01:35.892395 10215 sgd_solver.cpp:112] Iteration 42420, lr = 0.0001
I0811 06:01:48.502853 10215 solver.cpp:239] Iteration 42490 (5.5511 iter/s, 12.6101s/70 iters), loss = 0.0557944
I0811 06:01:48.502880 10215 solver.cpp:258]     Train net output #0: loss = 0.0557947 (* 1 = 0.0557947 loss)
I0811 06:01:48.502887 10215 sgd_solver.cpp:112] Iteration 42490, lr = 0.0001
I0811 06:02:01.120199 10215 solver.cpp:239] Iteration 42560 (5.54808 iter/s, 12.617s/70 iters), loss = 5.65221e-05
I0811 06:02:01.120321 10215 solver.cpp:258]     Train net output #0: loss = 5.68345e-05 (* 1 = 5.68345e-05 loss)
I0811 06:02:01.120340 10215 sgd_solver.cpp:112] Iteration 42560, lr = 0.0001
I0811 06:02:13.739102 10215 solver.cpp:239] Iteration 42630 (5.54743 iter/s, 12.6185s/70 iters), loss = 0.00028276
I0811 06:02:13.739130 10215 solver.cpp:258]     Train net output #0: loss = 0.000283072 (* 1 = 0.000283072 loss)
I0811 06:02:13.739136 10215 sgd_solver.cpp:112] Iteration 42630, lr = 0.0001
I0811 06:02:15.778657 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:02:26.364557 10215 solver.cpp:239] Iteration 42700 (5.54452 iter/s, 12.6251s/70 iters), loss = 8.35667e-06
I0811 06:02:26.364584 10215 solver.cpp:258]     Train net output #0: loss = 8.6713e-06 (* 1 = 8.6713e-06 loss)
I0811 06:02:26.364591 10215 sgd_solver.cpp:112] Iteration 42700, lr = 0.0001
I0811 06:02:28.266641 10215 solver.cpp:347] Iteration 42712, Testing net (#0)
I0811 06:02:28.266657 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:02:33.990224 10215 blocking_queue.cpp:49] Waiting for data
I0811 06:02:41.018224 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:02:44.966936 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:02:44.966959 10215 solver.cpp:414]     Test net output #1: loss = 0.00707046 (* 1 = 0.00707046 loss)
I0811 06:02:55.597535 10215 solver.cpp:239] Iteration 42770 (2.39462 iter/s, 29.2322s/70 iters), loss = 1.9428e-05
I0811 06:02:55.597563 10215 solver.cpp:258]     Train net output #0: loss = 1.97442e-05 (* 1 = 1.97442e-05 loss)
I0811 06:02:55.597568 10215 sgd_solver.cpp:112] Iteration 42770, lr = 0.0001
I0811 06:03:08.230873 10215 solver.cpp:239] Iteration 42840 (5.54106 iter/s, 12.633s/70 iters), loss = 1.18901e-05
I0811 06:03:08.230965 10215 solver.cpp:258]     Train net output #0: loss = 1.22036e-05 (* 1 = 1.22036e-05 loss)
I0811 06:03:08.230973 10215 sgd_solver.cpp:112] Iteration 42840, lr = 0.0001
I0811 06:03:20.860813 10215 solver.cpp:239] Iteration 42910 (5.54258 iter/s, 12.6295s/70 iters), loss = 1.49774e-05
I0811 06:03:20.860843 10215 solver.cpp:258]     Train net output #0: loss = 1.52932e-05 (* 1 = 1.52932e-05 loss)
I0811 06:03:20.860849 10215 sgd_solver.cpp:112] Iteration 42910, lr = 0.0001
I0811 06:03:33.483070 10215 solver.cpp:239] Iteration 42980 (5.54592 iter/s, 12.6219s/70 iters), loss = 0.000123683
I0811 06:03:33.483100 10215 solver.cpp:258]     Train net output #0: loss = 0.000124 (* 1 = 0.000124 loss)
I0811 06:03:33.483106 10215 sgd_solver.cpp:112] Iteration 42980, lr = 0.0001
I0811 06:03:46.102993 10215 solver.cpp:239] Iteration 43050 (5.54695 iter/s, 12.6195s/70 iters), loss = 9.87227e-05
I0811 06:03:46.103135 10215 solver.cpp:258]     Train net output #0: loss = 9.90393e-05 (* 1 = 9.90393e-05 loss)
I0811 06:03:46.103143 10215 sgd_solver.cpp:112] Iteration 43050, lr = 0.0001
I0811 06:03:58.715272 10215 solver.cpp:239] Iteration 43120 (5.55036 iter/s, 12.6118s/70 iters), loss = 3.16781e-05
I0811 06:03:58.715301 10215 solver.cpp:258]     Train net output #0: loss = 3.19982e-05 (* 1 = 3.19982e-05 loss)
I0811 06:03:58.715306 10215 sgd_solver.cpp:112] Iteration 43120, lr = 0.0001
I0811 06:04:11.332056 10215 solver.cpp:239] Iteration 43190 (5.54833 iter/s, 12.6164s/70 iters), loss = 0.000882744
I0811 06:04:11.332084 10215 solver.cpp:258]     Train net output #0: loss = 0.000883066 (* 1 = 0.000883066 loss)
I0811 06:04:11.332090 10215 sgd_solver.cpp:112] Iteration 43190, lr = 0.0001
I0811 06:04:13.555452 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:04:23.950587 10215 solver.cpp:239] Iteration 43260 (5.54756 iter/s, 12.6182s/70 iters), loss = 2.37645e-05
I0811 06:04:23.950773 10215 solver.cpp:258]     Train net output #0: loss = 2.40833e-05 (* 1 = 2.40833e-05 loss)
I0811 06:04:23.950780 10215 sgd_solver.cpp:112] Iteration 43260, lr = 0.0001
I0811 06:04:26.216333 10215 solver.cpp:347] Iteration 43274, Testing net (#0)
I0811 06:04:26.216348 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:04:39.863389 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:04:44.120613 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:04:44.120641 10215 solver.cpp:414]     Test net output #1: loss = 0.00682251 (* 1 = 0.00682251 loss)
I0811 06:04:54.407203 10215 solver.cpp:239] Iteration 43330 (2.29843 iter/s, 30.4556s/70 iters), loss = 0.000222487
I0811 06:04:54.407269 10215 solver.cpp:258]     Train net output #0: loss = 0.00022281 (* 1 = 0.00022281 loss)
I0811 06:04:54.407274 10215 sgd_solver.cpp:112] Iteration 43330, lr = 0.0001
I0811 06:05:07.035303 10215 solver.cpp:239] Iteration 43400 (5.54337 iter/s, 12.6277s/70 iters), loss = 0.00761608
I0811 06:05:07.035331 10215 solver.cpp:258]     Train net output #0: loss = 0.0076164 (* 1 = 0.0076164 loss)
I0811 06:05:07.035336 10215 sgd_solver.cpp:112] Iteration 43400, lr = 0.0001
I0811 06:05:19.649787 10215 solver.cpp:239] Iteration 43470 (5.54934 iter/s, 12.6141s/70 iters), loss = 2.71037e-05
I0811 06:05:19.649817 10215 solver.cpp:258]     Train net output #0: loss = 2.74285e-05 (* 1 = 2.74285e-05 loss)
I0811 06:05:19.649823 10215 sgd_solver.cpp:112] Iteration 43470, lr = 0.0001
I0811 06:05:32.262159 10215 solver.cpp:239] Iteration 43540 (5.55027 iter/s, 12.612s/70 iters), loss = 2.11335e-05
I0811 06:05:32.262205 10215 solver.cpp:258]     Train net output #0: loss = 2.14576e-05 (* 1 = 2.14576e-05 loss)
I0811 06:05:32.262212 10215 sgd_solver.cpp:112] Iteration 43540, lr = 0.0001
I0811 06:05:44.876956 10215 solver.cpp:239] Iteration 43610 (5.54921 iter/s, 12.6144s/70 iters), loss = 0.000665182
I0811 06:05:44.876984 10215 solver.cpp:258]     Train net output #0: loss = 0.000665504 (* 1 = 0.000665504 loss)
I0811 06:05:44.876991 10215 sgd_solver.cpp:112] Iteration 43610, lr = 0.0001
I0811 06:05:57.500277 10215 solver.cpp:239] Iteration 43680 (5.54545 iter/s, 12.6229s/70 iters), loss = 3.45081e-05
I0811 06:05:57.500305 10215 solver.cpp:258]     Train net output #0: loss = 3.48391e-05 (* 1 = 3.48391e-05 loss)
I0811 06:05:57.500313 10215 sgd_solver.cpp:112] Iteration 43680, lr = 0.0001
I0811 06:06:10.115818 10215 solver.cpp:239] Iteration 43750 (5.54888 iter/s, 12.6152s/70 iters), loss = 0.0037918
I0811 06:06:10.115916 10215 solver.cpp:258]     Train net output #0: loss = 0.00379213 (* 1 = 0.00379213 loss)
I0811 06:06:10.115921 10215 sgd_solver.cpp:112] Iteration 43750, lr = 0.0001
I0811 06:06:12.533604 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:06:22.740809 10215 solver.cpp:239] Iteration 43820 (5.54474 iter/s, 12.6246s/70 iters), loss = 4.73196e-05
I0811 06:06:22.740836 10215 solver.cpp:258]     Train net output #0: loss = 4.76564e-05 (* 1 = 4.76564e-05 loss)
I0811 06:06:22.740842 10215 sgd_solver.cpp:112] Iteration 43820, lr = 0.0001
I0811 06:06:25.363404 10215 solver.cpp:347] Iteration 43836, Testing net (#0)
I0811 06:06:25.363418 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:06:38.253612 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:06:42.298310 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:06:42.298388 10215 solver.cpp:414]     Test net output #1: loss = 0.00689287 (* 1 = 0.00689287 loss)
I0811 06:06:52.223660 10215 solver.cpp:239] Iteration 43890 (2.37433 iter/s, 29.482s/70 iters), loss = 0.00443268
I0811 06:06:52.223688 10215 solver.cpp:258]     Train net output #0: loss = 0.00443303 (* 1 = 0.00443303 loss)
I0811 06:06:52.223695 10215 sgd_solver.cpp:112] Iteration 43890, lr = 0.0001
I0811 06:07:04.852669 10215 solver.cpp:239] Iteration 43960 (5.54296 iter/s, 12.6286s/70 iters), loss = 0.000521035
I0811 06:07:04.852695 10215 solver.cpp:258]     Train net output #0: loss = 0.000521376 (* 1 = 0.000521376 loss)
I0811 06:07:04.852701 10215 sgd_solver.cpp:112] Iteration 43960, lr = 0.0001
I0811 06:07:17.467762 10215 solver.cpp:239] Iteration 44030 (5.54907 iter/s, 12.6147s/70 iters), loss = 9.80665e-05
I0811 06:07:17.467902 10215 solver.cpp:258]     Train net output #0: loss = 9.84057e-05 (* 1 = 9.84057e-05 loss)
I0811 06:07:17.467911 10215 sgd_solver.cpp:112] Iteration 44030, lr = 0.0001
I0811 06:07:30.082082 10215 solver.cpp:239] Iteration 44100 (5.54946 iter/s, 12.6138s/70 iters), loss = 0.00156257
I0811 06:07:30.082109 10215 solver.cpp:258]     Train net output #0: loss = 0.00156291 (* 1 = 0.00156291 loss)
I0811 06:07:30.082114 10215 sgd_solver.cpp:112] Iteration 44100, lr = 0.0001
I0811 06:07:42.707060 10215 solver.cpp:239] Iteration 44170 (5.54473 iter/s, 12.6246s/70 iters), loss = 0.00227709
I0811 06:07:42.707088 10215 solver.cpp:258]     Train net output #0: loss = 0.00227743 (* 1 = 0.00227743 loss)
I0811 06:07:42.707093 10215 sgd_solver.cpp:112] Iteration 44170, lr = 0.0001
I0811 06:07:55.327378 10215 solver.cpp:239] Iteration 44240 (5.54678 iter/s, 12.6199s/70 iters), loss = 0.000272435
I0811 06:07:55.327564 10215 solver.cpp:258]     Train net output #0: loss = 0.000272779 (* 1 = 0.000272779 loss)
I0811 06:07:55.327572 10215 sgd_solver.cpp:112] Iteration 44240, lr = 0.0001
I0811 06:08:07.955819 10215 solver.cpp:239] Iteration 44310 (5.54327 iter/s, 12.6279s/70 iters), loss = 0.00407042
I0811 06:08:07.955847 10215 solver.cpp:258]     Train net output #0: loss = 0.00407076 (* 1 = 0.00407076 loss)
I0811 06:08:07.955853 10215 sgd_solver.cpp:112] Iteration 44310, lr = 0.0001
I0811 06:08:10.551875 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:08:20.576108 10215 solver.cpp:239] Iteration 44380 (5.54679 iter/s, 12.6199s/70 iters), loss = 0.00194143
I0811 06:08:20.576136 10215 solver.cpp:258]     Train net output #0: loss = 0.00194177 (* 1 = 0.00194177 loss)
I0811 06:08:20.576141 10215 sgd_solver.cpp:112] Iteration 44380, lr = 0.0001
I0811 06:08:23.552474 10215 solver.cpp:347] Iteration 44398, Testing net (#0)
I0811 06:08:23.552489 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:08:36.448529 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:08:40.565312 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:08:40.565335 10215 solver.cpp:414]     Test net output #1: loss = 0.00676171 (* 1 = 0.00676171 loss)
I0811 06:08:50.134739 10215 solver.cpp:239] Iteration 44450 (2.36824 iter/s, 29.5578s/70 iters), loss = 0.000666689
I0811 06:08:50.134766 10215 solver.cpp:258]     Train net output #0: loss = 0.000667028 (* 1 = 0.000667028 loss)
I0811 06:08:50.134773 10215 sgd_solver.cpp:112] Iteration 44450, lr = 0.0001
I0811 06:09:02.734905 10215 solver.cpp:239] Iteration 44520 (5.55565 iter/s, 12.5998s/70 iters), loss = 0.000198913
I0811 06:09:02.734953 10215 solver.cpp:258]     Train net output #0: loss = 0.000199254 (* 1 = 0.000199254 loss)
I0811 06:09:02.734959 10215 sgd_solver.cpp:112] Iteration 44520, lr = 0.0001
I0811 06:09:15.358372 10215 solver.cpp:239] Iteration 44590 (5.54541 iter/s, 12.6231s/70 iters), loss = 0.0110886
I0811 06:09:15.358543 10215 solver.cpp:258]     Train net output #0: loss = 0.0110889 (* 1 = 0.0110889 loss)
I0811 06:09:15.358556 10215 sgd_solver.cpp:112] Iteration 44590, lr = 0.0001
I0811 06:09:27.993850 10215 solver.cpp:239] Iteration 44660 (5.54018 iter/s, 12.635s/70 iters), loss = 0.000501333
I0811 06:09:27.993878 10215 solver.cpp:258]     Train net output #0: loss = 0.000501673 (* 1 = 0.000501673 loss)
I0811 06:09:27.993885 10215 sgd_solver.cpp:112] Iteration 44660, lr = 0.0001
I0811 06:09:40.610786 10215 solver.cpp:239] Iteration 44730 (5.54826 iter/s, 12.6166s/70 iters), loss = 9.28016e-05
I0811 06:09:40.610815 10215 solver.cpp:258]     Train net output #0: loss = 9.31398e-05 (* 1 = 9.31398e-05 loss)
I0811 06:09:40.610821 10215 sgd_solver.cpp:112] Iteration 44730, lr = 0.0001
I0811 06:09:53.245110 10215 solver.cpp:239] Iteration 44800 (5.54063 iter/s, 12.634s/70 iters), loss = 5.14195e-05
I0811 06:09:53.245270 10215 solver.cpp:258]     Train net output #0: loss = 5.1759e-05 (* 1 = 5.1759e-05 loss)
I0811 06:09:53.245277 10215 sgd_solver.cpp:112] Iteration 44800, lr = 0.0001
I0811 06:10:05.868921 10215 solver.cpp:239] Iteration 44870 (5.5453 iter/s, 12.6233s/70 iters), loss = 5.12685e-05
I0811 06:10:05.868954 10215 solver.cpp:258]     Train net output #0: loss = 5.16061e-05 (* 1 = 5.16061e-05 loss)
I0811 06:10:05.868959 10215 sgd_solver.cpp:112] Iteration 44870, lr = 0.0001
I0811 06:10:08.670454 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:10:18.480990 10215 solver.cpp:239] Iteration 44940 (5.5504 iter/s, 12.6117s/70 iters), loss = 0.00065079
I0811 06:10:18.481019 10215 solver.cpp:258]     Train net output #0: loss = 0.000651127 (* 1 = 0.000651127 loss)
I0811 06:10:18.481024 10215 sgd_solver.cpp:112] Iteration 44940, lr = 0.0001
I0811 06:10:21.828675 10215 solver.cpp:464] Snapshotting to binary proto file snapshot_iter_44960.caffemodel
I0811 06:10:21.924150 10215 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshot_iter_44960.solverstate
I0811 06:10:21.928616 10215 solver.cpp:347] Iteration 44960, Testing net (#0)
I0811 06:10:21.928627 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:10:31.880250 10215 blocking_queue.cpp:49] Waiting for data
I0811 06:10:34.657896 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:10:38.821753 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 06:10:38.821776 10215 solver.cpp:414]     Test net output #1: loss = 0.00680147 (* 1 = 0.00680147 loss)
I0811 06:10:48.034638 10215 solver.cpp:239] Iteration 45010 (2.36864 iter/s, 29.5528s/70 iters), loss = 0.000250878
I0811 06:10:48.034667 10215 solver.cpp:258]     Train net output #0: loss = 0.00025121 (* 1 = 0.00025121 loss)
I0811 06:10:48.034672 10215 sgd_solver.cpp:112] Iteration 45010, lr = 0.0001
I0811 06:11:00.660960 10215 solver.cpp:239] Iteration 45080 (5.54414 iter/s, 12.6259s/70 iters), loss = 0.000452853
I0811 06:11:00.660987 10215 solver.cpp:258]     Train net output #0: loss = 0.000453184 (* 1 = 0.000453184 loss)
I0811 06:11:00.660992 10215 sgd_solver.cpp:112] Iteration 45080, lr = 0.0001
I0811 06:11:13.290107 10215 solver.cpp:239] Iteration 45150 (5.5429 iter/s, 12.6288s/70 iters), loss = 2.70037e-05
I0811 06:11:13.290248 10215 solver.cpp:258]     Train net output #0: loss = 2.7332e-05 (* 1 = 2.7332e-05 loss)
I0811 06:11:13.290256 10215 sgd_solver.cpp:112] Iteration 45150, lr = 0.0001
I0811 06:11:25.920696 10215 solver.cpp:239] Iteration 45220 (5.54231 iter/s, 12.6301s/70 iters), loss = 0.000169286
I0811 06:11:25.920773 10215 solver.cpp:258]     Train net output #0: loss = 0.000169607 (* 1 = 0.000169607 loss)
I0811 06:11:25.920779 10215 sgd_solver.cpp:112] Iteration 45220, lr = 0.0001
I0811 06:11:38.554797 10215 solver.cpp:239] Iteration 45290 (5.54074 iter/s, 12.6337s/70 iters), loss = 5.40778e-05
I0811 06:11:38.554826 10215 solver.cpp:258]     Train net output #0: loss = 5.43976e-05 (* 1 = 5.43976e-05 loss)
I0811 06:11:38.554831 10215 sgd_solver.cpp:112] Iteration 45290, lr = 0.0001
I0811 06:11:51.176331 10215 solver.cpp:239] Iteration 45360 (5.54624 iter/s, 12.6212s/70 iters), loss = 0.00165318
I0811 06:11:51.176452 10215 solver.cpp:258]     Train net output #0: loss = 0.00165349 (* 1 = 0.00165349 loss)
I0811 06:11:51.176471 10215 sgd_solver.cpp:112] Iteration 45360, lr = 0.0001
I0811 06:12:03.802528 10215 solver.cpp:239] Iteration 45430 (5.54423 iter/s, 12.6257s/70 iters), loss = 0.00141962
I0811 06:12:03.802561 10215 solver.cpp:258]     Train net output #0: loss = 0.00141993 (* 1 = 0.00141993 loss)
I0811 06:12:03.802567 10215 sgd_solver.cpp:112] Iteration 45430, lr = 0.0001
I0811 06:12:06.895225 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:12:16.413941 10215 solver.cpp:239] Iteration 45500 (5.55069 iter/s, 12.611s/70 iters), loss = 4.28411e-05
I0811 06:12:16.413970 10215 solver.cpp:258]     Train net output #0: loss = 4.31589e-05 (* 1 = 4.31589e-05 loss)
I0811 06:12:16.413976 10215 sgd_solver.cpp:112] Iteration 45500, lr = 0.0001
I0811 06:12:20.110672 10215 solver.cpp:347] Iteration 45522, Testing net (#0)
I0811 06:12:20.110687 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:12:32.867736 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:12:37.095002 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997667
I0811 06:12:37.095026 10215 solver.cpp:414]     Test net output #1: loss = 0.0067366 (* 1 = 0.0067366 loss)
I0811 06:12:45.935361 10215 solver.cpp:239] Iteration 45570 (2.37123 iter/s, 29.5206s/70 iters), loss = 4.07743e-05
I0811 06:12:45.935390 10215 solver.cpp:258]     Train net output #0: loss = 4.1093e-05 (* 1 = 4.1093e-05 loss)
I0811 06:12:45.935396 10215 sgd_solver.cpp:112] Iteration 45570, lr = 0.0001
I0811 06:12:58.560446 10215 solver.cpp:239] Iteration 45640 (5.54468 iter/s, 12.6247s/70 iters), loss = 0.000821947
I0811 06:12:58.560473 10215 solver.cpp:258]     Train net output #0: loss = 0.000822266 (* 1 = 0.000822266 loss)
I0811 06:12:58.560479 10215 sgd_solver.cpp:112] Iteration 45640, lr = 0.0001
I0811 06:13:11.189307 10215 solver.cpp:239] Iteration 45710 (5.54302 iter/s, 12.6285s/70 iters), loss = 0.00211994
I0811 06:13:11.189474 10215 solver.cpp:258]     Train net output #0: loss = 0.00212025 (* 1 = 0.00212025 loss)
I0811 06:13:11.189482 10215 sgd_solver.cpp:112] Iteration 45710, lr = 0.0001
I0811 06:13:23.805850 10215 solver.cpp:239] Iteration 45780 (5.54849 iter/s, 12.616s/70 iters), loss = 0.0018351
I0811 06:13:23.805876 10215 solver.cpp:258]     Train net output #0: loss = 0.00183541 (* 1 = 0.00183541 loss)
I0811 06:13:23.805882 10215 sgd_solver.cpp:112] Iteration 45780, lr = 0.0001
I0811 06:13:36.437480 10215 solver.cpp:239] Iteration 45850 (5.54181 iter/s, 12.6313s/70 iters), loss = 0.00237547
I0811 06:13:36.437510 10215 solver.cpp:258]     Train net output #0: loss = 0.00237579 (* 1 = 0.00237579 loss)
I0811 06:13:36.437515 10215 sgd_solver.cpp:112] Iteration 45850, lr = 0.0001
I0811 06:13:49.060842 10215 solver.cpp:239] Iteration 45920 (5.54544 iter/s, 12.623s/70 iters), loss = 0.000401226
I0811 06:13:49.060986 10215 solver.cpp:258]     Train net output #0: loss = 0.000401543 (* 1 = 0.000401543 loss)
I0811 06:13:49.060994 10215 sgd_solver.cpp:112] Iteration 45920, lr = 0.0001
I0811 06:14:01.686477 10215 solver.cpp:239] Iteration 45990 (5.54448 iter/s, 12.6252s/70 iters), loss = 0.00856434
I0811 06:14:01.686506 10215 solver.cpp:258]     Train net output #0: loss = 0.00856465 (* 1 = 0.00856465 loss)
I0811 06:14:01.686512 10215 sgd_solver.cpp:112] Iteration 45990, lr = 0.0001
I0811 06:14:04.961810 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:14:14.307855 10215 solver.cpp:239] Iteration 46060 (5.54631 iter/s, 12.621s/70 iters), loss = 0.000593366
I0811 06:14:14.307886 10215 solver.cpp:258]     Train net output #0: loss = 0.000593678 (* 1 = 0.000593678 loss)
I0811 06:14:14.307893 10215 sgd_solver.cpp:112] Iteration 46060, lr = 0.0001
I0811 06:14:18.369025 10215 solver.cpp:347] Iteration 46084, Testing net (#0)
I0811 06:14:18.369040 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:14:31.108685 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:14:35.391255 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:14:35.391279 10215 solver.cpp:414]     Test net output #1: loss = 0.00672103 (* 1 = 0.00672103 loss)
I0811 06:14:43.883548 10215 solver.cpp:239] Iteration 46130 (2.36687 iter/s, 29.5749s/70 iters), loss = 0.00012109
I0811 06:14:43.883574 10215 solver.cpp:258]     Train net output #0: loss = 0.000121414 (* 1 = 0.000121414 loss)
I0811 06:14:43.883580 10215 sgd_solver.cpp:112] Iteration 46130, lr = 0.0001
I0811 06:14:56.495463 10215 solver.cpp:239] Iteration 46200 (5.55047 iter/s, 12.6115s/70 iters), loss = 1.35198e-05
I0811 06:14:56.495491 10215 solver.cpp:258]     Train net output #0: loss = 1.3844e-05 (* 1 = 1.3844e-05 loss)
I0811 06:14:56.495497 10215 sgd_solver.cpp:112] Iteration 46200, lr = 0.0001
I0811 06:15:09.119738 10215 solver.cpp:239] Iteration 46270 (5.54504 iter/s, 12.6239s/70 iters), loss = 0.000173082
I0811 06:15:09.119882 10215 solver.cpp:258]     Train net output #0: loss = 0.000173407 (* 1 = 0.000173407 loss)
I0811 06:15:09.119889 10215 sgd_solver.cpp:112] Iteration 46270, lr = 0.0001
I0811 06:15:21.755146 10215 solver.cpp:239] Iteration 46340 (5.5402 iter/s, 12.6349s/70 iters), loss = 4.84666e-06
I0811 06:15:21.755177 10215 solver.cpp:258]     Train net output #0: loss = 5.17455e-06 (* 1 = 5.17455e-06 loss)
I0811 06:15:21.755182 10215 sgd_solver.cpp:112] Iteration 46340, lr = 0.0001
I0811 06:15:34.379341 10215 solver.cpp:239] Iteration 46410 (5.54507 iter/s, 12.6238s/70 iters), loss = 1.00255e-05
I0811 06:15:34.379369 10215 solver.cpp:258]     Train net output #0: loss = 1.03569e-05 (* 1 = 1.03569e-05 loss)
I0811 06:15:34.379375 10215 sgd_solver.cpp:112] Iteration 46410, lr = 0.0001
I0811 06:15:47.003453 10215 solver.cpp:239] Iteration 46480 (5.54511 iter/s, 12.6237s/70 iters), loss = 0.00103537
I0811 06:15:47.003579 10215 solver.cpp:258]     Train net output #0: loss = 0.0010357 (* 1 = 0.0010357 loss)
I0811 06:15:47.003587 10215 sgd_solver.cpp:112] Iteration 46480, lr = 0.0001
I0811 06:15:59.615701 10215 solver.cpp:239] Iteration 46550 (5.55036 iter/s, 12.6118s/70 iters), loss = 0.000114654
I0811 06:15:59.615727 10215 solver.cpp:258]     Train net output #0: loss = 0.000114985 (* 1 = 0.000114985 loss)
I0811 06:15:59.615732 10215 sgd_solver.cpp:112] Iteration 46550, lr = 0.0001
I0811 06:16:03.083843 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:16:12.239056 10215 solver.cpp:239] Iteration 46620 (5.54544 iter/s, 12.623s/70 iters), loss = 0.00326641
I0811 06:16:12.239084 10215 solver.cpp:258]     Train net output #0: loss = 0.00326674 (* 1 = 0.00326674 loss)
I0811 06:16:12.239089 10215 sgd_solver.cpp:112] Iteration 46620, lr = 0.0001
I0811 06:16:16.673606 10215 solver.cpp:347] Iteration 46646, Testing net (#0)
I0811 06:16:16.673621 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:16:29.347354 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:16:33.671712 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:16:33.671736 10215 solver.cpp:414]     Test net output #1: loss = 0.00670792 (* 1 = 0.00670792 loss)
I0811 06:16:41.784948 10215 solver.cpp:239] Iteration 46690 (2.36926 iter/s, 29.5451s/70 iters), loss = 7.02602e-06
I0811 06:16:41.784978 10215 solver.cpp:258]     Train net output #0: loss = 7.35792e-06 (* 1 = 7.35792e-06 loss)
I0811 06:16:41.784983 10215 sgd_solver.cpp:112] Iteration 46690, lr = 0.0001
I0811 06:16:54.395272 10215 solver.cpp:239] Iteration 46760 (5.55117 iter/s, 12.61s/70 iters), loss = 0.000142382
I0811 06:16:54.395299 10215 solver.cpp:258]     Train net output #0: loss = 0.000142714 (* 1 = 0.000142714 loss)
I0811 06:16:54.395305 10215 sgd_solver.cpp:112] Iteration 46760, lr = 0.0001
I0811 06:17:07.016719 10215 solver.cpp:239] Iteration 46830 (5.54628 iter/s, 12.6211s/70 iters), loss = 1.11053e-05
I0811 06:17:07.016783 10215 solver.cpp:258]     Train net output #0: loss = 1.14371e-05 (* 1 = 1.14371e-05 loss)
I0811 06:17:07.016790 10215 sgd_solver.cpp:112] Iteration 46830, lr = 0.0001
I0811 06:17:19.621016 10215 solver.cpp:239] Iteration 46900 (5.55384 iter/s, 12.6039s/70 iters), loss = 0.00142308
I0811 06:17:19.621043 10215 solver.cpp:258]     Train net output #0: loss = 0.00142341 (* 1 = 0.00142341 loss)
I0811 06:17:19.621049 10215 sgd_solver.cpp:112] Iteration 46900, lr = 0.0001
I0811 06:17:32.243748 10215 solver.cpp:239] Iteration 46970 (5.54571 iter/s, 12.6224s/70 iters), loss = 1.59141e-05
I0811 06:17:32.243778 10215 solver.cpp:258]     Train net output #0: loss = 1.62507e-05 (* 1 = 1.62507e-05 loss)
I0811 06:17:32.243784 10215 sgd_solver.cpp:112] Iteration 46970, lr = 0.0001
I0811 06:17:44.863009 10215 solver.cpp:239] Iteration 47040 (5.54724 iter/s, 12.6189s/70 iters), loss = 0.000140968
I0811 06:17:44.863096 10215 solver.cpp:258]     Train net output #0: loss = 0.000141291 (* 1 = 0.000141291 loss)
I0811 06:17:44.863116 10215 sgd_solver.cpp:112] Iteration 47040, lr = 0.0001
I0811 06:17:57.492933 10215 solver.cpp:239] Iteration 47110 (5.54258 iter/s, 12.6295s/70 iters), loss = 2.79292e-05
I0811 06:17:57.492962 10215 solver.cpp:258]     Train net output #0: loss = 2.82536e-05 (* 1 = 2.82536e-05 loss)
I0811 06:17:57.492969 10215 sgd_solver.cpp:112] Iteration 47110, lr = 0.0001
I0811 06:18:01.152179 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:18:10.116632 10215 solver.cpp:239] Iteration 47180 (5.54529 iter/s, 12.6233s/70 iters), loss = 1.18545e-05
I0811 06:18:10.116659 10215 solver.cpp:258]     Train net output #0: loss = 1.21797e-05 (* 1 = 1.21797e-05 loss)
I0811 06:18:10.116665 10215 sgd_solver.cpp:112] Iteration 47180, lr = 0.0001
I0811 06:18:14.904407 10215 solver.cpp:347] Iteration 47208, Testing net (#0)
I0811 06:18:14.904511 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:18:27.458472 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:18:28.933590 10215 blocking_queue.cpp:49] Waiting for data
I0811 06:18:31.855478 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:18:31.855500 10215 solver.cpp:414]     Test net output #1: loss = 0.00663637 (* 1 = 0.00663637 loss)
I0811 06:18:39.615819 10215 solver.cpp:239] Iteration 47250 (2.37301 iter/s, 29.4984s/70 iters), loss = 1.66148e-06
I0811 06:18:39.615846 10215 solver.cpp:258]     Train net output #0: loss = 1.98187e-06 (* 1 = 1.98187e-06 loss)
I0811 06:18:39.615851 10215 sgd_solver.cpp:112] Iteration 47250, lr = 0.0001
I0811 06:18:52.232794 10215 solver.cpp:239] Iteration 47320 (5.54824 iter/s, 12.6166s/70 iters), loss = 0.00134294
I0811 06:18:52.232878 10215 solver.cpp:258]     Train net output #0: loss = 0.00134326 (* 1 = 0.00134326 loss)
I0811 06:18:52.232885 10215 sgd_solver.cpp:112] Iteration 47320, lr = 0.0001
I0811 06:19:04.859043 10215 solver.cpp:239] Iteration 47390 (5.54419 iter/s, 12.6258s/70 iters), loss = 0.00271578
I0811 06:19:04.859071 10215 solver.cpp:258]     Train net output #0: loss = 0.00271608 (* 1 = 0.00271608 loss)
I0811 06:19:04.859076 10215 sgd_solver.cpp:112] Iteration 47390, lr = 0.0001
I0811 06:19:17.485091 10215 solver.cpp:239] Iteration 47460 (5.54426 iter/s, 12.6257s/70 iters), loss = 0.00306295
I0811 06:19:17.485119 10215 solver.cpp:258]     Train net output #0: loss = 0.00306325 (* 1 = 0.00306325 loss)
I0811 06:19:17.485126 10215 sgd_solver.cpp:112] Iteration 47460, lr = 0.0001
I0811 06:19:30.108738 10215 solver.cpp:239] Iteration 47530 (5.54531 iter/s, 12.6233s/70 iters), loss = 1.74821e-05
I0811 06:19:30.108881 10215 solver.cpp:258]     Train net output #0: loss = 1.77883e-05 (* 1 = 1.77883e-05 loss)
I0811 06:19:30.108889 10215 sgd_solver.cpp:112] Iteration 47530, lr = 0.0001
I0811 06:19:42.730779 10215 solver.cpp:239] Iteration 47600 (5.54607 iter/s, 12.6216s/70 iters), loss = 0.000145771
I0811 06:19:42.730806 10215 solver.cpp:258]     Train net output #0: loss = 0.000146078 (* 1 = 0.000146078 loss)
I0811 06:19:42.730813 10215 sgd_solver.cpp:112] Iteration 47600, lr = 0.0001
I0811 06:19:55.356228 10215 solver.cpp:239] Iteration 47670 (5.54452 iter/s, 12.6251s/70 iters), loss = 7.93013e-05
I0811 06:19:55.356256 10215 solver.cpp:258]     Train net output #0: loss = 7.96065e-05 (* 1 = 7.96065e-05 loss)
I0811 06:19:55.356262 10215 sgd_solver.cpp:112] Iteration 47670, lr = 0.0001
I0811 06:19:59.210584 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:20:07.981617 10215 solver.cpp:239] Iteration 47740 (5.54455 iter/s, 12.625s/70 iters), loss = 0.000123879
I0811 06:20:07.981748 10215 solver.cpp:258]     Train net output #0: loss = 0.000124183 (* 1 = 0.000124183 loss)
I0811 06:20:07.981756 10215 sgd_solver.cpp:112] Iteration 47740, lr = 0.0001
I0811 06:20:13.129317 10215 solver.cpp:347] Iteration 47770, Testing net (#0)
I0811 06:20:13.129330 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:20:25.601790 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:20:30.013801 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:20:30.013824 10215 solver.cpp:414]     Test net output #1: loss = 0.00682128 (* 1 = 0.00682128 loss)
I0811 06:20:37.415771 10215 solver.cpp:239] Iteration 47810 (2.37826 iter/s, 29.4332s/70 iters), loss = 0.116615
I0811 06:20:37.415798 10215 solver.cpp:258]     Train net output #0: loss = 0.116615 (* 1 = 0.116615 loss)
I0811 06:20:37.415804 10215 sgd_solver.cpp:112] Iteration 47810, lr = 0.0001
I0811 06:20:50.038059 10215 solver.cpp:239] Iteration 47880 (5.54591 iter/s, 12.6219s/70 iters), loss = 3.03612e-05
I0811 06:20:50.038202 10215 solver.cpp:258]     Train net output #0: loss = 3.06631e-05 (* 1 = 3.06631e-05 loss)
I0811 06:20:50.038209 10215 sgd_solver.cpp:112] Iteration 47880, lr = 0.0001
I0811 06:21:02.675128 10215 solver.cpp:239] Iteration 47950 (5.53947 iter/s, 12.6366s/70 iters), loss = 1.46668e-05
I0811 06:21:02.675154 10215 solver.cpp:258]     Train net output #0: loss = 1.49679e-05 (* 1 = 1.49679e-05 loss)
I0811 06:21:02.675160 10215 sgd_solver.cpp:112] Iteration 47950, lr = 0.0001
I0811 06:21:15.284982 10215 solver.cpp:239] Iteration 48020 (5.55138 iter/s, 12.6095s/70 iters), loss = 0.000681674
I0811 06:21:15.285012 10215 solver.cpp:258]     Train net output #0: loss = 0.00068197 (* 1 = 0.00068197 loss)
I0811 06:21:15.285017 10215 sgd_solver.cpp:112] Iteration 48020, lr = 0.0001
I0811 06:21:27.910630 10215 solver.cpp:239] Iteration 48090 (5.54444 iter/s, 12.6253s/70 iters), loss = 1.74865e-05
I0811 06:21:27.910789 10215 solver.cpp:258]     Train net output #0: loss = 1.77793e-05 (* 1 = 1.77793e-05 loss)
I0811 06:21:27.910797 10215 sgd_solver.cpp:112] Iteration 48090, lr = 0.0001
I0811 06:21:40.536597 10215 solver.cpp:239] Iteration 48160 (5.54435 iter/s, 12.6255s/70 iters), loss = 0.000102899
I0811 06:21:40.536625 10215 solver.cpp:258]     Train net output #0: loss = 0.000103202 (* 1 = 0.000103202 loss)
I0811 06:21:40.536631 10215 sgd_solver.cpp:112] Iteration 48160, lr = 0.0001
I0811 06:21:53.161044 10215 solver.cpp:239] Iteration 48230 (5.54496 iter/s, 12.6241s/70 iters), loss = 6.41351e-05
I0811 06:21:53.161070 10215 solver.cpp:258]     Train net output #0: loss = 6.44404e-05 (* 1 = 6.44404e-05 loss)
I0811 06:21:53.161077 10215 sgd_solver.cpp:112] Iteration 48230, lr = 0.0001
I0811 06:21:57.198379 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:22:05.791009 10215 solver.cpp:239] Iteration 48300 (5.54254 iter/s, 12.6296s/70 iters), loss = 1.35272e-05
I0811 06:22:05.791105 10215 solver.cpp:258]     Train net output #0: loss = 1.3834e-05 (* 1 = 1.3834e-05 loss)
I0811 06:22:05.791123 10215 sgd_solver.cpp:112] Iteration 48300, lr = 0.0001
I0811 06:22:11.291944 10215 solver.cpp:347] Iteration 48332, Testing net (#0)
I0811 06:22:11.291957 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:22:23.805507 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:22:28.283442 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 06:22:28.283464 10215 solver.cpp:414]     Test net output #1: loss = 0.00691618 (* 1 = 0.00691618 loss)
I0811 06:22:35.322984 10215 solver.cpp:239] Iteration 48370 (2.37038 iter/s, 29.5311s/70 iters), loss = 0.00214948
I0811 06:22:35.323015 10215 solver.cpp:258]     Train net output #0: loss = 0.00214979 (* 1 = 0.00214979 loss)
I0811 06:22:35.323021 10215 sgd_solver.cpp:112] Iteration 48370, lr = 0.0001
I0811 06:22:47.943017 10215 solver.cpp:239] Iteration 48440 (5.5469 iter/s, 12.6197s/70 iters), loss = 0.000190811
I0811 06:22:47.943154 10215 solver.cpp:258]     Train net output #0: loss = 0.000191114 (* 1 = 0.000191114 loss)
I0811 06:22:47.943161 10215 sgd_solver.cpp:112] Iteration 48440, lr = 0.0001
I0811 06:23:00.576422 10215 solver.cpp:239] Iteration 48510 (5.54108 iter/s, 12.6329s/70 iters), loss = 0.213214
I0811 06:23:00.576448 10215 solver.cpp:258]     Train net output #0: loss = 0.213214 (* 1 = 0.213214 loss)
I0811 06:23:00.576454 10215 sgd_solver.cpp:112] Iteration 48510, lr = 0.0001
I0811 06:23:13.199816 10215 solver.cpp:239] Iteration 48580 (5.54542 iter/s, 12.623s/70 iters), loss = 0.00538143
I0811 06:23:13.199844 10215 solver.cpp:258]     Train net output #0: loss = 0.00538173 (* 1 = 0.00538173 loss)
I0811 06:23:13.199851 10215 sgd_solver.cpp:112] Iteration 48580, lr = 0.0001
I0811 06:23:25.821858 10215 solver.cpp:239] Iteration 48650 (5.54602 iter/s, 12.6217s/70 iters), loss = 0.000973485
I0811 06:23:25.821951 10215 solver.cpp:258]     Train net output #0: loss = 0.000973779 (* 1 = 0.000973779 loss)
I0811 06:23:25.821971 10215 sgd_solver.cpp:112] Iteration 48650, lr = 0.0001
I0811 06:23:38.440929 10215 solver.cpp:239] Iteration 48720 (5.54735 iter/s, 12.6186s/70 iters), loss = 0.000274972
I0811 06:23:38.440960 10215 solver.cpp:258]     Train net output #0: loss = 0.000275268 (* 1 = 0.000275268 loss)
I0811 06:23:38.440966 10215 sgd_solver.cpp:112] Iteration 48720, lr = 0.0001
I0811 06:23:51.071952 10215 solver.cpp:239] Iteration 48790 (5.54208 iter/s, 12.6306s/70 iters), loss = 0.00121281
I0811 06:23:51.071985 10215 solver.cpp:258]     Train net output #0: loss = 0.0012131 (* 1 = 0.0012131 loss)
I0811 06:23:51.071990 10215 sgd_solver.cpp:112] Iteration 48790, lr = 0.0001
I0811 06:23:55.303659 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:24:03.702558 10215 solver.cpp:239] Iteration 48860 (5.54226 iter/s, 12.6302s/70 iters), loss = 0.000284204
I0811 06:24:03.702726 10215 solver.cpp:258]     Train net output #0: loss = 0.000284496 (* 1 = 0.000284496 loss)
I0811 06:24:03.702733 10215 sgd_solver.cpp:112] Iteration 48860, lr = 0.0001
I0811 06:24:09.576058 10215 solver.cpp:347] Iteration 48894, Testing net (#0)
I0811 06:24:09.576072 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:24:22.396279 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:24:26.953943 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:24:26.953968 10215 solver.cpp:414]     Test net output #1: loss = 0.0070402 (* 1 = 0.0070402 loss)
I0811 06:24:33.635187 10215 solver.cpp:239] Iteration 48930 (2.33866 iter/s, 29.9317s/70 iters), loss = 4.31373e-05
I0811 06:24:33.635215 10215 solver.cpp:258]     Train net output #0: loss = 4.34265e-05 (* 1 = 4.34265e-05 loss)
I0811 06:24:33.635221 10215 sgd_solver.cpp:112] Iteration 48930, lr = 0.0001
I0811 06:24:46.253355 10215 solver.cpp:239] Iteration 49000 (5.54772 iter/s, 12.6178s/70 iters), loss = 0.000102653
I0811 06:24:46.253494 10215 solver.cpp:258]     Train net output #0: loss = 0.000102944 (* 1 = 0.000102944 loss)
I0811 06:24:46.253502 10215 sgd_solver.cpp:112] Iteration 49000, lr = 0.0001
I0811 06:24:58.869232 10215 solver.cpp:239] Iteration 49070 (5.54877 iter/s, 12.6154s/70 iters), loss = 5.88978e-05
I0811 06:24:58.869261 10215 solver.cpp:258]     Train net output #0: loss = 5.91907e-05 (* 1 = 5.91907e-05 loss)
I0811 06:24:58.869266 10215 sgd_solver.cpp:112] Iteration 49070, lr = 0.0001
I0811 06:25:11.495786 10215 solver.cpp:239] Iteration 49140 (5.54403 iter/s, 12.6262s/70 iters), loss = 6.10564e-05
I0811 06:25:11.495815 10215 solver.cpp:258]     Train net output #0: loss = 6.13451e-05 (* 1 = 6.13451e-05 loss)
I0811 06:25:11.495821 10215 sgd_solver.cpp:112] Iteration 49140, lr = 0.0001
I0811 06:25:24.095199 10215 solver.cpp:239] Iteration 49210 (5.55598 iter/s, 12.599s/70 iters), loss = 0.00508267
I0811 06:25:24.095281 10215 solver.cpp:258]     Train net output #0: loss = 0.00508296 (* 1 = 0.00508296 loss)
I0811 06:25:24.095300 10215 sgd_solver.cpp:112] Iteration 49210, lr = 0.0001
I0811 06:25:36.726555 10215 solver.cpp:239] Iteration 49280 (5.54195 iter/s, 12.6309s/70 iters), loss = 0.000133477
I0811 06:25:36.726634 10215 solver.cpp:258]     Train net output #0: loss = 0.000133783 (* 1 = 0.000133783 loss)
I0811 06:25:36.726641 10215 sgd_solver.cpp:112] Iteration 49280, lr = 0.0001
I0811 06:25:49.356200 10215 solver.cpp:239] Iteration 49350 (5.54269 iter/s, 12.6292s/70 iters), loss = 0.0303196
I0811 06:25:49.356227 10215 solver.cpp:258]     Train net output #0: loss = 0.0303199 (* 1 = 0.0303199 loss)
I0811 06:25:49.356232 10215 sgd_solver.cpp:112] Iteration 49350, lr = 0.0001
I0811 06:25:53.773331 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:26:01.980383 10215 solver.cpp:239] Iteration 49420 (5.54508 iter/s, 12.6238s/70 iters), loss = 0.00105897
I0811 06:26:01.980531 10215 solver.cpp:258]     Train net output #0: loss = 0.00105927 (* 1 = 0.00105927 loss)
I0811 06:26:01.980540 10215 sgd_solver.cpp:112] Iteration 49420, lr = 0.0001
I0811 06:26:08.216269 10215 solver.cpp:347] Iteration 49456, Testing net (#0)
I0811 06:26:08.216284 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:26:20.566890 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:26:25.153478 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:26:25.153502 10215 solver.cpp:414]     Test net output #1: loss = 0.00705411 (* 1 = 0.00705411 loss)
I0811 06:26:31.464756 10215 solver.cpp:239] Iteration 49490 (2.37421 iter/s, 29.4834s/70 iters), loss = 0.00633037
I0811 06:26:31.464782 10215 solver.cpp:258]     Train net output #0: loss = 0.00633067 (* 1 = 0.00633067 loss)
I0811 06:26:31.464788 10215 sgd_solver.cpp:112] Iteration 49490, lr = 0.0001
I0811 06:26:44.085264 10215 solver.cpp:239] Iteration 49560 (5.54669 iter/s, 12.6201s/70 iters), loss = 0.00604861
I0811 06:26:44.085467 10215 solver.cpp:258]     Train net output #0: loss = 0.00604891 (* 1 = 0.00604891 loss)
I0811 06:26:44.085475 10215 sgd_solver.cpp:112] Iteration 49560, lr = 0.0001
I0811 06:26:56.700304 10215 solver.cpp:239] Iteration 49630 (5.54916 iter/s, 12.6145s/70 iters), loss = 0.0111984
I0811 06:26:56.700331 10215 solver.cpp:258]     Train net output #0: loss = 0.0111987 (* 1 = 0.0111987 loss)
I0811 06:26:56.700337 10215 sgd_solver.cpp:112] Iteration 49630, lr = 0.0001
I0811 06:27:09.336549 10215 solver.cpp:239] Iteration 49700 (5.53978 iter/s, 12.6359s/70 iters), loss = 0.00197344
I0811 06:27:09.336589 10215 solver.cpp:258]     Train net output #0: loss = 0.00197373 (* 1 = 0.00197373 loss)
I0811 06:27:09.336596 10215 sgd_solver.cpp:112] Iteration 49700, lr = 0.0001
I0811 06:27:21.971184 10215 solver.cpp:239] Iteration 49770 (5.5405 iter/s, 12.6342s/70 iters), loss = 1.59838e-06
I0811 06:27:21.971243 10215 solver.cpp:258]     Train net output #0: loss = 1.88501e-06 (* 1 = 1.88501e-06 loss)
I0811 06:27:21.971251 10215 sgd_solver.cpp:112] Iteration 49770, lr = 0.0001
I0811 06:27:34.607846 10215 solver.cpp:239] Iteration 49840 (5.53961 iter/s, 12.6363s/70 iters), loss = 0.000418983
I0811 06:27:34.607874 10215 solver.cpp:258]     Train net output #0: loss = 0.000419265 (* 1 = 0.000419265 loss)
I0811 06:27:34.607880 10215 sgd_solver.cpp:112] Iteration 49840, lr = 0.0001
I0811 06:27:47.245826 10215 solver.cpp:239] Iteration 49910 (5.53902 iter/s, 12.6376s/70 iters), loss = 0.00745552
I0811 06:27:47.245853 10215 solver.cpp:258]     Train net output #0: loss = 0.0074558 (* 1 = 0.0074558 loss)
I0811 06:27:47.245859 10215 sgd_solver.cpp:112] Iteration 49910, lr = 0.0001
I0811 06:27:51.956282 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:27:59.868409 10215 solver.cpp:239] Iteration 49980 (5.54578 iter/s, 12.6222s/70 iters), loss = 0.00531117
I0811 06:27:59.868552 10215 solver.cpp:258]     Train net output #0: loss = 0.00531145 (* 1 = 0.00531145 loss)
I0811 06:27:59.868559 10215 sgd_solver.cpp:112] Iteration 49980, lr = 0.0001
I0811 06:28:06.460116 10215 solver.cpp:347] Iteration 50018, Testing net (#0)
I0811 06:28:06.460131 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:28:07.797312 10215 blocking_queue.cpp:49] Waiting for data
I0811 06:28:18.822432 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:28:23.488804 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:28:23.488831 10215 solver.cpp:414]     Test net output #1: loss = 0.00705974 (* 1 = 0.00705974 loss)
I0811 06:28:29.449391 10215 solver.cpp:239] Iteration 50050 (2.36646 iter/s, 29.58s/70 iters), loss = 0.000200962
I0811 06:28:29.449419 10215 solver.cpp:258]     Train net output #0: loss = 0.000201238 (* 1 = 0.000201238 loss)
I0811 06:28:29.449424 10215 sgd_solver.cpp:112] Iteration 50050, lr = 0.0001
I0811 06:28:42.071204 10215 solver.cpp:239] Iteration 50120 (5.54612 iter/s, 12.6214s/70 iters), loss = 0.00260102
I0811 06:28:42.071352 10215 solver.cpp:258]     Train net output #0: loss = 0.00260129 (* 1 = 0.00260129 loss)
I0811 06:28:42.071359 10215 sgd_solver.cpp:112] Iteration 50120, lr = 0.0001
I0811 06:28:54.693380 10215 solver.cpp:239] Iteration 50190 (5.54601 iter/s, 12.6217s/70 iters), loss = 0.000774548
I0811 06:28:54.693406 10215 solver.cpp:258]     Train net output #0: loss = 0.000774816 (* 1 = 0.000774816 loss)
I0811 06:28:54.693413 10215 sgd_solver.cpp:112] Iteration 50190, lr = 0.0001
I0811 06:29:07.293812 10215 solver.cpp:239] Iteration 50260 (5.55553 iter/s, 12.6001s/70 iters), loss = 3.98502e-05
I0811 06:29:07.293840 10215 solver.cpp:258]     Train net output #0: loss = 4.012e-05 (* 1 = 4.012e-05 loss)
I0811 06:29:07.293846 10215 sgd_solver.cpp:112] Iteration 50260, lr = 0.0001
I0811 06:29:19.917910 10215 solver.cpp:239] Iteration 50330 (5.54511 iter/s, 12.6237s/70 iters), loss = 0.000184894
I0811 06:29:19.918079 10215 solver.cpp:258]     Train net output #0: loss = 0.000185166 (* 1 = 0.000185166 loss)
I0811 06:29:19.918087 10215 sgd_solver.cpp:112] Iteration 50330, lr = 0.0001
I0811 06:29:32.518883 10215 solver.cpp:239] Iteration 50400 (5.55535 iter/s, 12.6005s/70 iters), loss = 0.00188365
I0811 06:29:32.518915 10215 solver.cpp:258]     Train net output #0: loss = 0.00188391 (* 1 = 0.00188391 loss)
I0811 06:29:32.518921 10215 sgd_solver.cpp:112] Iteration 50400, lr = 0.0001
I0811 06:29:45.145290 10215 solver.cpp:239] Iteration 50470 (5.5441 iter/s, 12.626s/70 iters), loss = 0.000367628
I0811 06:29:45.145321 10215 solver.cpp:258]     Train net output #0: loss = 0.000367896 (* 1 = 0.000367896 loss)
I0811 06:29:45.145326 10215 sgd_solver.cpp:112] Iteration 50470, lr = 0.0001
I0811 06:29:50.051514 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:29:57.766669 10215 solver.cpp:239] Iteration 50540 (5.54631 iter/s, 12.621s/70 iters), loss = 0.000628827
I0811 06:29:57.766695 10215 solver.cpp:258]     Train net output #0: loss = 0.000629095 (* 1 = 0.000629095 loss)
I0811 06:29:57.766701 10215 sgd_solver.cpp:112] Iteration 50540, lr = 0.0001
I0811 06:30:04.713826 10215 solver.cpp:347] Iteration 50580, Testing net (#0)
I0811 06:30:04.713840 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:30:17.002900 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:30:21.696180 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:30:21.696233 10215 solver.cpp:414]     Test net output #1: loss = 0.00706504 (* 1 = 0.00706504 loss)
I0811 06:30:27.296319 10215 solver.cpp:239] Iteration 50610 (2.37056 iter/s, 29.5288s/70 iters), loss = 0.000916545
I0811 06:30:27.296345 10215 solver.cpp:258]     Train net output #0: loss = 0.000916813 (* 1 = 0.000916813 loss)
I0811 06:30:27.296350 10215 sgd_solver.cpp:112] Iteration 50610, lr = 0.0001
I0811 06:30:39.923760 10215 solver.cpp:239] Iteration 50680 (5.54364 iter/s, 12.6271s/70 iters), loss = 1.8185e-05
I0811 06:30:39.923787 10215 solver.cpp:258]     Train net output #0: loss = 1.84513e-05 (* 1 = 1.84513e-05 loss)
I0811 06:30:39.923794 10215 sgd_solver.cpp:112] Iteration 50680, lr = 0.0001
I0811 06:30:52.556565 10215 solver.cpp:239] Iteration 50750 (5.54129 iter/s, 12.6324s/70 iters), loss = 0.00658203
I0811 06:30:52.556704 10215 solver.cpp:258]     Train net output #0: loss = 0.0065823 (* 1 = 0.0065823 loss)
I0811 06:30:52.556711 10215 sgd_solver.cpp:112] Iteration 50750, lr = 0.0001
I0811 06:31:05.171301 10215 solver.cpp:239] Iteration 50820 (5.54928 iter/s, 12.6143s/70 iters), loss = 0.000577614
I0811 06:31:05.171329 10215 solver.cpp:258]     Train net output #0: loss = 0.000577883 (* 1 = 0.000577883 loss)
I0811 06:31:05.171334 10215 sgd_solver.cpp:112] Iteration 50820, lr = 0.0001
I0811 06:31:17.793061 10215 solver.cpp:239] Iteration 50890 (5.54614 iter/s, 12.6214s/70 iters), loss = 1.10524e-05
I0811 06:31:17.793088 10215 solver.cpp:258]     Train net output #0: loss = 1.13216e-05 (* 1 = 1.13216e-05 loss)
I0811 06:31:17.793094 10215 sgd_solver.cpp:112] Iteration 50890, lr = 0.0001
I0811 06:31:30.412818 10215 solver.cpp:239] Iteration 50960 (5.54702 iter/s, 12.6194s/70 iters), loss = 0.00251076
I0811 06:31:30.412959 10215 solver.cpp:258]     Train net output #0: loss = 0.00251102 (* 1 = 0.00251102 loss)
I0811 06:31:30.412967 10215 sgd_solver.cpp:112] Iteration 50960, lr = 0.0001
I0811 06:31:43.029580 10215 solver.cpp:239] Iteration 51030 (5.54839 iter/s, 12.6163s/70 iters), loss = 0.00488574
I0811 06:31:43.029608 10215 solver.cpp:258]     Train net output #0: loss = 0.00488601 (* 1 = 0.00488601 loss)
I0811 06:31:43.029614 10215 sgd_solver.cpp:112] Iteration 51030, lr = 0.0001
I0811 06:31:48.121016 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:31:55.655865 10215 solver.cpp:239] Iteration 51100 (5.54415 iter/s, 12.6259s/70 iters), loss = 0.000244708
I0811 06:31:55.655892 10215 solver.cpp:258]     Train net output #0: loss = 0.000244975 (* 1 = 0.000244975 loss)
I0811 06:31:55.655899 10215 sgd_solver.cpp:112] Iteration 51100, lr = 0.0001
I0811 06:32:02.970043 10215 solver.cpp:347] Iteration 51142, Testing net (#0)
I0811 06:32:02.970135 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:32:15.191285 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:32:19.938915 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:32:19.938938 10215 solver.cpp:414]     Test net output #1: loss = 0.00695355 (* 1 = 0.00695355 loss)
I0811 06:32:25.174767 10215 solver.cpp:239] Iteration 51170 (2.37143 iter/s, 29.5181s/70 iters), loss = 3.12847e-06
I0811 06:32:25.174791 10215 solver.cpp:258]     Train net output #0: loss = 3.40124e-06 (* 1 = 3.40124e-06 loss)
I0811 06:32:25.174798 10215 sgd_solver.cpp:112] Iteration 51170, lr = 0.0001
I0811 06:32:37.800026 10215 solver.cpp:239] Iteration 51240 (5.5446 iter/s, 12.6249s/70 iters), loss = 0.0381928
I0811 06:32:37.800166 10215 solver.cpp:258]     Train net output #0: loss = 0.0381931 (* 1 = 0.0381931 loss)
I0811 06:32:37.800173 10215 sgd_solver.cpp:112] Iteration 51240, lr = 0.0001
I0811 06:32:50.422330 10215 solver.cpp:239] Iteration 51310 (5.54595 iter/s, 12.6218s/70 iters), loss = 0.000588194
I0811 06:32:50.422359 10215 solver.cpp:258]     Train net output #0: loss = 0.000588459 (* 1 = 0.000588459 loss)
I0811 06:32:50.422364 10215 sgd_solver.cpp:112] Iteration 51310, lr = 0.0001
I0811 06:33:03.060406 10215 solver.cpp:239] Iteration 51380 (5.53898 iter/s, 12.6377s/70 iters), loss = 0.000440561
I0811 06:33:03.060436 10215 solver.cpp:258]     Train net output #0: loss = 0.000440837 (* 1 = 0.000440837 loss)
I0811 06:33:03.060442 10215 sgd_solver.cpp:112] Iteration 51380, lr = 0.0001
I0811 06:33:15.694139 10215 solver.cpp:239] Iteration 51450 (5.54089 iter/s, 12.6334s/70 iters), loss = 0.0104352
I0811 06:33:15.694263 10215 solver.cpp:258]     Train net output #0: loss = 0.0104355 (* 1 = 0.0104355 loss)
I0811 06:33:15.694281 10215 sgd_solver.cpp:112] Iteration 51450, lr = 0.0001
I0811 06:33:28.295958 10215 solver.cpp:239] Iteration 51520 (5.55496 iter/s, 12.6014s/70 iters), loss = 2.77546e-05
I0811 06:33:28.295986 10215 solver.cpp:258]     Train net output #0: loss = 2.80236e-05 (* 1 = 2.80236e-05 loss)
I0811 06:33:28.295992 10215 sgd_solver.cpp:112] Iteration 51520, lr = 0.0001
I0811 06:33:40.920644 10215 solver.cpp:239] Iteration 51590 (5.54486 iter/s, 12.6243s/70 iters), loss = 0.00151602
I0811 06:33:40.920673 10215 solver.cpp:258]     Train net output #0: loss = 0.00151628 (* 1 = 0.00151628 loss)
I0811 06:33:40.920680 10215 sgd_solver.cpp:112] Iteration 51590, lr = 0.0001
I0811 06:33:46.217010 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:33:53.554489 10215 solver.cpp:239] Iteration 51660 (5.54084 iter/s, 12.6335s/70 iters), loss = 1.75749e-05
I0811 06:33:53.554519 10215 solver.cpp:258]     Train net output #0: loss = 1.78439e-05 (* 1 = 1.78439e-05 loss)
I0811 06:33:53.554525 10215 sgd_solver.cpp:112] Iteration 51660, lr = 0.0001
I0811 06:34:01.234257 10215 solver.cpp:347] Iteration 51704, Testing net (#0)
I0811 06:34:01.234272 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:34:13.391089 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:34:18.186594 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:34:18.186642 10215 solver.cpp:414]     Test net output #1: loss = 0.00704968 (* 1 = 0.00704968 loss)
I0811 06:34:23.064658 10215 solver.cpp:239] Iteration 51730 (2.37213 iter/s, 29.5093s/70 iters), loss = 0.0100307
I0811 06:34:23.064687 10215 solver.cpp:258]     Train net output #0: loss = 0.010031 (* 1 = 0.010031 loss)
I0811 06:34:23.064693 10215 sgd_solver.cpp:112] Iteration 51730, lr = 0.0001
I0811 06:34:35.698465 10215 solver.cpp:239] Iteration 51800 (5.54085 iter/s, 12.6334s/70 iters), loss = 0.00395257
I0811 06:34:35.698496 10215 solver.cpp:258]     Train net output #0: loss = 0.00395284 (* 1 = 0.00395284 loss)
I0811 06:34:35.698503 10215 sgd_solver.cpp:112] Iteration 51800, lr = 0.0001
I0811 06:34:48.333997 10215 solver.cpp:239] Iteration 51870 (5.5401 iter/s, 12.6352s/70 iters), loss = 3.55681e-05
I0811 06:34:48.334151 10215 solver.cpp:258]     Train net output #0: loss = 3.58402e-05 (* 1 = 3.58402e-05 loss)
I0811 06:34:48.334158 10215 sgd_solver.cpp:112] Iteration 51870, lr = 0.0001
I0811 06:35:00.958473 10215 solver.cpp:239] Iteration 51940 (5.545 iter/s, 12.624s/70 iters), loss = 0.00615926
I0811 06:35:00.958504 10215 solver.cpp:258]     Train net output #0: loss = 0.00615954 (* 1 = 0.00615954 loss)
I0811 06:35:00.958510 10215 sgd_solver.cpp:112] Iteration 51940, lr = 0.0001
I0811 06:35:13.582917 10215 solver.cpp:239] Iteration 52010 (5.54496 iter/s, 12.6241s/70 iters), loss = 0.00206292
I0811 06:35:13.582947 10215 solver.cpp:258]     Train net output #0: loss = 0.00206319 (* 1 = 0.00206319 loss)
I0811 06:35:13.582952 10215 sgd_solver.cpp:112] Iteration 52010, lr = 0.0001
I0811 06:35:26.193399 10215 solver.cpp:239] Iteration 52080 (5.5511 iter/s, 12.6101s/70 iters), loss = 1.5258e-05
I0811 06:35:26.193511 10215 solver.cpp:258]     Train net output #0: loss = 1.5539e-05 (* 1 = 1.5539e-05 loss)
I0811 06:35:26.193518 10215 sgd_solver.cpp:112] Iteration 52080, lr = 0.0001
I0811 06:35:38.818295 10215 solver.cpp:239] Iteration 52150 (5.5448 iter/s, 12.6244s/70 iters), loss = 2.01307e-05
I0811 06:35:38.818328 10215 solver.cpp:258]     Train net output #0: loss = 2.04087e-05 (* 1 = 2.04087e-05 loss)
I0811 06:35:38.818334 10215 sgd_solver.cpp:112] Iteration 52150, lr = 0.0001
I0811 06:35:44.289222 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:35:51.433070 10215 solver.cpp:239] Iteration 52220 (5.54921 iter/s, 12.6144s/70 iters), loss = 4.26397e-05
I0811 06:35:51.433099 10215 solver.cpp:258]     Train net output #0: loss = 4.29154e-05 (* 1 = 4.29154e-05 loss)
I0811 06:35:51.433105 10215 sgd_solver.cpp:112] Iteration 52220, lr = 0.0001
I0811 06:35:59.469898 10215 solver.cpp:347] Iteration 52266, Testing net (#0)
I0811 06:35:59.469971 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:36:04.786664 10215 blocking_queue.cpp:49] Waiting for data
I0811 06:36:11.543146 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:36:16.385670 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:36:16.385694 10215 solver.cpp:414]     Test net output #1: loss = 0.00711163 (* 1 = 0.00711163 loss)
I0811 06:36:20.893726 10215 solver.cpp:239] Iteration 52290 (2.37612 iter/s, 29.4598s/70 iters), loss = 0.00034431
I0811 06:36:20.893759 10215 solver.cpp:258]     Train net output #0: loss = 0.000344596 (* 1 = 0.000344596 loss)
I0811 06:36:20.893765 10215 sgd_solver.cpp:112] Iteration 52290, lr = 0.0001
I0811 06:36:33.523452 10215 solver.cpp:239] Iteration 52360 (5.54265 iter/s, 12.6293s/70 iters), loss = 0.0109022
I0811 06:36:33.523581 10215 solver.cpp:258]     Train net output #0: loss = 0.0109025 (* 1 = 0.0109025 loss)
I0811 06:36:33.523588 10215 sgd_solver.cpp:112] Iteration 52360, lr = 0.0001
I0811 06:36:46.139690 10215 solver.cpp:239] Iteration 52430 (5.54861 iter/s, 12.6158s/70 iters), loss = 0.000329107
I0811 06:36:46.139721 10215 solver.cpp:258]     Train net output #0: loss = 0.000329393 (* 1 = 0.000329393 loss)
I0811 06:36:46.139727 10215 sgd_solver.cpp:112] Iteration 52430, lr = 0.0001
I0811 06:36:58.773844 10215 solver.cpp:239] Iteration 52500 (5.5407 iter/s, 12.6338s/70 iters), loss = 0.000281431
I0811 06:36:58.773874 10215 solver.cpp:258]     Train net output #0: loss = 0.000281716 (* 1 = 0.000281716 loss)
I0811 06:36:58.773880 10215 sgd_solver.cpp:112] Iteration 52500, lr = 0.0001
I0811 06:37:11.410745 10215 solver.cpp:239] Iteration 52570 (5.5395 iter/s, 12.6365s/70 iters), loss = 0.015017
I0811 06:37:11.410864 10215 solver.cpp:258]     Train net output #0: loss = 0.0150173 (* 1 = 0.0150173 loss)
I0811 06:37:11.410871 10215 sgd_solver.cpp:112] Iteration 52570, lr = 0.0001
I0811 06:37:24.036166 10215 solver.cpp:239] Iteration 52640 (5.54457 iter/s, 12.625s/70 iters), loss = 2.66416e-05
I0811 06:37:24.036198 10215 solver.cpp:258]     Train net output #0: loss = 2.6925e-05 (* 1 = 2.6925e-05 loss)
I0811 06:37:24.036203 10215 sgd_solver.cpp:112] Iteration 52640, lr = 0.0001
I0811 06:37:36.659808 10215 solver.cpp:239] Iteration 52710 (5.54532 iter/s, 12.6233s/70 iters), loss = 0.000266261
I0811 06:37:36.659837 10215 solver.cpp:258]     Train net output #0: loss = 0.000266546 (* 1 = 0.000266546 loss)
I0811 06:37:36.659842 10215 sgd_solver.cpp:112] Iteration 52710, lr = 0.0001
I0811 06:37:42.327913 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:37:49.291409 10215 solver.cpp:239] Iteration 52780 (5.54182 iter/s, 12.6312s/70 iters), loss = 4.18743e-06
I0811 06:37:49.291437 10215 solver.cpp:258]     Train net output #0: loss = 4.47435e-06 (* 1 = 4.47435e-06 loss)
I0811 06:37:49.291443 10215 sgd_solver.cpp:112] Iteration 52780, lr = 0.0001
I0811 06:37:57.694556 10215 solver.cpp:347] Iteration 52828, Testing net (#0)
I0811 06:37:57.694571 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:38:09.901377 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:38:14.784662 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:38:14.784745 10215 solver.cpp:414]     Test net output #1: loss = 0.00709371 (* 1 = 0.00709371 loss)
I0811 06:38:18.934718 10215 solver.cpp:239] Iteration 52850 (2.36148 iter/s, 29.6425s/70 iters), loss = 0.000283381
I0811 06:38:18.934746 10215 solver.cpp:258]     Train net output #0: loss = 0.00028366 (* 1 = 0.00028366 loss)
I0811 06:38:18.934751 10215 sgd_solver.cpp:112] Iteration 52850, lr = 0.0001
I0811 06:38:31.537210 10215 solver.cpp:239] Iteration 52920 (5.55462 iter/s, 12.6021s/70 iters), loss = 0.00318777
I0811 06:38:31.537235 10215 solver.cpp:258]     Train net output #0: loss = 0.00318805 (* 1 = 0.00318805 loss)
I0811 06:38:31.537241 10215 sgd_solver.cpp:112] Iteration 52920, lr = 0.0001
I0811 06:38:44.166743 10215 solver.cpp:239] Iteration 52990 (5.54274 iter/s, 12.6291s/70 iters), loss = 0.000997113
I0811 06:38:44.166774 10215 solver.cpp:258]     Train net output #0: loss = 0.00099739 (* 1 = 0.00099739 loss)
I0811 06:38:44.166779 10215 sgd_solver.cpp:112] Iteration 52990, lr = 0.0001
I0811 06:38:56.794654 10215 solver.cpp:239] Iteration 53060 (5.54344 iter/s, 12.6275s/70 iters), loss = 6.68291e-06
I0811 06:38:56.794788 10215 solver.cpp:258]     Train net output #0: loss = 6.95922e-06 (* 1 = 6.95922e-06 loss)
I0811 06:38:56.794796 10215 sgd_solver.cpp:112] Iteration 53060, lr = 0.0001
I0811 06:39:09.427644 10215 solver.cpp:239] Iteration 53130 (5.54126 iter/s, 12.6325s/70 iters), loss = 2.60803e-05
I0811 06:39:09.427672 10215 solver.cpp:258]     Train net output #0: loss = 2.63604e-05 (* 1 = 2.63604e-05 loss)
I0811 06:39:09.427678 10215 sgd_solver.cpp:112] Iteration 53130, lr = 0.0001
I0811 06:39:22.055215 10215 solver.cpp:239] Iteration 53200 (5.54359 iter/s, 12.6272s/70 iters), loss = 0.000121392
I0811 06:39:22.055243 10215 solver.cpp:258]     Train net output #0: loss = 0.000121672 (* 1 = 0.000121672 loss)
I0811 06:39:22.055248 10215 sgd_solver.cpp:112] Iteration 53200, lr = 0.0001
I0811 06:39:34.680351 10215 solver.cpp:239] Iteration 53270 (5.54466 iter/s, 12.6248s/70 iters), loss = 0.00015419
I0811 06:39:34.680496 10215 solver.cpp:258]     Train net output #0: loss = 0.000154472 (* 1 = 0.000154472 loss)
I0811 06:39:34.680505 10215 sgd_solver.cpp:112] Iteration 53270, lr = 0.0001
I0811 06:39:40.528204 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:39:47.305390 10215 solver.cpp:239] Iteration 53340 (5.54475 iter/s, 12.6245s/70 iters), loss = 5.11031e-05
I0811 06:39:47.305423 10215 solver.cpp:258]     Train net output #0: loss = 5.13862e-05 (* 1 = 5.13862e-05 loss)
I0811 06:39:47.305429 10215 sgd_solver.cpp:112] Iteration 53340, lr = 0.0001
I0811 06:39:56.059753 10215 solver.cpp:347] Iteration 53390, Testing net (#0)
I0811 06:39:56.059767 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:40:08.115144 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:40:13.077186 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:40:13.077210 10215 solver.cpp:414]     Test net output #1: loss = 0.00726221 (* 1 = 0.00726221 loss)
I0811 06:40:16.872440 10215 solver.cpp:239] Iteration 53410 (2.36757 iter/s, 29.5662s/70 iters), loss = 6.61723e-05
I0811 06:40:16.872467 10215 solver.cpp:258]     Train net output #0: loss = 6.64516e-05 (* 1 = 6.64516e-05 loss)
I0811 06:40:16.872473 10215 sgd_solver.cpp:112] Iteration 53410, lr = 0.0001
I0811 06:40:29.496031 10215 solver.cpp:239] Iteration 53480 (5.54534 iter/s, 12.6232s/70 iters), loss = 8.53492e-05
I0811 06:40:29.496058 10215 solver.cpp:258]     Train net output #0: loss = 8.56268e-05 (* 1 = 8.56268e-05 loss)
I0811 06:40:29.496063 10215 sgd_solver.cpp:112] Iteration 53480, lr = 0.0001
I0811 06:40:42.119685 10215 solver.cpp:239] Iteration 53550 (5.54531 iter/s, 12.6233s/70 iters), loss = 0.00493848
I0811 06:40:42.119823 10215 solver.cpp:258]     Train net output #0: loss = 0.00493875 (* 1 = 0.00493875 loss)
I0811 06:40:42.119832 10215 sgd_solver.cpp:112] Iteration 53550, lr = 0.0001
I0811 06:40:54.753741 10215 solver.cpp:239] Iteration 53620 (5.54079 iter/s, 12.6336s/70 iters), loss = 0.00323141
I0811 06:40:54.753770 10215 solver.cpp:258]     Train net output #0: loss = 0.00323169 (* 1 = 0.00323169 loss)
I0811 06:40:54.753777 10215 sgd_solver.cpp:112] Iteration 53620, lr = 0.0001
I0811 06:41:07.377982 10215 solver.cpp:239] Iteration 53690 (5.54505 iter/s, 12.6239s/70 iters), loss = 2.74912e-05
I0811 06:41:07.378010 10215 solver.cpp:258]     Train net output #0: loss = 2.77758e-05 (* 1 = 2.77758e-05 loss)
I0811 06:41:07.378016 10215 sgd_solver.cpp:112] Iteration 53690, lr = 0.0001
I0811 06:41:20.008991 10215 solver.cpp:239] Iteration 53760 (5.54208 iter/s, 12.6306s/70 iters), loss = 0.000167834
I0811 06:41:20.009075 10215 solver.cpp:258]     Train net output #0: loss = 0.000168123 (* 1 = 0.000168123 loss)
I0811 06:41:20.009094 10215 sgd_solver.cpp:112] Iteration 53760, lr = 0.0001
I0811 06:41:32.614882 10215 solver.cpp:239] Iteration 53830 (5.55315 iter/s, 12.6055s/70 iters), loss = 0.000124482
I0811 06:41:32.614909 10215 solver.cpp:258]     Train net output #0: loss = 0.000124766 (* 1 = 0.000124766 loss)
I0811 06:41:32.614915 10215 sgd_solver.cpp:112] Iteration 53830, lr = 0.0001
I0811 06:41:38.650854 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:41:45.237776 10215 solver.cpp:239] Iteration 53900 (5.54564 iter/s, 12.6225s/70 iters), loss = 1.88753e-05
I0811 06:41:45.237803 10215 solver.cpp:258]     Train net output #0: loss = 1.91608e-05 (* 1 = 1.91608e-05 loss)
I0811 06:41:45.237809 10215 sgd_solver.cpp:112] Iteration 53900, lr = 0.0001
I0811 06:41:54.335088 10215 solver.cpp:347] Iteration 53952, Testing net (#0)
I0811 06:41:54.335202 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:42:06.367333 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:42:11.328393 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:42:11.328418 10215 solver.cpp:414]     Test net output #1: loss = 0.00721994 (* 1 = 0.00721994 loss)
I0811 06:42:14.758728 10215 solver.cpp:239] Iteration 53970 (2.37126 iter/s, 29.5201s/70 iters), loss = 0.0228558
I0811 06:42:14.758755 10215 solver.cpp:258]     Train net output #0: loss = 0.0228561 (* 1 = 0.0228561 loss)
I0811 06:42:14.758761 10215 sgd_solver.cpp:112] Iteration 53970, lr = 0.0001
I0811 06:42:27.374089 10215 solver.cpp:239] Iteration 54040 (5.54895 iter/s, 12.615s/70 iters), loss = 4.97528e-05
I0811 06:42:27.374213 10215 solver.cpp:258]     Train net output #0: loss = 5.00369e-05 (* 1 = 5.00369e-05 loss)
I0811 06:42:27.374233 10215 sgd_solver.cpp:112] Iteration 54040, lr = 0.0001
I0811 06:42:39.985528 10215 solver.cpp:239] Iteration 54110 (5.55072 iter/s, 12.611s/70 iters), loss = 0.000358513
I0811 06:42:39.985555 10215 solver.cpp:258]     Train net output #0: loss = 0.000358794 (* 1 = 0.000358794 loss)
I0811 06:42:39.985561 10215 sgd_solver.cpp:112] Iteration 54110, lr = 0.0001
I0811 06:42:52.607333 10215 solver.cpp:239] Iteration 54180 (5.54612 iter/s, 12.6214s/70 iters), loss = 0.000367188
I0811 06:42:52.607360 10215 solver.cpp:258]     Train net output #0: loss = 0.000367467 (* 1 = 0.000367467 loss)
I0811 06:42:52.607367 10215 sgd_solver.cpp:112] Iteration 54180, lr = 0.0001
I0811 06:43:05.228876 10215 solver.cpp:239] Iteration 54250 (5.54624 iter/s, 12.6212s/70 iters), loss = 0.0131601
I0811 06:43:05.229004 10215 solver.cpp:258]     Train net output #0: loss = 0.0131604 (* 1 = 0.0131604 loss)
I0811 06:43:05.229012 10215 sgd_solver.cpp:112] Iteration 54250, lr = 0.0001
I0811 06:43:17.844332 10215 solver.cpp:239] Iteration 54320 (5.54895 iter/s, 12.615s/70 iters), loss = 6.14972e-05
I0811 06:43:17.844362 10215 solver.cpp:258]     Train net output #0: loss = 6.17623e-05 (* 1 = 6.17623e-05 loss)
I0811 06:43:17.844367 10215 sgd_solver.cpp:112] Iteration 54320, lr = 0.0001
I0811 06:43:30.455970 10215 solver.cpp:239] Iteration 54390 (5.5506 iter/s, 12.6113s/70 iters), loss = 0.000320324
I0811 06:43:30.456002 10215 solver.cpp:258]     Train net output #0: loss = 0.000320584 (* 1 = 0.000320584 loss)
I0811 06:43:30.456008 10215 sgd_solver.cpp:112] Iteration 54390, lr = 0.0001
I0811 06:43:36.795121 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:43:43.079411 10215 solver.cpp:239] Iteration 54460 (5.5454 iter/s, 12.6231s/70 iters), loss = 0.0215778
I0811 06:43:43.079438 10215 solver.cpp:258]     Train net output #0: loss = 0.021578 (* 1 = 0.021578 loss)
I0811 06:43:43.079444 10215 sgd_solver.cpp:112] Iteration 54460, lr = 0.0001
I0811 06:43:52.566124 10215 solver.cpp:347] Iteration 54514, Testing net (#0)
I0811 06:43:52.566139 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:44:01.968612 10215 blocking_queue.cpp:49] Waiting for data
I0811 06:44:04.537163 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:44:09.578073 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997167
I0811 06:44:09.578124 10215 solver.cpp:414]     Test net output #1: loss = 0.00721066 (* 1 = 0.00721066 loss)
I0811 06:44:12.645941 10215 solver.cpp:239] Iteration 54530 (2.36761 iter/s, 29.5657s/70 iters), loss = 0.000267955
I0811 06:44:12.645968 10215 solver.cpp:258]     Train net output #0: loss = 0.000268215 (* 1 = 0.000268215 loss)
I0811 06:44:12.645974 10215 sgd_solver.cpp:112] Iteration 54530, lr = 0.0001
I0811 06:44:25.261190 10215 solver.cpp:239] Iteration 54600 (5.549 iter/s, 12.6149s/70 iters), loss = 7.95757e-06
I0811 06:44:25.261217 10215 solver.cpp:258]     Train net output #0: loss = 8.21846e-06 (* 1 = 8.21846e-06 loss)
I0811 06:44:25.261224 10215 sgd_solver.cpp:112] Iteration 54600, lr = 0.0001
I0811 06:44:37.883054 10215 solver.cpp:239] Iteration 54670 (5.5461 iter/s, 12.6215s/70 iters), loss = 0.000354746
I0811 06:44:37.883085 10215 solver.cpp:258]     Train net output #0: loss = 0.000355012 (* 1 = 0.000355012 loss)
I0811 06:44:37.883091 10215 sgd_solver.cpp:112] Iteration 54670, lr = 0.0001
I0811 06:44:50.497180 10215 solver.cpp:239] Iteration 54740 (5.5495 iter/s, 12.6137s/70 iters), loss = 0.000307259
I0811 06:44:50.497239 10215 solver.cpp:258]     Train net output #0: loss = 0.000307521 (* 1 = 0.000307521 loss)
I0811 06:44:50.497246 10215 sgd_solver.cpp:112] Iteration 54740, lr = 0.0001
I0811 06:45:03.116313 10215 solver.cpp:239] Iteration 54810 (5.54731 iter/s, 12.6187s/70 iters), loss = 0.00018987
I0811 06:45:03.116340 10215 solver.cpp:258]     Train net output #0: loss = 0.000190131 (* 1 = 0.000190131 loss)
I0811 06:45:03.116346 10215 sgd_solver.cpp:112] Iteration 54810, lr = 0.0001
I0811 06:45:15.743618 10215 solver.cpp:239] Iteration 54880 (5.54371 iter/s, 12.6269s/70 iters), loss = 5.9902e-05
I0811 06:45:15.743646 10215 solver.cpp:258]     Train net output #0: loss = 6.01751e-05 (* 1 = 6.01751e-05 loss)
I0811 06:45:15.743654 10215 sgd_solver.cpp:112] Iteration 54880, lr = 0.0001
I0811 06:45:28.356485 10215 solver.cpp:239] Iteration 54950 (5.55005 iter/s, 12.6125s/70 iters), loss = 0.00268107
I0811 06:45:28.356659 10215 solver.cpp:258]     Train net output #0: loss = 0.00268134 (* 1 = 0.00268134 loss)
I0811 06:45:28.356667 10215 sgd_solver.cpp:112] Iteration 54950, lr = 0.0001
I0811 06:45:34.886504 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:45:40.982385 10215 solver.cpp:239] Iteration 55020 (5.54439 iter/s, 12.6254s/70 iters), loss = 0.000356965
I0811 06:45:40.982415 10215 solver.cpp:258]     Train net output #0: loss = 0.000357238 (* 1 = 0.000357238 loss)
I0811 06:45:40.982421 10215 sgd_solver.cpp:112] Iteration 55020, lr = 0.0001
I0811 06:45:50.830921 10215 solver.cpp:347] Iteration 55076, Testing net (#0)
I0811 06:45:50.830938 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:46:02.694090 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:46:07.807885 10215 solver.cpp:414]     Test net output #0: accuracy = 0.997333
I0811 06:46:07.807910 10215 solver.cpp:414]     Test net output #1: loss = 0.00803273 (* 1 = 0.00803273 loss)
I0811 06:46:10.515466 10215 solver.cpp:239] Iteration 55090 (2.37029 iter/s, 29.5323s/70 iters), loss = 1.56405e-05
I0811 06:46:10.515499 10215 solver.cpp:258]     Train net output #0: loss = 1.59013e-05 (* 1 = 1.59013e-05 loss)
I0811 06:46:10.515506 10215 sgd_solver.cpp:112] Iteration 55090, lr = 0.0001
I0811 06:46:23.135962 10215 solver.cpp:239] Iteration 55160 (5.5467 iter/s, 12.6201s/70 iters), loss = 9.48984e-06
I0811 06:46:23.135988 10215 solver.cpp:258]     Train net output #0: loss = 9.75189e-06 (* 1 = 9.75189e-06 loss)
I0811 06:46:23.135993 10215 sgd_solver.cpp:112] Iteration 55160, lr = 0.0001
I0811 06:46:35.761209 10215 solver.cpp:239] Iteration 55230 (5.54461 iter/s, 12.6249s/70 iters), loss = 2.36406e-05
I0811 06:46:35.761335 10215 solver.cpp:258]     Train net output #0: loss = 2.39048e-05 (* 1 = 2.39048e-05 loss)
I0811 06:46:35.761343 10215 sgd_solver.cpp:112] Iteration 55230, lr = 0.0001
I0811 06:46:48.401670 10215 solver.cpp:239] Iteration 55300 (5.53798 iter/s, 12.64s/70 iters), loss = 0.000165424
I0811 06:46:48.401696 10215 solver.cpp:258]     Train net output #0: loss = 0.000165669 (* 1 = 0.000165669 loss)
I0811 06:46:48.401701 10215 sgd_solver.cpp:112] Iteration 55300, lr = 0.0001
I0811 06:47:01.031764 10215 solver.cpp:239] Iteration 55370 (5.54248 iter/s, 12.6297s/70 iters), loss = 2.93354e-05
I0811 06:47:01.031790 10215 solver.cpp:258]     Train net output #0: loss = 2.95814e-05 (* 1 = 2.95814e-05 loss)
I0811 06:47:01.031795 10215 sgd_solver.cpp:112] Iteration 55370, lr = 0.0001
I0811 06:47:13.654371 10215 solver.cpp:239] Iteration 55440 (5.54577 iter/s, 12.6222s/70 iters), loss = 0.000220015
I0811 06:47:13.654510 10215 solver.cpp:258]     Train net output #0: loss = 0.000220252 (* 1 = 0.000220252 loss)
I0811 06:47:13.654518 10215 sgd_solver.cpp:112] Iteration 55440, lr = 0.0001
I0811 06:47:26.280107 10215 solver.cpp:239] Iteration 55510 (5.54444 iter/s, 12.6253s/70 iters), loss = 0.000505212
I0811 06:47:26.280134 10215 solver.cpp:258]     Train net output #0: loss = 0.000505449 (* 1 = 0.000505449 loss)
I0811 06:47:26.280140 10215 sgd_solver.cpp:112] Iteration 55510, lr = 0.0001
I0811 06:47:32.996047 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:47:38.911813 10215 solver.cpp:239] Iteration 55580 (5.54177 iter/s, 12.6313s/70 iters), loss = 1.19004e-05
I0811 06:47:38.911842 10215 solver.cpp:258]     Train net output #0: loss = 1.21362e-05 (* 1 = 1.21362e-05 loss)
I0811 06:47:38.911847 10215 sgd_solver.cpp:112] Iteration 55580, lr = 0.0001
I0811 06:47:49.108520 10215 solver.cpp:347] Iteration 55638, Testing net (#0)
I0811 06:47:49.108665 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:48:00.950179 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:48:06.107374 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:48:06.107399 10215 solver.cpp:414]     Test net output #1: loss = 0.00723876 (* 1 = 0.00723876 loss)
I0811 06:48:08.454463 10215 solver.cpp:239] Iteration 55650 (2.36952 iter/s, 29.5418s/70 iters), loss = 5.36679e-05
I0811 06:48:08.454493 10215 solver.cpp:258]     Train net output #0: loss = 5.39019e-05 (* 1 = 5.39019e-05 loss)
I0811 06:48:08.454499 10215 sgd_solver.cpp:112] Iteration 55650, lr = 1e-05
I0811 06:48:21.067392 10215 solver.cpp:239] Iteration 55720 (5.55002 iter/s, 12.6126s/70 iters), loss = 0.000337202
I0811 06:48:21.067523 10215 solver.cpp:258]     Train net output #0: loss = 0.00033744 (* 1 = 0.00033744 loss)
I0811 06:48:21.067530 10215 sgd_solver.cpp:112] Iteration 55720, lr = 1e-05
I0811 06:48:33.684417 10215 solver.cpp:239] Iteration 55790 (5.54826 iter/s, 12.6166s/70 iters), loss = 0.00136173
I0811 06:48:33.684444 10215 solver.cpp:258]     Train net output #0: loss = 0.00136197 (* 1 = 0.00136197 loss)
I0811 06:48:33.684450 10215 sgd_solver.cpp:112] Iteration 55790, lr = 1e-05
I0811 06:48:46.302897 10215 solver.cpp:239] Iteration 55860 (5.54758 iter/s, 12.6181s/70 iters), loss = 0.00104026
I0811 06:48:46.302923 10215 solver.cpp:258]     Train net output #0: loss = 0.0010405 (* 1 = 0.0010405 loss)
I0811 06:48:46.302929 10215 sgd_solver.cpp:112] Iteration 55860, lr = 1e-05
I0811 06:48:58.933719 10215 solver.cpp:239] Iteration 55930 (5.54216 iter/s, 12.6305s/70 iters), loss = 0.000115281
I0811 06:48:58.933864 10215 solver.cpp:258]     Train net output #0: loss = 0.00011551 (* 1 = 0.00011551 loss)
I0811 06:48:58.933872 10215 sgd_solver.cpp:112] Iteration 55930, lr = 1e-05
I0811 06:49:11.573832 10215 solver.cpp:239] Iteration 56000 (5.53814 iter/s, 12.6396s/70 iters), loss = 8.09194e-05
I0811 06:49:11.573858 10215 solver.cpp:258]     Train net output #0: loss = 8.11418e-05 (* 1 = 8.11418e-05 loss)
I0811 06:49:11.573864 10215 sgd_solver.cpp:112] Iteration 56000, lr = 1e-05
I0811 06:49:24.191251 10215 solver.cpp:239] Iteration 56070 (5.54805 iter/s, 12.617s/70 iters), loss = 0.00150521
I0811 06:49:24.191279 10215 solver.cpp:258]     Train net output #0: loss = 0.00150544 (* 1 = 0.00150544 loss)
I0811 06:49:24.191285 10215 sgd_solver.cpp:112] Iteration 56070, lr = 1e-05
I0811 06:49:31.101347 10220 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:49:36.816277 10215 solver.cpp:239] Iteration 56140 (5.54471 iter/s, 12.6247s/70 iters), loss = 2.18953e-05
I0811 06:49:36.816305 10215 solver.cpp:258]     Train net output #0: loss = 2.21172e-05 (* 1 = 2.21172e-05 loss)
I0811 06:49:36.816311 10215 sgd_solver.cpp:112] Iteration 56140, lr = 1e-05
I0811 06:49:47.373929 10215 solver.cpp:464] Snapshotting to binary proto file snapshot_iter_56200.caffemodel
I0811 06:49:47.469554 10215 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshot_iter_56200.solverstate
I0811 06:49:47.473915 10215 solver.cpp:347] Iteration 56200, Testing net (#0)
I0811 06:49:47.473925 10215 net.cpp:676] Ignoring source layer train-data
I0811 06:49:59.149652 10221 data_layer.cpp:73] Restarting data prefetching from start.
I0811 06:50:04.352725 10215 solver.cpp:414]     Test net output #0: accuracy = 0.9975
I0811 06:50:04.352836 10215 solver.cpp:414]     Test net output #1: loss = 0.00722427 (* 1 = 0.00722427 loss)
I0811 06:50:04.352843 10215 solver.cpp:332] Optimization Done.
I0811 06:50:04.352845 10215 caffe.cpp:250] Optimization Done.
